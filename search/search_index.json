{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"File Storage &amp; Sandbox Backends for Pydantic AI","text":"<p>Console Toolset, Docker Sandbox, and Permission System for Pydantic AI agents.</p> <p>pydantic-ai-backend provides file storage, sandbox execution, and a ready-to-use console toolset for pydantic-ai agents. Give your AI agents the ability to read, write, and execute code safely.</p> <ul> <li> <p> Console Toolset</p> <p>Ready-to-use tools: ls, read, write, edit, glob, grep, execute</p> </li> <li> <p> Docker Isolation</p> <p>Execute code safely in isolated containers</p> </li> <li> <p> Multiple Backends</p> <p>In-memory, filesystem, Docker \u2014 same interface</p> </li> <li> <p> Permission System</p> <p>Fine-grained access control with presets</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Add file and execution capabilities to any pydantic-ai agent:</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\nagent = Agent(\n    \"openai:gpt-4o\",\n    deps_type=Deps,\n    toolsets=[create_console_toolset()],\n)\n\nbackend = LocalBackend(root_dir=\"/workspace\")\nresult = agent.run_sync(\n    \"Create a fibonacci.py script and run it\",\n    deps=Deps(backend=backend),\n)\nprint(result.output)\n</code></pre>"},{"location":"#choose-your-backend","title":"Choose Your Backend","text":"<p>Same toolset, different backends \u2014 swap based on your use case:</p> Local DevelopmentTestingProduction (Docker)Multi-User Python<pre><code>from pydantic_ai_backends import LocalBackend\n\nbackend = LocalBackend(root_dir=\"./workspace\")\n</code></pre> Python<pre><code>from pydantic_ai_backends import StateBackend\n\nbackend = StateBackend()  # In-memory, no side effects\n</code></pre> Python<pre><code>from pydantic_ai_backends import DockerSandbox\n\nbackend = DockerSandbox(runtime=\"python-datascience\")\n</code></pre> Python<pre><code>from pydantic_ai_backends import SessionManager\n\nmanager = SessionManager(workspace_root=\"/app/workspaces\")\nbackend = await manager.get_or_create(user_id=\"alice\")\n</code></pre>"},{"location":"#available-tools","title":"Available Tools","text":"Tool Description <code>ls</code> List files in a directory <code>read_file</code> Read file content with line numbers <code>write_file</code> Create or overwrite a file <code>edit_file</code> Replace strings in a file <code>glob</code> Find files matching a pattern <code>grep</code> Search for patterns in files <code>execute</code> Run shell commands (optional)"},{"location":"#backend-comparison","title":"Backend Comparison","text":"Backend Persistence Execution Best For <code>LocalBackend</code> Persistent Yes CLI tools, local dev <code>StateBackend</code> Ephemeral No Testing, mocking <code>DockerSandbox</code> Ephemeral* Yes Safe execution, multi-user <code>CompositeBackend</code> Mixed Depends Route by path prefix <p>*DockerSandbox supports persistent volumes via <code>workspace_root</code> parameter.</p>"},{"location":"#related-projects","title":"Related Projects","text":"Package Description Pydantic Deep Agents Full agent framework (uses this library) pydantic-ai-todo Task planning toolset subagents-pydantic-ai Multi-agent orchestration summarization-pydantic-ai Context management pydantic-ai The foundation \u2014 agent framework by Pydantic"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p> Installation</p> <p>Get started with pip or uv</p> </li> <li> <p> Concepts</p> <p>Learn about backends and toolsets</p> </li> <li> <p> Examples</p> <p>See real-world usage patterns</p> </li> <li> <p> API Reference</p> <p>Full API documentation</p> </li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#014-2025-01-22","title":"0.1.4 - 2025-01-22","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>README: Complete rewrite with centered header, badges, Use Cases table, and vstorm-co branding</li> <li>Documentation: Updated styling to match pydantic-deep pink theme</li> <li>Inter font for text, JetBrains Mono for code</li> <li>Pink accent color scheme</li> <li>Custom CSS and announcement bar</li> <li>mkdocs.yml: Updated with full Material theme configuration</li> </ul>"},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Custom Styling: docs/overrides/main.html, docs/stylesheets/extra.css</li> <li>Abbreviations: docs/includes/abbreviations.md for markdown expansions</li> <li>FAQ Section: Expanded getting-help.md with common questions</li> </ul>"},{"location":"changelog/#013-2026-01-22","title":"0.1.3 - 2026-01-22","text":""},{"location":"changelog/#fixed","title":"Fixed","text":"<ul> <li><code>DockerSandbox.edit()</code> now handles multiline strings correctly. Replaced sed/grep-based   implementation with Python string operations, which naturally handle newlines and special   characters without shell escaping issues. (#6)</li> </ul>"},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>Added <code>edit()</code> as an abstract method in <code>BaseSandbox</code> to make the interface explicit</li> <li>Docker tests now use shared fixtures (<code>scope=\"module\"</code>) for faster test execution</li> </ul>"},{"location":"changelog/#012-2026-01-21","title":"0.1.2 - 2026-01-21","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Fine-grained Permission System - Pattern-based access control for file operations and shell execution</li> <li><code>PermissionRuleset</code> - Complete permission configuration with per-operation rules</li> <li><code>PermissionRule</code> - Glob pattern matching with <code>allow</code>, <code>deny</code>, or <code>ask</code> actions</li> <li><code>PermissionChecker</code> - Validates operations against rulesets with async callback support</li> <li> <p><code>OperationPermissions</code> - Per-operation default actions and override rules</p> </li> <li> <p>Pre-configured Permission Presets</p> </li> <li><code>DEFAULT_RULESET</code> - Safe defaults (allow reads except secrets, ask for writes/executes)</li> <li><code>PERMISSIVE_RULESET</code> - Allow most operations, deny only dangerous commands</li> <li><code>READONLY_RULESET</code> - Allow read operations only, deny all writes and executes</li> <li> <p><code>STRICT_RULESET</code> - Everything requires explicit approval</p> </li> <li> <p>Permission Integration</p> </li> <li><code>permissions</code> parameter in <code>LocalBackend</code> for fine-grained access control</li> <li><code>permissions</code> parameter in <code>create_console_toolset()</code> for tool approval requirements</li> <li><code>ask_callback</code> parameter for interactive permission prompts</li> <li> <p><code>ask_fallback</code> parameter to control behavior when callback unavailable (\"deny\" or \"error\")</p> </li> <li> <p>Helper Functions and Patterns</p> </li> <li><code>create_ruleset()</code> factory function for custom permission configurations</li> <li><code>SECRETS_PATTERNS</code> - Common patterns for sensitive files (.env, .pem, credentials, etc.)</li> <li><code>SYSTEM_PATTERNS</code> - Common patterns for system directories (/etc, /var, etc.)</li> <li> <p><code>is_allowed()</code>, <code>is_denied()</code>, <code>requires_approval()</code> convenience methods</p> </li> <li> <p>New Exceptions</p> </li> <li><code>PermissionError</code> - Raised when approval required but no callback available</li> <li><code>PermissionDeniedError</code> - Raised when operation is explicitly denied</li> </ul>"},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li><code>LocalBackend</code> now checks permissions after <code>allowed_directories</code> validation</li> <li>Legacy <code>require_write_approval</code> and <code>require_execute_approval</code> flags are preserved for backward compatibility but <code>permissions</code> parameter takes precedence when provided</li> </ul>"},{"location":"changelog/#fixed_1","title":"Fixed","text":"<ul> <li><code>DockerSandbox.execute()</code> no longer incorrectly escapes commands when timeout is specified.   Previously, using Python's <code>repr()</code> for shell quoting caused issues with commands containing   mixed quotes or special characters. (#3)</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>New \"Permissions\" concept guide with examples</li> <li>Updated backends documentation with permission examples</li> <li>Updated console toolset documentation with permission configuration</li> <li>API reference for all permission types and functions</li> </ul>"},{"location":"changelog/#011-2026-01-20","title":"0.1.1 - 2026-01-20","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li><code>ignore_hidden</code> parameter to <code>grep_raw()</code> in <code>BackendProtocol</code> - controls whether hidden   files (dotfiles) are included in search results (default: <code>True</code> = ignore hidden files).</li> <li><code>default_ignore_hidden</code> option in <code>create_console_toolset()</code> so agents can opt-in to   searching dotfiles by default.</li> <li><code>--include-hidden</code> CLI flag in the <code>examples/local_cli</code> agent to expose the new grep   behavior from the command line.</li> </ul>"},{"location":"changelog/#changed_3","title":"Changed","text":"<ul> <li><code>grep_raw()</code> now consistently ignores hidden files by default across all backends   (<code>StateBackend</code>, <code>LocalBackend</code>, <code>CompositeBackend</code>, <code>DockerSandbox</code>).</li> <li>Console <code>grep</code> tool now treats <code>ignore_hidden</code> as an override parameter, falling back to   the toolset's default when omitted.</li> </ul>"},{"location":"changelog/#010-2025-01-17","title":"0.1.0 - 2025-01-17","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li><code>LocalBackend</code> - Unified backend for local filesystem + shell execution</li> <li>Console Toolset - Ready-to-use pydantic-ai toolset</li> <li>Full Documentation - MkDocs Material theme documentation</li> <li>New <code>[console]</code> optional dependency for pydantic-ai toolset</li> <li>Real Coveralls integration for dynamic coverage badge</li> <li>Architecture diagram in README</li> </ul>"},{"location":"changelog/#changed_4","title":"Changed","text":"<ul> <li>Project Structure Reorganization</li> <li>Updated all imports to new module paths</li> <li>Version now loaded dynamically from package metadata</li> <li>README rewritten with pydantic-ai agent examples</li> </ul>"},{"location":"changelog/#removed","title":"Removed","text":"<ul> <li><code>FilesystemBackend</code> - Replaced by <code>LocalBackend</code></li> <li><code>LocalSandbox</code> - Replaced by <code>LocalBackend</code></li> </ul>"},{"location":"changelog/#004-2025-01-16","title":"0.0.4 - 2025-01-16","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li><code>volumes</code> parameter to <code>DockerSandbox</code> for mounting host directories</li> <li><code>workspace_root</code> parameter to <code>SessionManager</code> for automatic per-session storage</li> </ul>"},{"location":"changelog/#001-2025-12-28","title":"0.0.1 - 2025-12-28","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Initial release extracted from pydantic-deep</li> <li><code>BackendProtocol</code> - Unified interface for file operations</li> <li><code>SandboxProtocol</code> - Extended interface for command execution</li> <li><code>StateBackend</code> - In-memory file storage</li> <li><code>DockerSandbox</code> - Docker container-based sandbox</li> <li><code>SessionManager</code> - Multi-user session management</li> <li>Built-in runtimes: python-minimal, python-datascience, python-web, node-minimal, node-react</li> </ul>"},{"location":"getting-help/","title":"Getting Help","text":""},{"location":"getting-help/#documentation","title":"Documentation","text":"<p>This documentation is your primary resource. Use the search bar (press <code>/</code> or <code>s</code>) to find specific topics.</p>"},{"location":"getting-help/#github-issues","title":"GitHub Issues","text":"<p>For bugs, feature requests, or questions:</p> <p> Open an Issue</p>"},{"location":"getting-help/#before-opening-an-issue","title":"Before Opening an Issue","text":"<ol> <li>Search existing issues - Your problem may already be reported</li> <li>Check the docs - The answer might be here</li> <li>Prepare a minimal example - Help us reproduce the issue</li> </ol>"},{"location":"getting-help/#bug-report-template","title":"Bug Report Template","text":"Markdown<pre><code>## Description\n[Clear description of the bug]\n\n## Steps to Reproduce\n1. Create backend with...\n2. Call method...\n3. Observe error...\n\n## Expected Behavior\n[What you expected to happen]\n\n## Actual Behavior\n[What actually happened]\n\n## Environment\n- pydantic-ai-backend version: X.X.X\n- pydantic-ai version: X.X.X\n- Python version: 3.XX\n- OS: [e.g., macOS 14.0, Ubuntu 22.04]\n- Docker version (if using DockerSandbox): X.X.X\n</code></pre>"},{"location":"getting-help/#community-resources","title":"Community Resources","text":""},{"location":"getting-help/#pydantic-ai","title":"Pydantic AI","text":"<p>pydantic-ai-backend is designed for use with Pydantic AI. Their documentation is an excellent resource:</p> <ul> <li>Pydantic AI Documentation</li> <li>Pydantic AI GitHub</li> </ul>"},{"location":"getting-help/#related-projects","title":"Related Projects","text":"<ul> <li>pydantic-deep - Full agent framework</li> <li>pydantic-ai-todo - Task planning toolset</li> <li>subagents-pydantic-ai - Multi-agent orchestration</li> <li>summarization-pydantic-ai - Context management</li> </ul>"},{"location":"getting-help/#faq","title":"FAQ","text":""},{"location":"getting-help/#which-backend-should-i-use","title":"Which backend should I use?","text":"Use Case Backend Unit tests <code>StateBackend</code> (in-memory, fast) Local CLI tools <code>LocalBackend</code> (persistent files) Multi-user web apps <code>DockerSandbox</code> + <code>SessionManager</code> Untrusted code <code>DockerSandbox</code> (isolated) Mixed sources <code>CompositeBackend</code> (route by path)"},{"location":"getting-help/#how-do-i-run-without-docker","title":"How do I run without Docker?","text":"<p>Use <code>LocalBackend</code> for local filesystem operations:</p> Python<pre><code>from pydantic_ai_backends import LocalBackend\n\nbackend = LocalBackend(root_dir=\"./workspace\")\n</code></pre> <p>For testing, use <code>StateBackend</code>:</p> Python<pre><code>from pydantic_ai_backends import StateBackend\n\nbackend = StateBackend()  # In-memory, no side effects\n</code></pre>"},{"location":"getting-help/#how-do-i-disable-shell-execution","title":"How do I disable shell execution?","text":"<p>For <code>LocalBackend</code>:</p> Python<pre><code>backend = LocalBackend(root_dir=\"./workspace\", enable_execute=False)\n</code></pre> <p>For the console toolset:</p> Python<pre><code>toolset = create_console_toolset(include_execute=False)\n</code></pre>"},{"location":"getting-help/#how-do-i-restrict-file-access","title":"How do I restrict file access?","text":"<p>Use the permission system:</p> Python<pre><code>from pydantic_ai_backends import LocalBackend\nfrom pydantic_ai_backends.permissions import READONLY_RULESET\n\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=READONLY_RULESET)\n</code></pre> <p>Or use <code>allowed_directories</code>:</p> Python<pre><code>backend = LocalBackend(\n    root_dir=\"/workspace\",\n    allowed_directories=[\"/workspace\", \"/shared\"],\n)\n</code></pre>"},{"location":"getting-help/#docker-container-wont-start","title":"Docker container won't start","text":"<ol> <li>Ensure Docker is running: <code>docker info</code></li> <li>Check image exists: <code>docker images</code></li> <li>Pull if needed: <code>docker pull python:3.12-slim</code></li> <li>On Linux, check permissions: <code>sudo usermod -aG docker $USER</code></li> </ol>"},{"location":"getting-help/#contributing","title":"Contributing","text":"<p>We welcome contributions! See our Contributing Guide for details.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>uv (recommended) or pip</li> </ul>"},{"location":"installation/#install-with-uv-recommended","title":"Install with uv (recommended)","text":"Bash<pre><code>uv add pydantic-ai-backend\n</code></pre>"},{"location":"installation/#install-with-pip","title":"Install with pip","text":"Bash<pre><code>pip install pydantic-ai-backend\n</code></pre>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"installation/#console-toolset","title":"Console Toolset","text":"<p>For the ready-to-use pydantic-ai toolset:</p> Bash<pre><code>uv add pydantic-ai-backend[console]\n# or\npip install pydantic-ai-backend[console]\n</code></pre>"},{"location":"installation/#docker-sandbox","title":"Docker Sandbox","text":"<p>For isolated code execution in Docker containers:</p> Bash<pre><code>uv add pydantic-ai-backend[docker]\n# or\npip install pydantic-ai-backend[docker]\n</code></pre>"},{"location":"installation/#all-dependencies","title":"All Dependencies","text":"Bash<pre><code>uv add pydantic-ai-backend[console,docker]\n# or\npip install pydantic-ai-backend[console,docker]\n</code></pre>"},{"location":"installation/#environment-setup","title":"Environment Setup","text":""},{"location":"installation/#api-key-for-console-toolset","title":"API Key (for console toolset)","text":"<p>If using the console toolset with pydantic-ai, set your model provider's API key:</p> OpenAIAnthropic Bash<pre><code>export OPENAI_API_KEY=your-api-key\n</code></pre> Bash<pre><code>export ANTHROPIC_API_KEY=your-api-key\n</code></pre>"},{"location":"installation/#docker-for-dockersandbox","title":"Docker (for DockerSandbox)","text":"<p>For using <code>DockerSandbox</code>:</p> <ol> <li>Install Docker: Get Docker</li> <li>Ensure Docker daemon is running</li> <li>Pull a base image:</li> </ol> Bash<pre><code>docker pull python:3.12-slim\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":""},{"location":"installation/#basic-localbackend","title":"Basic (LocalBackend)","text":"Python<pre><code>from pydantic_ai_backends import LocalBackend\n\nbackend = LocalBackend(root_dir=\".\")\nbackend.write(\"test.txt\", \"Hello from pydantic-ai-backend!\")\nprint(backend.read(\"test.txt\"))\n</code></pre>"},{"location":"installation/#with-console-toolset","title":"With Console Toolset","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\nbackend = LocalBackend(root_dir=\".\", enable_execute=False)\ntoolset = create_console_toolset(include_execute=False)\n\nagent = Agent(\"openai:gpt-4o-mini\", deps_type=Deps)\nagent = agent.with_toolset(toolset)\n\nresult = agent.run_sync(\"List files in current directory\", deps=Deps(backend=backend))\nprint(result.output)\n</code></pre>"},{"location":"installation/#with-docker","title":"With Docker","text":"Python<pre><code>from pydantic_ai_backends import DockerSandbox\n\nsandbox = DockerSandbox(image=\"python:3.12-slim\")\nsandbox.write(\"/workspace/hello.py\", \"print('Hello from Docker!')\")\nresult = sandbox.execute(\"python /workspace/hello.py\")\nprint(result.output)  # \"Hello from Docker!\"\nsandbox.stop()\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#import-errors","title":"Import Errors","text":"<p>Ensure you have the correct Python version:</p> Bash<pre><code>python --version  # Should be 3.10+\n</code></pre>"},{"location":"installation/#docker-permission-denied","title":"Docker Permission Denied","text":"<p>On Linux, add your user to the docker group:</p> Bash<pre><code>sudo usermod -aG docker $USER\n</code></pre> <p>Then log out and back in.</p>"},{"location":"installation/#pydantic-ai-not-found","title":"pydantic-ai Not Found","text":"<p>If using console toolset, install with the <code>[console]</code> extra:</p> Bash<pre><code>pip install pydantic-ai-backend[console]\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<ul> <li>Core Concepts - Learn the fundamentals</li> <li>Local Backend Example - Start with local files</li> <li>API Reference - Complete API documentation</li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for pydantic-ai-backend.</p>"},{"location":"api/#quick-example","title":"Quick Example","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\nbackend = LocalBackend(root_dir=\".\")\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps).with_toolset(toolset)\n\nresult = agent.run_sync(\"Create hello.py and run it\", deps=Deps(backend=backend))\n</code></pre>"},{"location":"api/#modules","title":"Modules","text":"Module Description Backends LocalBackend, StateBackend, CompositeBackend Docker DockerSandbox, SessionManager, RuntimeConfig Toolsets Console toolset for pydantic-ai Types Type definitions"},{"location":"api/#import-reference","title":"Import Reference","text":"Python<pre><code># Toolset for pydantic-ai agents (requires [console] extra)\nfrom pydantic_ai_backends import (\n    create_console_toolset,\n    get_console_system_prompt,\n    ConsoleDeps,\n)\n\n# Backends\nfrom pydantic_ai_backends import (\n    LocalBackend,\n    StateBackend,\n    CompositeBackend,\n)\n\n# Docker (requires [docker] extra)\nfrom pydantic_ai_backends import (\n    DockerSandbox,\n    SessionManager,\n    RuntimeConfig,\n    BUILTIN_RUNTIMES,\n)\n\n# Types\nfrom pydantic_ai_backends import (\n    FileInfo,\n    WriteResult,\n    EditResult,\n    ExecuteResponse,\n    GrepMatch,\n)\n\n# Protocols\nfrom pydantic_ai_backends import (\n    BackendProtocol,\n    SandboxProtocol,\n)\n</code></pre>"},{"location":"api/#protocols","title":"Protocols","text":""},{"location":"api/#backendprotocol","title":"BackendProtocol","text":"<p>All backends implement this interface:</p> Python<pre><code>class BackendProtocol(Protocol):\n    def ls_info(self, path: str) -&gt; list[FileInfo]: ...\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str: ...\n    def write(self, path: str, content: str | bytes) -&gt; WriteResult: ...\n    def edit(self, path: str, old: str, new: str, replace_all: bool = False) -&gt; EditResult: ...\n    def glob_info(self, pattern: str, path: str = \".\") -&gt; list[FileInfo]: ...\n    def grep_raw(\n        self,\n        pattern: str,\n        path: str | None = None,\n        glob: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str: ...\n</code></pre>"},{"location":"api/#sandboxprotocol","title":"SandboxProtocol","text":"<p>Extends BackendProtocol with execution:</p> Python<pre><code>class SandboxProtocol(BackendProtocol, Protocol):\n    def execute(self, command: str, timeout: int | None = None) -&gt; ExecuteResponse: ...\n    @property\n    def id(self) -&gt; str: ...\n</code></pre>"},{"location":"api/backends/","title":"Backends API","text":""},{"location":"api/backends/#localbackend","title":"LocalBackend","text":""},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend","title":"<code>pydantic_ai_backends.backends.local.LocalBackend</code>","text":"<p>Local filesystem backend with optional shell execution.</p> <p>Combines file operations (Python native) with optional shell command execution (subprocess). File operations can be restricted to specific directories using <code>allowed_directories</code>.</p> Example Python<pre><code>from pydantic_ai_backends import LocalBackend\n\n# Full access with shell execution\nbackend = LocalBackend(root_dir=\"/workspace\")\nbackend.write(\"/src/app.py\", \"print('hello')\")\nresult = backend.execute(\"python /src/app.py\")\n\n# Restricted directories, no shell\nbackend = LocalBackend(\n    allowed_directories=[\"/home/user/project\"],\n    enable_execute=False,\n)\n</code></pre> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>class LocalBackend:\n    \"\"\"Local filesystem backend with optional shell execution.\n\n    Combines file operations (Python native) with optional shell command\n    execution (subprocess). File operations can be restricted to specific\n    directories using `allowed_directories`.\n\n    Example:\n        ```python\n        from pydantic_ai_backends import LocalBackend\n\n        # Full access with shell execution\n        backend = LocalBackend(root_dir=\"/workspace\")\n        backend.write(\"/src/app.py\", \"print('hello')\")\n        result = backend.execute(\"python /src/app.py\")\n\n        # Restricted directories, no shell\n        backend = LocalBackend(\n            allowed_directories=[\"/home/user/project\"],\n            enable_execute=False,\n        )\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        root_dir: str | Path | None = None,\n        allowed_directories: list[str] | None = None,\n        enable_execute: bool = True,\n        sandbox_id: str | None = None,\n        permissions: PermissionRuleset | None = None,\n        ask_callback: AskCallback | None = None,\n        ask_fallback: AskFallback = \"error\",\n    ):\n        \"\"\"Initialize the backend.\n\n        Args:\n            root_dir: Base directory for file operations. If not provided,\n                uses first allowed_directory or current working directory.\n            allowed_directories: List of directories that file operations are\n                restricted to. If None, only root_dir is accessible.\n                Paths are resolved to absolute paths.\n            enable_execute: Whether shell execution is enabled. Default True.\n            sandbox_id: Unique identifier for this backend instance.\n            permissions: Optional permission ruleset for fine-grained access control.\n                If provided, operations are checked against this ruleset after\n                the allowed_directories check passes.\n            ask_callback: Async callback for \"ask\" permission actions. Receives\n                (operation, target, reason) and returns True to allow.\n            ask_fallback: What to do when ask_callback is None but needed.\n                \"deny\" denies the operation, \"error\" raises PermissionError.\n        \"\"\"\n        self._id = sandbox_id or str(uuid.uuid4())\n        self._enable_execute = enable_execute\n        self._permissions = permissions\n        self._ask_callback = ask_callback\n        self._ask_fallback = ask_fallback\n        self._permission_checker: PermissionChecker | None = None\n\n        # Initialize permission checker if ruleset provided\n        if permissions is not None:\n            from pydantic_ai_backends.permissions.checker import PermissionChecker\n\n            self._permission_checker = PermissionChecker(\n                ruleset=permissions,\n                ask_callback=ask_callback,\n                ask_fallback=ask_fallback,\n            )\n\n        # Resolve allowed directories\n        self._allowed_directories: list[Path] | None = None\n        if allowed_directories is not None:\n            self._allowed_directories = [Path(d).resolve() for d in allowed_directories]\n            # Create directories if they don't exist\n            for d in self._allowed_directories:\n                d.mkdir(parents=True, exist_ok=True)\n\n        # Resolve root directory\n        if root_dir is not None:\n            self._root = Path(root_dir).resolve()\n        elif self._allowed_directories:\n            self._root = self._allowed_directories[0]\n        else:\n            self._root = Path.cwd()  # pragma: no cover\n\n        # Ensure root exists\n        self._root.mkdir(parents=True, exist_ok=True)\n\n        # If no allowed_directories specified, restrict to root_dir only\n        if self._allowed_directories is None:\n            self._allowed_directories = [self._root]\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Unique identifier for this backend.\"\"\"\n        return self._id\n\n    @property\n    def root_dir(self) -&gt; Path:\n        \"\"\"Get the root directory.\"\"\"\n        return self._root\n\n    @property\n    def execute_enabled(self) -&gt; bool:\n        \"\"\"Whether shell execution is enabled.\"\"\"\n        return self._enable_execute\n\n    @property\n    def permissions(self) -&gt; PermissionRuleset | None:\n        \"\"\"The permission ruleset for this backend, if any.\"\"\"\n        return self._permissions\n\n    @property\n    def permission_checker(self) -&gt; PermissionChecker | None:\n        \"\"\"The permission checker for this backend, if any.\"\"\"\n        return self._permission_checker\n\n    def _check_permission_sync(self, operation: PermissionOperation, target: str) -&gt; str | None:\n        \"\"\"Check permission synchronously.\n\n        Returns None if allowed, or an error message if denied.\n        For \"ask\" actions, returns an error since this is sync.\n        \"\"\"\n        if self._permission_checker is None:\n            return None\n\n        from pydantic_ai_backends.permissions.checker import (\n            PermissionError,\n        )\n\n        action = self._permission_checker.check_sync(operation, target)\n        if action == \"allow\":\n            return None\n        if action == \"deny\":\n            rule = self._permission_checker._find_matching_rule(operation, target)\n            if rule and rule.description:\n                return f\"Permission denied: {rule.description}\"\n            return f\"Permission denied for {operation} on '{target}'\"\n        # action == \"ask\" - in sync context, we can't ask\n        if self._ask_fallback == \"deny\":\n            return f\"Permission denied for {operation} on '{target}' (approval required)\"\n        # ask_fallback == \"error\"\n        raise PermissionError(operation, target, \"Approval required but no callback\")\n\n    def _validate_path(self, path: str) -&gt; Path:\n        \"\"\"Validate and resolve path within allowed directories.\n\n        Args:\n            path: Path to validate (absolute or relative to root).\n\n        Returns:\n            Resolved absolute Path.\n\n        Raises:\n            PermissionError: If path is outside allowed directories.\n        \"\"\"\n        # Handle relative paths\n        if not Path(path).is_absolute():\n            resolved = (self._root / path).resolve()\n        else:\n            resolved = Path(path).resolve()\n\n        # Check against allowed directories\n        assert self._allowed_directories is not None\n        for allowed in self._allowed_directories:\n            try:\n                resolved.relative_to(allowed)\n                return resolved\n            except ValueError:\n                continue\n\n        # Path not in any allowed directory\n        allowed_str = \", \".join(str(d) for d in self._allowed_directories)\n        raise PermissionError(\n            f\"Access denied: '{path}' is outside allowed directories ({allowed_str})\"\n        )\n\n    def ls_info(self, path: str) -&gt; list[FileInfo]:\n        \"\"\"List files and directories at the given path.\"\"\"\n        try:\n            full_path = self._validate_path(path)\n        except PermissionError:  # pragma: no cover\n            return []\n\n        if not full_path.exists():  # pragma: no cover\n            return []\n\n        if full_path.is_file():  # pragma: no cover\n            return [\n                FileInfo(\n                    name=full_path.name,\n                    path=str(full_path),\n                    is_dir=False,\n                    size=full_path.stat().st_size,\n                )\n            ]\n\n        results: list[FileInfo] = []\n        try:\n            for entry in full_path.iterdir():\n                try:\n                    # Validate each entry is within allowed dirs\n                    self._validate_path(str(entry))\n                    results.append(\n                        FileInfo(\n                            name=entry.name,\n                            path=str(entry),\n                            is_dir=entry.is_dir(),\n                            size=entry.stat().st_size if entry.is_file() else None,\n                        )\n                    )\n                except PermissionError:  # pragma: no cover\n                    continue  # Skip entries outside allowed directories\n        except PermissionError:  # pragma: no cover\n            return []\n\n        return sorted(results, key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n\n    def _read_bytes(self, path: str) -&gt; bytes:  # pragma: no cover\n        \"\"\"Read raw bytes from a file.\"\"\"\n        try:\n            full_path = self._validate_path(path)\n        except PermissionError:\n            return b\"\"\n\n        if not full_path.exists() or not full_path.is_file():\n            return b\"\"\n\n        try:\n            return full_path.read_bytes()\n        except (PermissionError, OSError):\n            return b\"\"\n\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n        \"\"\"Read file content with line numbers.\"\"\"\n        try:\n            full_path = self._validate_path(path)\n        except PermissionError as e:\n            return f\"Error: {e}\"\n\n        # Check permissions\n        perm_error = self._check_permission_sync(\"read\", str(full_path))\n        if perm_error:\n            return f\"Error: {perm_error}\"\n\n        if not full_path.exists():\n            return f\"Error: File '{path}' not found\"\n\n        if full_path.is_dir():  # pragma: no cover\n            return f\"Error: '{path}' is a directory\"\n\n        try:\n            with open(full_path, encoding=\"utf-8\", errors=\"replace\") as f:\n                lines = f.readlines()\n        except PermissionError:  # pragma: no cover\n            return f\"Error: Permission denied for '{path}'\"\n        except OSError as e:  # pragma: no cover\n            return f\"Error: {e}\"\n\n        total_lines = len(lines)\n\n        if offset &gt;= total_lines:  # pragma: no cover\n            return f\"Error: Offset {offset} exceeds file length ({total_lines} lines)\"\n\n        end = min(offset + limit, total_lines)\n        result_lines = []\n\n        for i in range(offset, end):\n            line_num = i + 1\n            line = lines[i].rstrip(\"\\n\\r\")\n            result_lines.append(f\"{line_num:&gt;6}\\t{line}\")\n\n        result = \"\\n\".join(result_lines)\n\n        if end &lt; total_lines:\n            result += f\"\\n\\n... ({total_lines - end} more lines)\"\n\n        return result\n\n    def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n        \"\"\"Write content to a file.\"\"\"\n        try:\n            full_path = self._validate_path(path)\n        except PermissionError as e:\n            return WriteResult(error=str(e))\n\n        # Check permissions\n        perm_error = self._check_permission_sync(\"write\", str(full_path))\n        if perm_error:\n            return WriteResult(error=perm_error)\n\n        try:\n            full_path.parent.mkdir(parents=True, exist_ok=True)\n\n            if isinstance(content, bytes):  # pragma: no cover\n                full_path.write_bytes(content)\n            else:\n                full_path.write_text(content, encoding=\"utf-8\")\n\n            return WriteResult(path=str(full_path))\n        except PermissionError:  # pragma: no cover\n            return WriteResult(error=f\"Permission denied for '{path}'\")\n        except OSError as e:  # pragma: no cover\n            return WriteResult(error=str(e))\n\n    def edit(\n        self, path: str, old_string: str, new_string: str, replace_all: bool = False\n    ) -&gt; EditResult:\n        \"\"\"Edit a file by replacing strings.\"\"\"\n        try:\n            full_path = self._validate_path(path)\n        except PermissionError as e:  # pragma: no cover\n            return EditResult(error=str(e))\n\n        # Check permissions\n        perm_error = self._check_permission_sync(\"edit\", str(full_path))\n        if perm_error:\n            return EditResult(error=perm_error)\n\n        if not full_path.exists():\n            return EditResult(error=f\"File '{path}' not found\")\n\n        try:\n            content = full_path.read_text(encoding=\"utf-8\")\n        except PermissionError:  # pragma: no cover\n            return EditResult(error=f\"Permission denied for '{path}'\")\n        except OSError as e:  # pragma: no cover\n            return EditResult(error=str(e))\n\n        occurrences = content.count(old_string)\n\n        if occurrences == 0:  # pragma: no cover\n            return EditResult(error=f\"String '{old_string}' not found in file\")\n\n        if occurrences &gt; 1 and not replace_all:  # pragma: no cover\n            return EditResult(\n                error=f\"String '{old_string}' found {occurrences} times. \"\n                \"Use replace_all=True to replace all, or provide more context.\"\n            )\n\n        if replace_all:  # pragma: no cover\n            new_content = content.replace(old_string, new_string)\n        else:\n            new_content = content.replace(old_string, new_string, 1)\n\n        try:\n            full_path.write_text(new_content, encoding=\"utf-8\")\n            return EditResult(path=str(full_path), occurrences=occurrences if replace_all else 1)\n        except PermissionError:  # pragma: no cover\n            return EditResult(error=f\"Permission denied for '{path}'\")\n        except OSError as e:  # pragma: no cover\n            return EditResult(error=str(e))\n\n    def glob_info(self, pattern: str, path: str = \".\") -&gt; list[FileInfo]:\n        \"\"\"Find files matching a glob pattern.\"\"\"\n        try:\n            base_path = self._validate_path(path)\n        except PermissionError:  # pragma: no cover\n            return []\n\n        if not base_path.exists():  # pragma: no cover\n            return []\n\n        results: list[FileInfo] = []\n\n        try:\n            for match in base_path.glob(pattern):  # pragma: no branch\n                if match.is_file():\n                    try:\n                        self._validate_path(str(match))\n                        results.append(\n                            FileInfo(\n                                name=match.name,\n                                path=str(match),\n                                is_dir=False,\n                                size=match.stat().st_size,\n                            )\n                        )\n                    except PermissionError:  # pragma: no cover\n                        continue\n        except (PermissionError, OSError):  # pragma: no cover\n            pass\n\n        return sorted(results, key=lambda x: x[\"path\"])\n\n    def grep_raw(\n        self,\n        pattern: str,\n        path: str | None = None,\n        glob: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Search for pattern in files.\n\n        Uses ripgrep if available, falls back to Python regex.\n        \"\"\"\n        search_path = path or str(self._root)\n\n        try:\n            validated_path = self._validate_path(search_path)\n        except PermissionError as e:  # pragma: no cover\n            return str(e)\n\n        # Try ripgrep first when searching directories for better performance\n        use_ripgrep = shutil.which(\"rg\") is not None and not validated_path.is_file()\n        if use_ripgrep:  # pragma: no cover\n            return self._grep_ripgrep(pattern, validated_path, glob, ignore_hidden)\n\n        return self._grep_python(pattern, validated_path, glob, ignore_hidden)  # pragma: no cover\n\n    def _grep_ripgrep(  # pragma: no cover\n        self, pattern: str, search_path: Path, glob: str | None = None, ignore_hidden: bool = True\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Use ripgrep for fast searching.\"\"\"\n        cmd = [\"rg\", \"--line-number\", \"--no-heading\", pattern]\n\n        if glob:\n            cmd.extend([\"--glob\", glob])\n\n        if not ignore_hidden:\n            cmd.append(\"--hidden\")\n\n        cmd.append(\".\")\n\n        try:\n            result = subprocess.run(\n                cmd,\n                cwd=search_path,\n                capture_output=True,\n                text=True,\n                timeout=30,\n            )\n        except subprocess.TimeoutExpired:\n            return \"Error: Search timed out\"\n        except OSError as e:\n            return f\"Error: {e}\"\n\n        results: list[GrepMatch] = []\n\n        for line in result.stdout.strip().split(\"\\n\"):\n            if not line:\n                continue\n\n            parts = line.split(\":\", 2)\n            if len(parts) &gt;= 3:\n                file_path = parts[0]\n                try:\n                    line_num = int(parts[1])\n                except ValueError:\n                    continue\n                content = parts[2]\n\n                # Convert to absolute path and validate\n                try:\n                    base_path = search_path.parent if search_path.is_file() else search_path\n                    full_path = (base_path / file_path).resolve()\n                    self._validate_path(str(full_path))\n                    results.append(\n                        GrepMatch(\n                            path=str(full_path),\n                            line_number=line_num,\n                            line=content,\n                        )\n                    )\n                except PermissionError:\n                    continue\n\n        return results\n\n    def _grep_python(  # pragma: no cover\n        self,\n        pattern: str,\n        search_path: Path,\n        glob_pattern: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Use Python regex for searching (fallback).\"\"\"\n        try:\n            regex = re.compile(pattern)\n        except re.error as e:\n            return f\"Error: Invalid regex pattern: {e}\"\n\n        if not search_path.exists():\n            return f\"Error: Path '{search_path}' not found\"\n\n        results: list[GrepMatch] = []\n\n        if search_path.is_file():\n            files = [search_path]\n        else:\n            if glob_pattern:\n                files = list(search_path.glob(glob_pattern))\n            else:\n                files = list(search_path.rglob(\"*\"))\n            if ignore_hidden:\n                files = [f for f in files if not any(part.startswith(\".\") for part in f.parts)]\n\n        for file_path in files:\n            if not file_path.is_file():\n                continue\n\n            try:\n                self._validate_path(str(file_path))\n            except PermissionError:\n                continue\n\n            try:\n                with open(file_path, encoding=\"utf-8\", errors=\"replace\") as f:\n                    for i, line in enumerate(f):\n                        if regex.search(line):\n                            results.append(\n                                GrepMatch(\n                                    path=str(file_path),\n                                    line_number=i + 1,\n                                    line=line.rstrip(\"\\n\\r\"),\n                                )\n                            )\n            except (PermissionError, OSError):\n                continue\n\n        return results\n\n    def execute(self, command: str, timeout: int | None = None) -&gt; ExecuteResponse:\n        \"\"\"Execute a shell command.\n\n        Args:\n            command: Command to execute.\n            timeout: Maximum execution time in seconds (default 120).\n\n        Returns:\n            ExecuteResponse with output, exit code, and truncation status.\n\n        Raises:\n            RuntimeError: If execute is disabled for this backend.\n        \"\"\"\n        if not self._enable_execute:\n            raise RuntimeError(\n                \"Shell execution is disabled for this backend. \"\n                \"Initialize with enable_execute=True to enable.\"\n            )\n\n        # Check permissions\n        perm_error = self._check_permission_sync(\"execute\", command)\n        if perm_error:\n            return ExecuteResponse(\n                output=f\"Error: {perm_error}\",\n                exit_code=1,\n                truncated=False,\n            )\n\n        try:\n            result = subprocess.run(\n                [\"sh\", \"-c\", command],\n                cwd=self._root,\n                capture_output=True,\n                text=True,\n                timeout=timeout or 120,\n            )\n\n            output = result.stdout + result.stderr\n\n            # Truncate if too long\n            max_output = 100000\n            truncated = len(output) &gt; max_output\n            if truncated:  # pragma: no cover\n                output = output[:max_output]\n\n            return ExecuteResponse(\n                output=output,\n                exit_code=result.returncode,\n                truncated=truncated,\n            )\n        except subprocess.TimeoutExpired:\n            return ExecuteResponse(\n                output=\"Error: Command timed out\",\n                exit_code=124,\n                truncated=False,\n            )\n        except Exception as e:  # pragma: no cover\n            return ExecuteResponse(\n                output=f\"Error: {e}\",\n                exit_code=1,\n                truncated=False,\n            )\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.execute_enabled","title":"<code>execute_enabled</code>  <code>property</code>","text":"<p>Whether shell execution is enabled.</p>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.__init__","title":"<code>__init__(root_dir=None, allowed_directories=None, enable_execute=True, sandbox_id=None, permissions=None, ask_callback=None, ask_fallback='error')</code>","text":"<p>Initialize the backend.</p> <p>Parameters:</p> Name Type Description Default <code>root_dir</code> <code>str | Path | None</code> <p>Base directory for file operations. If not provided, uses first allowed_directory or current working directory.</p> <code>None</code> <code>allowed_directories</code> <code>list[str] | None</code> <p>List of directories that file operations are restricted to. If None, only root_dir is accessible. Paths are resolved to absolute paths.</p> <code>None</code> <code>enable_execute</code> <code>bool</code> <p>Whether shell execution is enabled. Default True.</p> <code>True</code> <code>sandbox_id</code> <code>str | None</code> <p>Unique identifier for this backend instance.</p> <code>None</code> <code>permissions</code> <code>PermissionRuleset | None</code> <p>Optional permission ruleset for fine-grained access control. If provided, operations are checked against this ruleset after the allowed_directories check passes.</p> <code>None</code> <code>ask_callback</code> <code>AskCallback | None</code> <p>Async callback for \"ask\" permission actions. Receives (operation, target, reason) and returns True to allow.</p> <code>None</code> <code>ask_fallback</code> <code>AskFallback</code> <p>What to do when ask_callback is None but needed. \"deny\" denies the operation, \"error\" raises PermissionError.</p> <code>'error'</code> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def __init__(\n    self,\n    root_dir: str | Path | None = None,\n    allowed_directories: list[str] | None = None,\n    enable_execute: bool = True,\n    sandbox_id: str | None = None,\n    permissions: PermissionRuleset | None = None,\n    ask_callback: AskCallback | None = None,\n    ask_fallback: AskFallback = \"error\",\n):\n    \"\"\"Initialize the backend.\n\n    Args:\n        root_dir: Base directory for file operations. If not provided,\n            uses first allowed_directory or current working directory.\n        allowed_directories: List of directories that file operations are\n            restricted to. If None, only root_dir is accessible.\n            Paths are resolved to absolute paths.\n        enable_execute: Whether shell execution is enabled. Default True.\n        sandbox_id: Unique identifier for this backend instance.\n        permissions: Optional permission ruleset for fine-grained access control.\n            If provided, operations are checked against this ruleset after\n            the allowed_directories check passes.\n        ask_callback: Async callback for \"ask\" permission actions. Receives\n            (operation, target, reason) and returns True to allow.\n        ask_fallback: What to do when ask_callback is None but needed.\n            \"deny\" denies the operation, \"error\" raises PermissionError.\n    \"\"\"\n    self._id = sandbox_id or str(uuid.uuid4())\n    self._enable_execute = enable_execute\n    self._permissions = permissions\n    self._ask_callback = ask_callback\n    self._ask_fallback = ask_fallback\n    self._permission_checker: PermissionChecker | None = None\n\n    # Initialize permission checker if ruleset provided\n    if permissions is not None:\n        from pydantic_ai_backends.permissions.checker import PermissionChecker\n\n        self._permission_checker = PermissionChecker(\n            ruleset=permissions,\n            ask_callback=ask_callback,\n            ask_fallback=ask_fallback,\n        )\n\n    # Resolve allowed directories\n    self._allowed_directories: list[Path] | None = None\n    if allowed_directories is not None:\n        self._allowed_directories = [Path(d).resolve() for d in allowed_directories]\n        # Create directories if they don't exist\n        for d in self._allowed_directories:\n            d.mkdir(parents=True, exist_ok=True)\n\n    # Resolve root directory\n    if root_dir is not None:\n        self._root = Path(root_dir).resolve()\n    elif self._allowed_directories:\n        self._root = self._allowed_directories[0]\n    else:\n        self._root = Path.cwd()  # pragma: no cover\n\n    # Ensure root exists\n    self._root.mkdir(parents=True, exist_ok=True)\n\n    # If no allowed_directories specified, restrict to root_dir only\n    if self._allowed_directories is None:\n        self._allowed_directories = [self._root]\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.ls_info","title":"<code>ls_info(path)</code>","text":"<p>List files and directories at the given path.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def ls_info(self, path: str) -&gt; list[FileInfo]:\n    \"\"\"List files and directories at the given path.\"\"\"\n    try:\n        full_path = self._validate_path(path)\n    except PermissionError:  # pragma: no cover\n        return []\n\n    if not full_path.exists():  # pragma: no cover\n        return []\n\n    if full_path.is_file():  # pragma: no cover\n        return [\n            FileInfo(\n                name=full_path.name,\n                path=str(full_path),\n                is_dir=False,\n                size=full_path.stat().st_size,\n            )\n        ]\n\n    results: list[FileInfo] = []\n    try:\n        for entry in full_path.iterdir():\n            try:\n                # Validate each entry is within allowed dirs\n                self._validate_path(str(entry))\n                results.append(\n                    FileInfo(\n                        name=entry.name,\n                        path=str(entry),\n                        is_dir=entry.is_dir(),\n                        size=entry.stat().st_size if entry.is_file() else None,\n                    )\n                )\n            except PermissionError:  # pragma: no cover\n                continue  # Skip entries outside allowed directories\n    except PermissionError:  # pragma: no cover\n        return []\n\n    return sorted(results, key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.read","title":"<code>read(path, offset=0, limit=2000)</code>","text":"<p>Read file content with line numbers.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n    \"\"\"Read file content with line numbers.\"\"\"\n    try:\n        full_path = self._validate_path(path)\n    except PermissionError as e:\n        return f\"Error: {e}\"\n\n    # Check permissions\n    perm_error = self._check_permission_sync(\"read\", str(full_path))\n    if perm_error:\n        return f\"Error: {perm_error}\"\n\n    if not full_path.exists():\n        return f\"Error: File '{path}' not found\"\n\n    if full_path.is_dir():  # pragma: no cover\n        return f\"Error: '{path}' is a directory\"\n\n    try:\n        with open(full_path, encoding=\"utf-8\", errors=\"replace\") as f:\n            lines = f.readlines()\n    except PermissionError:  # pragma: no cover\n        return f\"Error: Permission denied for '{path}'\"\n    except OSError as e:  # pragma: no cover\n        return f\"Error: {e}\"\n\n    total_lines = len(lines)\n\n    if offset &gt;= total_lines:  # pragma: no cover\n        return f\"Error: Offset {offset} exceeds file length ({total_lines} lines)\"\n\n    end = min(offset + limit, total_lines)\n    result_lines = []\n\n    for i in range(offset, end):\n        line_num = i + 1\n        line = lines[i].rstrip(\"\\n\\r\")\n        result_lines.append(f\"{line_num:&gt;6}\\t{line}\")\n\n    result = \"\\n\".join(result_lines)\n\n    if end &lt; total_lines:\n        result += f\"\\n\\n... ({total_lines - end} more lines)\"\n\n    return result\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.write","title":"<code>write(path, content)</code>","text":"<p>Write content to a file.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n    \"\"\"Write content to a file.\"\"\"\n    try:\n        full_path = self._validate_path(path)\n    except PermissionError as e:\n        return WriteResult(error=str(e))\n\n    # Check permissions\n    perm_error = self._check_permission_sync(\"write\", str(full_path))\n    if perm_error:\n        return WriteResult(error=perm_error)\n\n    try:\n        full_path.parent.mkdir(parents=True, exist_ok=True)\n\n        if isinstance(content, bytes):  # pragma: no cover\n            full_path.write_bytes(content)\n        else:\n            full_path.write_text(content, encoding=\"utf-8\")\n\n        return WriteResult(path=str(full_path))\n    except PermissionError:  # pragma: no cover\n        return WriteResult(error=f\"Permission denied for '{path}'\")\n    except OSError as e:  # pragma: no cover\n        return WriteResult(error=str(e))\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.edit","title":"<code>edit(path, old_string, new_string, replace_all=False)</code>","text":"<p>Edit a file by replacing strings.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def edit(\n    self, path: str, old_string: str, new_string: str, replace_all: bool = False\n) -&gt; EditResult:\n    \"\"\"Edit a file by replacing strings.\"\"\"\n    try:\n        full_path = self._validate_path(path)\n    except PermissionError as e:  # pragma: no cover\n        return EditResult(error=str(e))\n\n    # Check permissions\n    perm_error = self._check_permission_sync(\"edit\", str(full_path))\n    if perm_error:\n        return EditResult(error=perm_error)\n\n    if not full_path.exists():\n        return EditResult(error=f\"File '{path}' not found\")\n\n    try:\n        content = full_path.read_text(encoding=\"utf-8\")\n    except PermissionError:  # pragma: no cover\n        return EditResult(error=f\"Permission denied for '{path}'\")\n    except OSError as e:  # pragma: no cover\n        return EditResult(error=str(e))\n\n    occurrences = content.count(old_string)\n\n    if occurrences == 0:  # pragma: no cover\n        return EditResult(error=f\"String '{old_string}' not found in file\")\n\n    if occurrences &gt; 1 and not replace_all:  # pragma: no cover\n        return EditResult(\n            error=f\"String '{old_string}' found {occurrences} times. \"\n            \"Use replace_all=True to replace all, or provide more context.\"\n        )\n\n    if replace_all:  # pragma: no cover\n        new_content = content.replace(old_string, new_string)\n    else:\n        new_content = content.replace(old_string, new_string, 1)\n\n    try:\n        full_path.write_text(new_content, encoding=\"utf-8\")\n        return EditResult(path=str(full_path), occurrences=occurrences if replace_all else 1)\n    except PermissionError:  # pragma: no cover\n        return EditResult(error=f\"Permission denied for '{path}'\")\n    except OSError as e:  # pragma: no cover\n        return EditResult(error=str(e))\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.glob_info","title":"<code>glob_info(pattern, path='.')</code>","text":"<p>Find files matching a glob pattern.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def glob_info(self, pattern: str, path: str = \".\") -&gt; list[FileInfo]:\n    \"\"\"Find files matching a glob pattern.\"\"\"\n    try:\n        base_path = self._validate_path(path)\n    except PermissionError:  # pragma: no cover\n        return []\n\n    if not base_path.exists():  # pragma: no cover\n        return []\n\n    results: list[FileInfo] = []\n\n    try:\n        for match in base_path.glob(pattern):  # pragma: no branch\n            if match.is_file():\n                try:\n                    self._validate_path(str(match))\n                    results.append(\n                        FileInfo(\n                            name=match.name,\n                            path=str(match),\n                            is_dir=False,\n                            size=match.stat().st_size,\n                        )\n                    )\n                except PermissionError:  # pragma: no cover\n                    continue\n    except (PermissionError, OSError):  # pragma: no cover\n        pass\n\n    return sorted(results, key=lambda x: x[\"path\"])\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.grep_raw","title":"<code>grep_raw(pattern, path=None, glob=None, ignore_hidden=True)</code>","text":"<p>Search for pattern in files.</p> <p>Uses ripgrep if available, falls back to Python regex.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def grep_raw(\n    self,\n    pattern: str,\n    path: str | None = None,\n    glob: str | None = None,\n    ignore_hidden: bool = True,\n) -&gt; list[GrepMatch] | str:\n    \"\"\"Search for pattern in files.\n\n    Uses ripgrep if available, falls back to Python regex.\n    \"\"\"\n    search_path = path or str(self._root)\n\n    try:\n        validated_path = self._validate_path(search_path)\n    except PermissionError as e:  # pragma: no cover\n        return str(e)\n\n    # Try ripgrep first when searching directories for better performance\n    use_ripgrep = shutil.which(\"rg\") is not None and not validated_path.is_file()\n    if use_ripgrep:  # pragma: no cover\n        return self._grep_ripgrep(pattern, validated_path, glob, ignore_hidden)\n\n    return self._grep_python(pattern, validated_path, glob, ignore_hidden)  # pragma: no cover\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.local.LocalBackend.execute","title":"<code>execute(command, timeout=None)</code>","text":"<p>Execute a shell command.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>Command to execute.</p> required <code>timeout</code> <code>int | None</code> <p>Maximum execution time in seconds (default 120).</p> <code>None</code> <p>Returns:</p> Type Description <code>ExecuteResponse</code> <p>ExecuteResponse with output, exit code, and truncation status.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If execute is disabled for this backend.</p> Source code in <code>src/pydantic_ai_backends/backends/local.py</code> Python<pre><code>def execute(self, command: str, timeout: int | None = None) -&gt; ExecuteResponse:\n    \"\"\"Execute a shell command.\n\n    Args:\n        command: Command to execute.\n        timeout: Maximum execution time in seconds (default 120).\n\n    Returns:\n        ExecuteResponse with output, exit code, and truncation status.\n\n    Raises:\n        RuntimeError: If execute is disabled for this backend.\n    \"\"\"\n    if not self._enable_execute:\n        raise RuntimeError(\n            \"Shell execution is disabled for this backend. \"\n            \"Initialize with enable_execute=True to enable.\"\n        )\n\n    # Check permissions\n    perm_error = self._check_permission_sync(\"execute\", command)\n    if perm_error:\n        return ExecuteResponse(\n            output=f\"Error: {perm_error}\",\n            exit_code=1,\n            truncated=False,\n        )\n\n    try:\n        result = subprocess.run(\n            [\"sh\", \"-c\", command],\n            cwd=self._root,\n            capture_output=True,\n            text=True,\n            timeout=timeout or 120,\n        )\n\n        output = result.stdout + result.stderr\n\n        # Truncate if too long\n        max_output = 100000\n        truncated = len(output) &gt; max_output\n        if truncated:  # pragma: no cover\n            output = output[:max_output]\n\n        return ExecuteResponse(\n            output=output,\n            exit_code=result.returncode,\n            truncated=truncated,\n        )\n    except subprocess.TimeoutExpired:\n        return ExecuteResponse(\n            output=\"Error: Command timed out\",\n            exit_code=124,\n            truncated=False,\n        )\n    except Exception as e:  # pragma: no cover\n        return ExecuteResponse(\n            output=f\"Error: {e}\",\n            exit_code=1,\n            truncated=False,\n        )\n</code></pre>"},{"location":"api/backends/#statebackend","title":"StateBackend","text":""},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend","title":"<code>pydantic_ai_backends.backends.state.StateBackend</code>","text":"<p>In-memory file storage backend.</p> <p>Files are stored in a dictionary and are ephemeral (lost when the process ends). Useful for testing and temporary file operations.</p> Example Python<pre><code>from pydantic_ai_backends import StateBackend\n\nbackend = StateBackend()\n\n# Write a file\nbackend.write(\"/src/app.py\", \"print('hello')\")\n\n# Read it back\ncontent = backend.read(\"/src/app.py\")\nprint(content)  # \"     1\\tprint('hello')\"\n\n# Search files\nmatches = backend.grep_raw(\"print\")\n</code></pre> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>class StateBackend:\n    \"\"\"In-memory file storage backend.\n\n    Files are stored in a dictionary and are ephemeral (lost when the\n    process ends). Useful for testing and temporary file operations.\n\n    Example:\n        ```python\n        from pydantic_ai_backends import StateBackend\n\n        backend = StateBackend()\n\n        # Write a file\n        backend.write(\"/src/app.py\", \"print('hello')\")\n\n        # Read it back\n        content = backend.read(\"/src/app.py\")\n        print(content)  # \"     1\\\\tprint('hello')\"\n\n        # Search files\n        matches = backend.grep_raw(\"print\")\n        ```\n    \"\"\"\n\n    def __init__(self, files: dict[str, FileData] | None = None):\n        \"\"\"Initialize the backend.\n\n        Args:\n            files: Optional initial file dictionary.\n        \"\"\"\n        self._files: dict[str, FileData] = files if files is not None else {}\n\n    @property\n    def _files_not_hidden(self) -&gt; dict[str, FileData]:\n        return {path: data for path, data in self._files.items() if _is_not_hidden_path(path)}\n\n    @property\n    def files(self) -&gt; dict[str, FileData]:\n        \"\"\"Get the internal files dictionary.\"\"\"\n        return self._files\n\n    def _get_timestamp(self) -&gt; str:\n        \"\"\"Get current ISO 8601 timestamp.\"\"\"\n        return datetime.now(timezone.utc).isoformat()\n\n    def ls_info(self, path: str) -&gt; list[FileInfo]:\n        \"\"\"List files and directories at the given path.\"\"\"\n        error = _validate_path(path)\n        if error:\n            return []\n\n        path = _normalize_path(path)\n\n        # Collect all entries at this level\n        entries: dict[str, FileInfo] = {}\n        prefix = path if path == \"/\" else path + \"/\"\n\n        for file_path, file_data in self._files.items():\n            if not file_path.startswith(prefix) and file_path != path:\n                continue  # pragma: no cover\n\n            # Get the relative path from the directory\n            if file_path == path:\n                # This is a file, not a directory\n                name = file_path.split(\"/\")[-1]\n                entries[name] = FileInfo(\n                    name=name,\n                    path=file_path,\n                    is_dir=False,\n                    size=sum(len(line) for line in file_data[\"content\"]),\n                )\n            else:  # pragma: no cover\n                rel_path = file_path[len(prefix) :]\n                parts = rel_path.split(\"/\")\n                name = parts[0]\n\n                if name not in entries:\n                    if len(parts) == 1:\n                        # Direct child file\n                        entries[name] = FileInfo(\n                            name=name,\n                            path=file_path,\n                            is_dir=False,\n                            size=sum(len(line) for line in file_data[\"content\"]),\n                        )\n                    else:\n                        # Directory (has more parts)\n                        entries[name] = FileInfo(\n                            name=name,\n                            path=prefix + name,\n                            is_dir=True,\n                            size=None,\n                        )\n\n        return sorted(entries.values(), key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n\n    def _read_bytes(self, path: str) -&gt; bytes:\n        \"\"\"Read raw bytes from a file.\n\n        Args:\n            path: File path to read.\n\n        Returns:\n            File content as bytes.\n        \"\"\"\n        error = _validate_path(path)\n        if error:  # pragma: no cover\n            return f\"Error: {error}\".encode()\n\n        path = _normalize_path(path)\n\n        if path not in self._files:\n            return b\"\"\n\n        content = \"\\n\".join(self._files[path][\"content\"])\n        return content.encode(\"utf-8\", errors=\"replace\")  # pragma: no cover\n\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n        \"\"\"Read file content with line numbers.\"\"\"\n        error = _validate_path(path)\n        if error:  # pragma: no cover\n            return f\"Error: {error}\"\n\n        path = _normalize_path(path)\n\n        if path not in self._files:\n            return f\"Error: File '{path}' not found\"\n\n        lines = self._files[path][\"content\"]\n        total_lines = len(lines)\n\n        if offset &gt;= total_lines:\n            return f\"Error: Offset {offset} exceeds file length ({total_lines} lines)\"\n\n        end = min(offset + limit, total_lines)\n        result_lines = []\n\n        for i in range(offset, end):\n            line_num = i + 1  # 1-indexed\n            result_lines.append(f\"{line_num:&gt;6}\\t{lines[i]}\")\n\n        result = \"\\n\".join(result_lines)\n\n        if end &lt; total_lines:\n            result += f\"\\n\\n... ({total_lines - end} more lines)\"\n\n        return result\n\n    def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n        \"\"\"Write content to a file.\"\"\"\n        error = _validate_path(path)\n        if error:\n            return WriteResult(error=error)\n\n        path = _normalize_path(path)\n        now = self._get_timestamp()\n\n        # Convert bytes to string if needed\n        if isinstance(content, bytes):\n            content = content.decode(\"utf-8\", errors=\"replace\")\n\n        # Split content into lines, preserving empty lines\n        lines = content.split(\"\\n\")\n\n        existing = self._files.get(path)\n        created_at = existing[\"created_at\"] if existing else now\n        self._files[path] = FileData(\n            content=lines,\n            created_at=created_at,\n            modified_at=now,\n        )\n\n        return WriteResult(path=path)\n\n    def edit(\n        self, path: str, old_string: str, new_string: str, replace_all: bool = False\n    ) -&gt; EditResult:\n        \"\"\"Edit a file by replacing strings.\"\"\"\n        error = _validate_path(path)\n        if error:\n            return EditResult(error=error)\n\n        path = _normalize_path(path)\n\n        if path not in self._files:\n            return EditResult(error=f\"File '{path}' not found\")  # pragma: no cover\n\n        content = \"\\n\".join(self._files[path][\"content\"])\n        occurrences = content.count(old_string)\n\n        if occurrences == 0:\n            return EditResult(error=f\"String '{old_string}' not found in file\")  # pragma: no cover\n\n        if occurrences &gt; 1 and not replace_all:\n            return EditResult(\n                error=f\"String '{old_string}' found {occurrences} times. \"\n                \"Use replace_all=True to replace all, or provide more context.\"\n            )\n\n        if replace_all:\n            new_content = content.replace(old_string, new_string)\n        else:\n            new_content = content.replace(old_string, new_string, 1)\n\n        self._files[path][\"content\"] = new_content.split(\"\\n\")\n        self._files[path][\"modified_at\"] = self._get_timestamp()\n\n        return EditResult(path=path, occurrences=occurrences if replace_all else 1)\n\n    def glob_info(self, pattern: str, path: str = \"/\") -&gt; list[FileInfo]:\n        \"\"\"Find files matching a glob pattern.\"\"\"\n        error = _validate_path(path)\n        if error:\n            return []\n\n        path = _normalize_path(path)\n\n        # Combine path and pattern\n        if path == \"/\":\n            full_pattern = \"/\" + pattern.lstrip(\"/\")\n        else:\n            full_pattern = path + \"/\" + pattern.lstrip(\"/\")\n\n        results: list[FileInfo] = []\n\n        for file_path, file_data in self._files.items():\n            # Use wcmatch for glob matching\n            if wcglob.globmatch(file_path, full_pattern, flags=wcglob.GLOBSTAR):\n                name = file_path.split(\"/\")[-1]\n                results.append(\n                    FileInfo(\n                        name=name,\n                        path=file_path,\n                        is_dir=False,\n                        size=sum(len(line) for line in file_data[\"content\"]),\n                    )\n                )\n\n        return sorted(results, key=lambda x: x[\"path\"])\n\n    def grep_raw(\n        self,\n        pattern: str,\n        path: str | None = None,\n        glob: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Search for pattern in files.\"\"\"\n        try:\n            regex = re.compile(pattern)\n        except re.error as e:\n            return f\"Error: Invalid regex pattern: {e}\"\n\n        results: list[GrepMatch] = []\n        files = self._files_not_hidden if ignore_hidden else self._files\n        # Determine which files to search\n        files_to_search: list[str] = []\n\n        if path:\n            error = _validate_path(path)\n            if error:\n                return f\"Error: {error}\"\n            path = _normalize_path(path)\n\n            if path in files:\n                files_to_search = [path]\n            else:\n                # Path is a directory - search all files under it\n                prefix = path if path == \"/\" else path + \"/\"\n                files_to_search = [f for f in files if f.startswith(prefix)]\n        else:\n            files_to_search = list(files.keys())\n\n        # Filter by glob if provided\n        if glob:\n            glob_pattern = \"/\" + glob.lstrip(\"/\")\n            files_to_search = [\n                f\n                for f in files_to_search\n                if wcglob.globmatch(f, glob_pattern, flags=wcglob.GLOBSTAR)\n            ]\n\n        # Search each file\n        for file_path in files_to_search:\n            lines = files[file_path][\"content\"]\n            for i, line in enumerate(lines):\n                if regex.search(line):\n                    results.append(\n                        GrepMatch(\n                            path=file_path,\n                            line_number=i + 1,\n                            line=line,\n                        )\n                    )\n\n        return results\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.files","title":"<code>files</code>  <code>property</code>","text":"<p>Get the internal files dictionary.</p>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.__init__","title":"<code>__init__(files=None)</code>","text":"<p>Initialize the backend.</p> <p>Parameters:</p> Name Type Description Default <code>files</code> <code>dict[str, FileData] | None</code> <p>Optional initial file dictionary.</p> <code>None</code> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def __init__(self, files: dict[str, FileData] | None = None):\n    \"\"\"Initialize the backend.\n\n    Args:\n        files: Optional initial file dictionary.\n    \"\"\"\n    self._files: dict[str, FileData] = files if files is not None else {}\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.ls_info","title":"<code>ls_info(path)</code>","text":"<p>List files and directories at the given path.</p> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def ls_info(self, path: str) -&gt; list[FileInfo]:\n    \"\"\"List files and directories at the given path.\"\"\"\n    error = _validate_path(path)\n    if error:\n        return []\n\n    path = _normalize_path(path)\n\n    # Collect all entries at this level\n    entries: dict[str, FileInfo] = {}\n    prefix = path if path == \"/\" else path + \"/\"\n\n    for file_path, file_data in self._files.items():\n        if not file_path.startswith(prefix) and file_path != path:\n            continue  # pragma: no cover\n\n        # Get the relative path from the directory\n        if file_path == path:\n            # This is a file, not a directory\n            name = file_path.split(\"/\")[-1]\n            entries[name] = FileInfo(\n                name=name,\n                path=file_path,\n                is_dir=False,\n                size=sum(len(line) for line in file_data[\"content\"]),\n            )\n        else:  # pragma: no cover\n            rel_path = file_path[len(prefix) :]\n            parts = rel_path.split(\"/\")\n            name = parts[0]\n\n            if name not in entries:\n                if len(parts) == 1:\n                    # Direct child file\n                    entries[name] = FileInfo(\n                        name=name,\n                        path=file_path,\n                        is_dir=False,\n                        size=sum(len(line) for line in file_data[\"content\"]),\n                    )\n                else:\n                    # Directory (has more parts)\n                    entries[name] = FileInfo(\n                        name=name,\n                        path=prefix + name,\n                        is_dir=True,\n                        size=None,\n                    )\n\n    return sorted(entries.values(), key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.read","title":"<code>read(path, offset=0, limit=2000)</code>","text":"<p>Read file content with line numbers.</p> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n    \"\"\"Read file content with line numbers.\"\"\"\n    error = _validate_path(path)\n    if error:  # pragma: no cover\n        return f\"Error: {error}\"\n\n    path = _normalize_path(path)\n\n    if path not in self._files:\n        return f\"Error: File '{path}' not found\"\n\n    lines = self._files[path][\"content\"]\n    total_lines = len(lines)\n\n    if offset &gt;= total_lines:\n        return f\"Error: Offset {offset} exceeds file length ({total_lines} lines)\"\n\n    end = min(offset + limit, total_lines)\n    result_lines = []\n\n    for i in range(offset, end):\n        line_num = i + 1  # 1-indexed\n        result_lines.append(f\"{line_num:&gt;6}\\t{lines[i]}\")\n\n    result = \"\\n\".join(result_lines)\n\n    if end &lt; total_lines:\n        result += f\"\\n\\n... ({total_lines - end} more lines)\"\n\n    return result\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.write","title":"<code>write(path, content)</code>","text":"<p>Write content to a file.</p> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n    \"\"\"Write content to a file.\"\"\"\n    error = _validate_path(path)\n    if error:\n        return WriteResult(error=error)\n\n    path = _normalize_path(path)\n    now = self._get_timestamp()\n\n    # Convert bytes to string if needed\n    if isinstance(content, bytes):\n        content = content.decode(\"utf-8\", errors=\"replace\")\n\n    # Split content into lines, preserving empty lines\n    lines = content.split(\"\\n\")\n\n    existing = self._files.get(path)\n    created_at = existing[\"created_at\"] if existing else now\n    self._files[path] = FileData(\n        content=lines,\n        created_at=created_at,\n        modified_at=now,\n    )\n\n    return WriteResult(path=path)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.edit","title":"<code>edit(path, old_string, new_string, replace_all=False)</code>","text":"<p>Edit a file by replacing strings.</p> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def edit(\n    self, path: str, old_string: str, new_string: str, replace_all: bool = False\n) -&gt; EditResult:\n    \"\"\"Edit a file by replacing strings.\"\"\"\n    error = _validate_path(path)\n    if error:\n        return EditResult(error=error)\n\n    path = _normalize_path(path)\n\n    if path not in self._files:\n        return EditResult(error=f\"File '{path}' not found\")  # pragma: no cover\n\n    content = \"\\n\".join(self._files[path][\"content\"])\n    occurrences = content.count(old_string)\n\n    if occurrences == 0:\n        return EditResult(error=f\"String '{old_string}' not found in file\")  # pragma: no cover\n\n    if occurrences &gt; 1 and not replace_all:\n        return EditResult(\n            error=f\"String '{old_string}' found {occurrences} times. \"\n            \"Use replace_all=True to replace all, or provide more context.\"\n        )\n\n    if replace_all:\n        new_content = content.replace(old_string, new_string)\n    else:\n        new_content = content.replace(old_string, new_string, 1)\n\n    self._files[path][\"content\"] = new_content.split(\"\\n\")\n    self._files[path][\"modified_at\"] = self._get_timestamp()\n\n    return EditResult(path=path, occurrences=occurrences if replace_all else 1)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.glob_info","title":"<code>glob_info(pattern, path='/')</code>","text":"<p>Find files matching a glob pattern.</p> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def glob_info(self, pattern: str, path: str = \"/\") -&gt; list[FileInfo]:\n    \"\"\"Find files matching a glob pattern.\"\"\"\n    error = _validate_path(path)\n    if error:\n        return []\n\n    path = _normalize_path(path)\n\n    # Combine path and pattern\n    if path == \"/\":\n        full_pattern = \"/\" + pattern.lstrip(\"/\")\n    else:\n        full_pattern = path + \"/\" + pattern.lstrip(\"/\")\n\n    results: list[FileInfo] = []\n\n    for file_path, file_data in self._files.items():\n        # Use wcmatch for glob matching\n        if wcglob.globmatch(file_path, full_pattern, flags=wcglob.GLOBSTAR):\n            name = file_path.split(\"/\")[-1]\n            results.append(\n                FileInfo(\n                    name=name,\n                    path=file_path,\n                    is_dir=False,\n                    size=sum(len(line) for line in file_data[\"content\"]),\n                )\n            )\n\n    return sorted(results, key=lambda x: x[\"path\"])\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.state.StateBackend.grep_raw","title":"<code>grep_raw(pattern, path=None, glob=None, ignore_hidden=True)</code>","text":"<p>Search for pattern in files.</p> Source code in <code>src/pydantic_ai_backends/backends/state.py</code> Python<pre><code>def grep_raw(\n    self,\n    pattern: str,\n    path: str | None = None,\n    glob: str | None = None,\n    ignore_hidden: bool = True,\n) -&gt; list[GrepMatch] | str:\n    \"\"\"Search for pattern in files.\"\"\"\n    try:\n        regex = re.compile(pattern)\n    except re.error as e:\n        return f\"Error: Invalid regex pattern: {e}\"\n\n    results: list[GrepMatch] = []\n    files = self._files_not_hidden if ignore_hidden else self._files\n    # Determine which files to search\n    files_to_search: list[str] = []\n\n    if path:\n        error = _validate_path(path)\n        if error:\n            return f\"Error: {error}\"\n        path = _normalize_path(path)\n\n        if path in files:\n            files_to_search = [path]\n        else:\n            # Path is a directory - search all files under it\n            prefix = path if path == \"/\" else path + \"/\"\n            files_to_search = [f for f in files if f.startswith(prefix)]\n    else:\n        files_to_search = list(files.keys())\n\n    # Filter by glob if provided\n    if glob:\n        glob_pattern = \"/\" + glob.lstrip(\"/\")\n        files_to_search = [\n            f\n            for f in files_to_search\n            if wcglob.globmatch(f, glob_pattern, flags=wcglob.GLOBSTAR)\n        ]\n\n    # Search each file\n    for file_path in files_to_search:\n        lines = files[file_path][\"content\"]\n        for i, line in enumerate(lines):\n            if regex.search(line):\n                results.append(\n                    GrepMatch(\n                        path=file_path,\n                        line_number=i + 1,\n                        line=line,\n                    )\n                )\n\n    return results\n</code></pre>"},{"location":"api/backends/#compositebackend","title":"CompositeBackend","text":""},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend","title":"<code>pydantic_ai_backends.backends.composite.CompositeBackend</code>","text":"<p>Backend that routes operations to different backends by path prefix.</p> <p>Allows combining multiple backends (e.g., memory for temp files, filesystem for persistent storage) under a unified interface.</p> Example Python<pre><code>from pydantic_ai_backends import CompositeBackend, StateBackend, FilesystemBackend\n\nbackend = CompositeBackend(\n    default=StateBackend(),  # Default for unmatched paths\n    routes={\n        \"/project/\": FilesystemBackend(\"/my/project\"),\n        \"/workspace/\": FilesystemBackend(\"/tmp/workspace\"),\n    },\n)\n\n# Routes to FilesystemBackend\nbackend.write(\"/project/app.py\", \"...\")\n\n# Routes to StateBackend (default)\nbackend.write(\"/temp/scratch.txt\", \"...\")\n</code></pre> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>class CompositeBackend:\n    \"\"\"Backend that routes operations to different backends by path prefix.\n\n    Allows combining multiple backends (e.g., memory for temp files,\n    filesystem for persistent storage) under a unified interface.\n\n    Example:\n        ```python\n        from pydantic_ai_backends import CompositeBackend, StateBackend, FilesystemBackend\n\n        backend = CompositeBackend(\n            default=StateBackend(),  # Default for unmatched paths\n            routes={\n                \"/project/\": FilesystemBackend(\"/my/project\"),\n                \"/workspace/\": FilesystemBackend(\"/tmp/workspace\"),\n            },\n        )\n\n        # Routes to FilesystemBackend\n        backend.write(\"/project/app.py\", \"...\")\n\n        # Routes to StateBackend (default)\n        backend.write(\"/temp/scratch.txt\", \"...\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        default: BackendProtocol,\n        routes: dict[str, BackendProtocol] | None = None,\n    ):\n        \"\"\"Initialize composite backend.\n\n        Args:\n            default: Default backend for paths that don't match any route.\n            routes: Dictionary mapping path prefixes to backends.\n                    e.g., {\"/memories/\": store_backend, \"/temp/\": state_backend}\n        \"\"\"\n        self._default = default\n        self._routes = routes or {}\n\n        # Sort routes by length (longest first) for correct matching\n        self._sorted_prefixes = sorted(self._routes.keys(), key=len, reverse=True)\n\n    def _get_backend(self, path: str) -&gt; BackendProtocol:\n        \"\"\"Get the appropriate backend for a path.\"\"\"\n        for prefix in self._sorted_prefixes:\n            if path.startswith(prefix):\n                return self._routes[prefix]\n        return self._default\n\n    def ls_info(self, path: str) -&gt; list[FileInfo]:\n        \"\"\"List files, aggregating from all relevant backends.\"\"\"\n        # If path matches a specific route, use that backend\n        backend = self._get_backend(path)\n\n        # For root path, aggregate from all backends\n        if path == \"/\" or path == \"\":\n            all_entries: dict[str, FileInfo] = {}\n\n            # First, get entries from default backend\n            for entry in self._default.ls_info(path):\n                all_entries[entry[\"path\"]] = entry\n\n            # Then, add virtual directories for route prefixes\n            for prefix in self._routes:\n                # Extract first directory from prefix\n                parts = prefix.strip(\"/\").split(\"/\")\n                if parts[0]:\n                    dir_name = parts[0]\n                    dir_path = \"/\" + dir_name\n                    if dir_path not in all_entries:\n                        all_entries[dir_path] = FileInfo(\n                            name=dir_name,\n                            path=dir_path,\n                            is_dir=True,\n                            size=None,\n                        )\n\n            return sorted(all_entries.values(), key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n\n        return backend.ls_info(path)\n\n    def _read_bytes(self, path: str) -&gt; bytes:\n        \"\"\"Read bytes from the appropriate backend.\"\"\"\n        return self._get_backend(path)._read_bytes(path)\n\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n        \"\"\"Read from the appropriate backend.\"\"\"\n        return self._get_backend(path).read(path, offset, limit)\n\n    def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n        \"\"\"Write to the appropriate backend.\"\"\"\n        return self._get_backend(path).write(path, content)\n\n    def edit(\n        self, path: str, old_string: str, new_string: str, replace_all: bool = False\n    ) -&gt; EditResult:\n        \"\"\"Edit using the appropriate backend.\"\"\"\n        return self._get_backend(path).edit(path, old_string, new_string, replace_all)\n\n    def glob_info(self, pattern: str, path: str = \"/\") -&gt; list[FileInfo]:\n        \"\"\"Glob across all backends if searching from root.\"\"\"\n        if path == \"/\" or path == \"\":\n            all_results: list[FileInfo] = []\n\n            # Search in default backend\n            all_results.extend(self._default.glob_info(pattern, path))\n\n            # Search in each routed backend\n            for prefix, backend in self._routes.items():\n                results = backend.glob_info(pattern, prefix)\n                all_results.extend(results)\n\n            return sorted(all_results, key=lambda x: x[\"path\"])\n\n        return self._get_backend(path).glob_info(pattern, path)\n\n    def grep_raw(\n        self,\n        pattern: str,\n        path: str | None = None,\n        glob: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Grep across all backends if no specific path.\"\"\"\n        if path is None or path == \"/\" or path == \"\":\n            all_results: list[GrepMatch] = []\n\n            # Search in default backend\n            result = self._default.grep_raw(pattern, path, glob, ignore_hidden)\n            if isinstance(result, list):\n                all_results.extend(result)\n            elif isinstance(result, str) and result.startswith(\"Error\"):\n                pass  # Ignore errors from individual backends\n\n            # Search in each routed backend\n            for prefix, backend in self._routes.items():\n                result = backend.grep_raw(pattern, prefix, glob, ignore_hidden)\n                if isinstance(result, list):\n                    all_results.extend(result)\n\n            return all_results\n\n        return self._get_backend(path).grep_raw(pattern, path, glob, ignore_hidden)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.__init__","title":"<code>__init__(default, routes=None)</code>","text":"<p>Initialize composite backend.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>BackendProtocol</code> <p>Default backend for paths that don't match any route.</p> required <code>routes</code> <code>dict[str, BackendProtocol] | None</code> <p>Dictionary mapping path prefixes to backends.     e.g., {\"/memories/\": store_backend, \"/temp/\": state_backend}</p> <code>None</code> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def __init__(\n    self,\n    default: BackendProtocol,\n    routes: dict[str, BackendProtocol] | None = None,\n):\n    \"\"\"Initialize composite backend.\n\n    Args:\n        default: Default backend for paths that don't match any route.\n        routes: Dictionary mapping path prefixes to backends.\n                e.g., {\"/memories/\": store_backend, \"/temp/\": state_backend}\n    \"\"\"\n    self._default = default\n    self._routes = routes or {}\n\n    # Sort routes by length (longest first) for correct matching\n    self._sorted_prefixes = sorted(self._routes.keys(), key=len, reverse=True)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.ls_info","title":"<code>ls_info(path)</code>","text":"<p>List files, aggregating from all relevant backends.</p> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def ls_info(self, path: str) -&gt; list[FileInfo]:\n    \"\"\"List files, aggregating from all relevant backends.\"\"\"\n    # If path matches a specific route, use that backend\n    backend = self._get_backend(path)\n\n    # For root path, aggregate from all backends\n    if path == \"/\" or path == \"\":\n        all_entries: dict[str, FileInfo] = {}\n\n        # First, get entries from default backend\n        for entry in self._default.ls_info(path):\n            all_entries[entry[\"path\"]] = entry\n\n        # Then, add virtual directories for route prefixes\n        for prefix in self._routes:\n            # Extract first directory from prefix\n            parts = prefix.strip(\"/\").split(\"/\")\n            if parts[0]:\n                dir_name = parts[0]\n                dir_path = \"/\" + dir_name\n                if dir_path not in all_entries:\n                    all_entries[dir_path] = FileInfo(\n                        name=dir_name,\n                        path=dir_path,\n                        is_dir=True,\n                        size=None,\n                    )\n\n        return sorted(all_entries.values(), key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n\n    return backend.ls_info(path)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.read","title":"<code>read(path, offset=0, limit=2000)</code>","text":"<p>Read from the appropriate backend.</p> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n    \"\"\"Read from the appropriate backend.\"\"\"\n    return self._get_backend(path).read(path, offset, limit)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.write","title":"<code>write(path, content)</code>","text":"<p>Write to the appropriate backend.</p> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n    \"\"\"Write to the appropriate backend.\"\"\"\n    return self._get_backend(path).write(path, content)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.edit","title":"<code>edit(path, old_string, new_string, replace_all=False)</code>","text":"<p>Edit using the appropriate backend.</p> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def edit(\n    self, path: str, old_string: str, new_string: str, replace_all: bool = False\n) -&gt; EditResult:\n    \"\"\"Edit using the appropriate backend.\"\"\"\n    return self._get_backend(path).edit(path, old_string, new_string, replace_all)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.glob_info","title":"<code>glob_info(pattern, path='/')</code>","text":"<p>Glob across all backends if searching from root.</p> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def glob_info(self, pattern: str, path: str = \"/\") -&gt; list[FileInfo]:\n    \"\"\"Glob across all backends if searching from root.\"\"\"\n    if path == \"/\" or path == \"\":\n        all_results: list[FileInfo] = []\n\n        # Search in default backend\n        all_results.extend(self._default.glob_info(pattern, path))\n\n        # Search in each routed backend\n        for prefix, backend in self._routes.items():\n            results = backend.glob_info(pattern, prefix)\n            all_results.extend(results)\n\n        return sorted(all_results, key=lambda x: x[\"path\"])\n\n    return self._get_backend(path).glob_info(pattern, path)\n</code></pre>"},{"location":"api/backends/#pydantic_ai_backends.backends.composite.CompositeBackend.grep_raw","title":"<code>grep_raw(pattern, path=None, glob=None, ignore_hidden=True)</code>","text":"<p>Grep across all backends if no specific path.</p> Source code in <code>src/pydantic_ai_backends/backends/composite.py</code> Python<pre><code>def grep_raw(\n    self,\n    pattern: str,\n    path: str | None = None,\n    glob: str | None = None,\n    ignore_hidden: bool = True,\n) -&gt; list[GrepMatch] | str:\n    \"\"\"Grep across all backends if no specific path.\"\"\"\n    if path is None or path == \"/\" or path == \"\":\n        all_results: list[GrepMatch] = []\n\n        # Search in default backend\n        result = self._default.grep_raw(pattern, path, glob, ignore_hidden)\n        if isinstance(result, list):\n            all_results.extend(result)\n        elif isinstance(result, str) and result.startswith(\"Error\"):\n            pass  # Ignore errors from individual backends\n\n        # Search in each routed backend\n        for prefix, backend in self._routes.items():\n            result = backend.grep_raw(pattern, prefix, glob, ignore_hidden)\n            if isinstance(result, list):\n                all_results.extend(result)\n\n        return all_results\n\n    return self._get_backend(path).grep_raw(pattern, path, glob, ignore_hidden)\n</code></pre>"},{"location":"api/docker/","title":"Docker API","text":""},{"location":"api/docker/#dockersandbox","title":"DockerSandbox","text":""},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox","title":"<code>pydantic_ai_backends.backends.docker.sandbox.DockerSandbox</code>","text":"<p>               Bases: <code>BaseSandbox</code></p> <p>Docker-based sandbox for isolated command execution.</p> <p>Creates a Docker container for running commands in an isolated environment. Requires the docker Python package to be installed.</p> <p>Supports RuntimeConfig for pre-configured environments with packages pre-installed.</p> Example Python<pre><code>from pydantic_ai_backends import DockerSandbox, RuntimeConfig\n\n# Use a simple image\nsandbox = DockerSandbox(image=\"python:3.12-slim\")\n\n# Or use a custom runtime with packages\ncustom_runtime = RuntimeConfig(\n    name=\"ml-env\",\n    base_image=\"python:3.12-slim\",\n    packages=[\"torch\", \"transformers\"],\n)\nsandbox = DockerSandbox(runtime=custom_runtime)\n</code></pre> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>class DockerSandbox(BaseSandbox):  # pragma: no cover\n    \"\"\"Docker-based sandbox for isolated command execution.\n\n    Creates a Docker container for running commands in an isolated environment.\n    Requires the docker Python package to be installed.\n\n    Supports RuntimeConfig for pre-configured environments with packages pre-installed.\n\n    Example:\n        ```python\n        from pydantic_ai_backends import DockerSandbox, RuntimeConfig\n\n        # Use a simple image\n        sandbox = DockerSandbox(image=\"python:3.12-slim\")\n\n        # Or use a custom runtime with packages\n        custom_runtime = RuntimeConfig(\n            name=\"ml-env\",\n            base_image=\"python:3.12-slim\",\n            packages=[\"torch\", \"transformers\"],\n        )\n        sandbox = DockerSandbox(runtime=custom_runtime)\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        image: str = \"python:3.12-slim\",\n        sandbox_id: str | None = None,\n        work_dir: str = \"/workspace\",\n        auto_remove: bool = True,\n        runtime: RuntimeConfig | str | None = None,\n        session_id: str | None = None,\n        idle_timeout: int = 3600,\n        volumes: dict[str, str] | None = None,\n    ):\n        \"\"\"Initialize Docker sandbox.\n\n        Args:\n            image: Docker image to use (ignored if runtime is provided).\n            sandbox_id: Unique identifier for this sandbox.\n            work_dir: Working directory inside container (ignored if runtime is provided).\n            auto_remove: Remove container when stopped.\n            runtime: RuntimeConfig or name of built-in runtime.\n            session_id: Alias for sandbox_id (for session management).\n            idle_timeout: Timeout in seconds for idle cleanup (default: 1 hour).\n            volumes: Host-to-container volume mappings for persistent storage.\n                     Format: {\"/host/path\": \"/container/path\"}\n        \"\"\"\n        # session_id is an alias for sandbox_id\n        effective_id = session_id or sandbox_id\n        super().__init__(effective_id)\n\n        self._auto_remove = auto_remove\n        self._container = None\n        self._idle_timeout = idle_timeout\n        self._last_activity = time.time()\n        self._volumes = volumes or {}\n\n        # Handle runtime configuration\n        if runtime is not None:\n            if isinstance(runtime, str):\n                from pydantic_ai_backends.backends.docker.runtimes import get_runtime\n\n                runtime = get_runtime(runtime)\n            self._runtime: RuntimeConfig | None = runtime\n            self._work_dir = runtime.work_dir\n            self._image = image  # Will be overridden by _ensure_runtime_image()\n        else:\n            self._runtime = None\n            self._work_dir = work_dir\n            self._image = image\n\n    @property\n    def runtime(self) -&gt; RuntimeConfig | None:\n        \"\"\"The runtime configuration for this sandbox.\"\"\"\n        return self._runtime\n\n    @property\n    def session_id(self) -&gt; str:\n        \"\"\"Alias for sandbox id, used for session management.\"\"\"\n        return self._id\n\n    def _ensure_container(self) -&gt; None:\n        \"\"\"Ensure Docker container is running.\"\"\"\n        if self._container is not None:\n            return\n\n        try:\n            import docker\n        except ImportError as e:\n            raise ImportError(\n                \"Docker package not installed. \"\n                \"Install with: pip install pydantic-ai-backend[docker]\"\n            ) from e\n\n        client = docker.from_env()\n\n        # Get the appropriate image (build if needed for runtime)\n        image = self._ensure_runtime_image(client)\n\n        # Prepare environment variables from runtime\n        env_vars = {}\n        if self._runtime and self._runtime.env_vars:\n            env_vars = self._runtime.env_vars\n\n        # Convert simple volume format to Docker SDK format\n        # {\"/host\": \"/container\"} -&gt; {\"/host\": {\"bind\": \"/container\", \"mode\": \"rw\"}}\n        docker_volumes: dict[str, dict[str, str]] = {}\n        for host_path, container_path in self._volumes.items():\n            docker_volumes[host_path] = {\"bind\": container_path, \"mode\": \"rw\"}\n\n        self._container = client.containers.run(\n            image,\n            command=\"sleep infinity\",\n            detach=True,\n            working_dir=self._work_dir,\n            auto_remove=self._auto_remove,\n            environment=env_vars,\n            volumes=docker_volumes if docker_volumes else None,\n        )\n\n    def _ensure_runtime_image(self, client: object) -&gt; str:\n        \"\"\"Ensure runtime image exists and return its name.\n\n        Args:\n            client: Docker client instance.\n\n        Returns:\n            Docker image name/tag to use.\n        \"\"\"\n        if self._runtime is None:\n            return self._image\n\n        # If ready-to-use image is specified\n        if self._runtime.image:\n            return self._runtime.image\n\n        # If base_image + packages - need to build\n        if self._runtime.base_image:\n            return self._build_runtime_image(client)\n\n        # Fallback to default image\n        return self._image\n\n    def _build_runtime_image(self, client: object) -&gt; str:\n        \"\"\"Build a custom image with packages installed.\n\n        Args:\n            client: Docker client instance.\n\n        Returns:\n            Docker image tag for the built image.\n        \"\"\"\n        import docker.errors\n\n        runtime = self._runtime\n        assert runtime is not None\n        assert runtime.base_image is not None\n\n        # Generate unique tag based on config\n        config_hash = hashlib.md5(runtime.model_dump_json().encode()).hexdigest()[:12]\n        image_tag = f\"pydantic-ai-backend-runtime:{runtime.name}-{config_hash}\"\n\n        # Check if image exists (cache)\n        if runtime.cache_image:\n            try:\n                client.images.get(image_tag)  # type: ignore[attr-defined]\n                return image_tag\n            except docker.errors.ImageNotFound:\n                pass\n\n        # Build Dockerfile\n        dockerfile = self._generate_dockerfile(runtime)\n\n        # Build image\n        client.images.build(  # type: ignore[attr-defined]\n            fileobj=io.BytesIO(dockerfile.encode()),\n            tag=image_tag,\n            rm=True,\n        )\n\n        return image_tag\n\n    def _generate_dockerfile(self, runtime: RuntimeConfig) -&gt; str:\n        \"\"\"Generate Dockerfile content for runtime.\n\n        Args:\n            runtime: Runtime configuration.\n\n        Returns:\n            Dockerfile content as string.\n        \"\"\"\n        assert runtime.base_image is not None\n        lines = [f\"FROM {runtime.base_image}\"]\n\n        # Setup commands\n        for cmd in runtime.setup_commands:\n            lines.append(f\"RUN {cmd}\")\n\n        # Install packages\n        if runtime.packages:\n            packages_str = \" \".join(runtime.packages)\n            if runtime.package_manager == \"pip\":\n                lines.append(f\"RUN pip install --no-cache-dir {packages_str}\")\n            elif runtime.package_manager == \"npm\":\n                lines.append(f\"RUN npm install -g {packages_str}\")\n            elif runtime.package_manager == \"apt\":\n                lines.append(f\"RUN apt-get update &amp;&amp; apt-get install -y {packages_str}\")\n            elif runtime.package_manager == \"cargo\":\n                lines.append(f\"RUN cargo install {packages_str}\")\n\n        # Environment variables\n        for key, value in runtime.env_vars.items():\n            lines.append(f\"ENV {key}={value}\")\n\n        # Work directory\n        lines.append(f\"WORKDIR {runtime.work_dir}\")\n\n        return \"\\n\".join(lines)\n\n    def execute(self, command: str, timeout: int | None = None) -&gt; ExecuteResponse:\n        \"\"\"Execute command in Docker container.\"\"\"\n        self._ensure_container()\n        self._last_activity = time.time()  # Update activity timestamp\n        assert self._container is not None  # Ensured by _ensure_container()\n\n        try:\n            # Note: Docker SDK exec_run doesn't support timeout parameter directly.\n            # For timeouts, we wrap the command with 'timeout' utility.\n            if timeout:\n                exec_cmd = [\"timeout\", str(timeout), \"sh\", \"-c\", command]\n            else:\n                exec_cmd = [\"sh\", \"-c\", command]\n\n            exit_code, output = self._container.exec_run(\n                exec_cmd,\n                workdir=self._work_dir,\n            )\n\n            output_str = output.decode(\"utf-8\", errors=\"replace\")\n\n            # Truncate if too long\n            max_output = 100000\n            truncated = len(output_str) &gt; max_output\n            if truncated:\n                output_str = output_str[:max_output]\n\n            return ExecuteResponse(\n                output=output_str,\n                exit_code=exit_code,\n                truncated=truncated,\n            )\n        except Exception as e:\n            return ExecuteResponse(\n                output=f\"Error: {e}\",\n                exit_code=1,\n                truncated=False,\n            )\n\n    def _read_bytes(self, path: str) -&gt; bytes:\n        \"\"\"Read raw bytes from file in container.\n\n        Args:\n            path: Path to the file in the container.\n\n        Returns:\n            File content as bytes.\n        \"\"\"\n        self._ensure_container()\n        assert self._container is not None\n\n        try:\n            # Use Docker get_archive to read file\n            stream, stat = self._container.get_archive(path)\n            raw_tar_bytes = b\"\".join(stream)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to read file: {e}\") from e\n\n        # Extract file from tar archive\n        with (\n            io.BytesIO(raw_tar_bytes) as tar_buffer,\n            tarfile.open(fileobj=tar_buffer, mode=\"r\") as tar,\n        ):\n            member = next((m for m in tar.getmembers() if m.isfile()), None)\n\n            if not member:\n                return f\"[Error: Path '{path}' exists but is empty or not a file.]\".encode()\n\n            f = tar.extractfile(member)\n            if f is None:\n                return b\"[Error: Could not extract file stream from archive]\"\n\n            file_bytes = f.read()\n            return file_bytes\n\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n        \"\"\"\n        Read file from container using Docker get_archive API.\n\n        Args:\n            path: Path to the file in the container.\n            offset: Start line index (for pagination).\n            limit: Maximum number of lines to return.\n        \"\"\"\n        try:\n            # Read raw bytes from file\n            file_bytes = self._read_bytes(path)\n\n            # Convert bytes to string\n            file_ext = Path(path).suffix.lower().lstrip(\".\")\n            try:\n                full_text = self._convert_bytes_to_text(file_ext, file_bytes)\n            except ValueError as e:\n                return f\"[Error: {e}]\"\n\n            # Split into lines\n            lines = full_text.splitlines()\n            total_lines = len(lines)\n\n            if offset &gt;= total_lines:\n                return \"[End of file]\"\n\n            end_index = offset + limit\n            chunk_lines = lines[offset:end_index]\n            chunk = \"\\n\".join(chunk_lines)\n\n            if end_index &lt; total_lines:\n                remaining = total_lines - end_index\n                footer = f\"\\n\\n[... {remaining} more lines. Use offset={end_index} to read more.]\"\n                return chunk + footer\n\n            return chunk\n\n        except Exception as e:\n            return f\"[Error reading file: {e}]\"\n\n    def _convert_bytes_to_text(self, file_ext: str, file_bytes: bytes) -&gt; str:\n        # Plain text files with encoding detection\n        if file_ext in (TEXT_EXT | CODE_EXT):\n            return self._decode_text(file_bytes)\n\n        mime_type = mimetypes.types_map.get(f\".{file_ext}\")\n        if mime_type and (mime_type.startswith(\"text\") or \"json\" in mime_type):\n            return self._decode_text(file_bytes)\n\n        # PDF files\n        elif file_ext == \"pdf\":\n            return self._extract_pdf_text(file_bytes)\n\n        return self._decode_unknown_text(file_bytes)\n\n    def _decode_text(self, file_bytes: bytes) -&gt; str:\n        chardet = _get_chardet()\n\n        # Use chardet to detect encoding with confidence\n        detection = chardet.detect(file_bytes)\n        detected_encoding = detection.get(\"encoding\")\n        confidence = detection.get(\"confidence\", 0)\n\n        # If high confidence detection, use it\n        if detected_encoding and confidence &gt; 0.7:\n            try:\n                return file_bytes.decode(detected_encoding)\n            except (UnicodeDecodeError, AttributeError, LookupError):\n                pass  # Fall through to manual attempts\n\n        # Fallback to common encodings if detection failed or low confidence\n        encodings = [\"utf-8\", \"utf-8-sig\", \"latin-1\", \"cp1252\", \"iso-8859-1\"]\n\n        # Add detected encoding to the front if not already there\n        if detected_encoding and detected_encoding not in encodings:\n            encodings.insert(0, detected_encoding)\n\n        for encoding in encodings:\n            try:\n                return file_bytes.decode(encoding)\n            except (UnicodeDecodeError, AttributeError, LookupError):\n                continue\n\n        # Last resort: decode with errors='replace' to avoid complete failure\n        return file_bytes.decode(\"utf-8\", errors=\"replace\")\n\n    def _decode_unknown_text(self, file_bytes: bytes) -&gt; str:\n        chardet = _get_chardet()\n        # Use chardet to detect encoding with confidence\n        detected_encoding = chardet.detect(file_bytes).get(\"encoding\")\n        # Fallback to common encodings if detection failed or low confidence\n        encodings = {detected_encoding, \"utf-8\"} if detected_encoding else [\"utf-8\"]\n        for encoding in encodings:\n            text = file_bytes.decode(encoding, errors=\"replace\")\n            if text.count(\"\\ufffd\") &lt; max(len(text) // 100, 2):\n                return text\n        raise ValueError(\"[Binary File]\")\n\n    def _extract_pdf_text(self, file_bytes: bytes) -&gt; str:\n        pypdf = _get_pypdf()\n\n        try:\n            pdf_file = BytesIO(file_bytes)\n            pdf_reader = pypdf.PdfReader(pdf_file)\n\n            if len(pdf_reader.pages) == 0:\n                raise ValueError(\"PDF contains no pages\")\n\n            # Extract metadata for context\n            metadata = pdf_reader.metadata\n            text_parts = []\n\n            if metadata:\n                if metadata.get(\"/Title\"):\n                    text_parts.append(f\"Title: {metadata['/Title']}\\n\")\n                if metadata.get(\"/Author\"):\n                    text_parts.append(f\"Author: {metadata['/Author']}\\n\")\n                if metadata.get(\"/Subject\"):\n                    text_parts.append(f\"Subject: {metadata['/Subject']}\\n\")\n                text_parts.append(\"\\n\")\n\n            # Extract text from each page with clear separators\n            for page_num, page in enumerate(pdf_reader.pages, 1):\n                page_text = page.extract_text()\n\n                if page_text and page_text.strip():\n                    # Clean up common PDF artifacts\n                    page_text = self._clean_pdf_text(page_text)\n                    text_parts.append(f\"--- Page {page_num} ---\\n\")\n                    text_parts.append(page_text)\n                    text_parts.append(\"\\n\\n\")\n\n            full_text = \"\".join(text_parts).strip()\n\n            if not full_text:\n                raise ValueError(\"No extractable text found in PDF\")\n\n            return full_text\n\n        except Exception as e:\n            raise ValueError(f\"Failed to parse PDF: {str(e)}\") from e\n\n    def _clean_pdf_text(self, text: str) -&gt; str:\n        \"\"\"\n        Clean common PDF text extraction artifacts for better LLM processing.\n\n        Args:\n            text: Raw extracted text\n\n        Returns:\n            Cleaned text\n        \"\"\"\n\n        # Remove excessive whitespace while preserving paragraph breaks\n        text = re.sub(r\" +\", \" \", text)  # Multiple spaces to single space\n        text = re.sub(r\"\\n \", \"\\n\", text)  # Remove leading spaces on lines\n        text = re.sub(r\" \\n\", \"\\n\", text)  # Remove trailing spaces on lines\n        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)  # Max 2 consecutive newlines\n\n        # Fix common hyphenation issues at line breaks\n        text = re.sub(r\"(\\w+)-\\n(\\w+)\", r\"\\1\\2\", text)\n\n        # Remove form feed characters\n        text = text.replace(\"\\f\", \"\\n\")\n\n        return text.strip()\n\n    def edit(\n        self, path: str, old_string: str, new_string: str, replace_all: bool = False\n    ) -&gt; EditResult:\n        \"\"\"Edit file using Python string operations instead of sed.\n\n        This method reads the entire file, performs string replacement in Python,\n        and writes it back. This approach handles multiline strings naturally\n        without shell escaping issues.\n\n        Args:\n            path: Path to the file in the container.\n            old_string: String to find and replace.\n            new_string: Replacement string.\n            replace_all: If True, replace all occurrences. If False, only replace first.\n\n        Returns:\n            EditResult with path and occurrence count on success, or error message.\n        \"\"\"\n        try:\n            # Read the file content\n            file_bytes = self._read_bytes(path)\n\n            # Check for error messages from _read_bytes\n            if file_bytes.startswith(b\"[Error:\"):\n                error_msg = file_bytes.decode(\"utf-8\", errors=\"replace\")\n                return EditResult(error=error_msg)\n\n            # Decode to string using the same logic as read()\n            file_ext = Path(path).suffix.lower().lstrip(\".\")\n            try:\n                content = self._convert_bytes_to_text(file_ext, file_bytes)\n            except ValueError as e:\n                return EditResult(error=str(e))\n\n            # Count occurrences\n            occurrences = content.count(old_string)\n\n            if occurrences == 0:\n                return EditResult(error=\"String not found in file\")\n\n            if occurrences &gt; 1 and not replace_all:\n                return EditResult(\n                    error=f\"String found {occurrences} times. \"\n                    \"Use replace_all=True to replace all, or provide more context.\"\n                )\n\n            new_content = content.replace(old_string, new_string)\n\n            # Write back the modified content\n            write_result = self.write(path, new_content)\n\n            if write_result.error:\n                return EditResult(error=write_result.error)\n\n            return EditResult(path=path, occurrences=occurrences)\n\n        except Exception as e:\n            return EditResult(error=f\"Failed to edit file: {e}\")\n\n    def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n        \"\"\"Write file to container using Docker put_archive API.\n\n        This method uses Docker's put_archive() instead of heredoc to handle\n        large files and special characters reliably.\n\n        Args:\n            path: Absolute path where the file should be written.\n            content: File content as string or bytes.\n\n        Returns:\n            WriteResult with path on success, or error message on failure.\n        \"\"\"\n        self._ensure_container()\n        assert self._container is not None\n\n        try:\n            # Parse path into directory and filename\n            posix_path = PurePosixPath(path)\n            parent_dir = str(posix_path.parent)\n            filename = posix_path.name\n\n            # Ensure parent directory exists\n            safe_parent_dir = shlex.quote(parent_dir)\n            mkdir_result = self.execute(f\"mkdir -p {safe_parent_dir}\")\n            if mkdir_result.exit_code != 0:\n                return WriteResult(error=f\"Failed to create directory: {mkdir_result.output}\")\n\n            # Create tar archive in memory\n            content = content if isinstance(content, bytes) else content.encode()\n            tar_buffer = io.BytesIO()\n\n            with tarfile.open(fileobj=tar_buffer, mode=\"w\") as tar:\n                # Create TarInfo for the file\n                tarinfo = tarfile.TarInfo(name=filename)\n                tarinfo.size = len(content)\n                tarinfo.mtime = int(time.time())\n                tarinfo.mode = 0o644\n\n                # Add file to archive\n                tar.addfile(tarinfo, io.BytesIO(content))\n\n            # Reset buffer position\n            tar_buffer.seek(0)\n\n            # Upload to container\n            self._container.put_archive(parent_dir, tar_buffer)\n\n            return WriteResult(path=path)\n\n        except Exception as e:\n            return WriteResult(error=f\"Failed to write file: {e}\")\n\n    def start(self) -&gt; None:\n        \"\"\"Explicitly start the container.\n\n        This is useful for pre-warming containers before use.\n        The container is normally started lazily on first operation.\n        \"\"\"\n        self._ensure_container()\n\n    def is_alive(self) -&gt; bool:\n        \"\"\"Check if container is running.\n\n        Returns:\n            True if container is running, False otherwise.\n        \"\"\"\n        if self._container is None:\n            return False\n        try:\n            self._container.reload()\n            return self._container.status == \"running\"\n        except Exception:\n            return False\n\n    def stop(self) -&gt; None:\n        \"\"\"Stop and remove the container.\"\"\"\n        import contextlib\n\n        container = getattr(self, \"_container\", None)\n        if container is not None:\n            with contextlib.suppress(Exception):\n                container.stop()\n            self._container = None\n\n    def __del__(self) -&gt; None:\n        \"\"\"Cleanup container on deletion.\"\"\"\n        if hasattr(self, \"_container\"):\n            self.stop()\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.runtime","title":"<code>runtime</code>  <code>property</code>","text":"<p>The runtime configuration for this sandbox.</p>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.session_id","title":"<code>session_id</code>  <code>property</code>","text":"<p>Alias for sandbox id, used for session management.</p>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.__init__","title":"<code>__init__(image='python:3.12-slim', sandbox_id=None, work_dir='/workspace', auto_remove=True, runtime=None, session_id=None, idle_timeout=3600, volumes=None)</code>","text":"<p>Initialize Docker sandbox.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>Docker image to use (ignored if runtime is provided).</p> <code>'python:3.12-slim'</code> <code>sandbox_id</code> <code>str | None</code> <p>Unique identifier for this sandbox.</p> <code>None</code> <code>work_dir</code> <code>str</code> <p>Working directory inside container (ignored if runtime is provided).</p> <code>'/workspace'</code> <code>auto_remove</code> <code>bool</code> <p>Remove container when stopped.</p> <code>True</code> <code>runtime</code> <code>RuntimeConfig | str | None</code> <p>RuntimeConfig or name of built-in runtime.</p> <code>None</code> <code>session_id</code> <code>str | None</code> <p>Alias for sandbox_id (for session management).</p> <code>None</code> <code>idle_timeout</code> <code>int</code> <p>Timeout in seconds for idle cleanup (default: 1 hour).</p> <code>3600</code> <code>volumes</code> <code>dict[str, str] | None</code> <p>Host-to-container volume mappings for persistent storage.      Format: {\"/host/path\": \"/container/path\"}</p> <code>None</code> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def __init__(\n    self,\n    image: str = \"python:3.12-slim\",\n    sandbox_id: str | None = None,\n    work_dir: str = \"/workspace\",\n    auto_remove: bool = True,\n    runtime: RuntimeConfig | str | None = None,\n    session_id: str | None = None,\n    idle_timeout: int = 3600,\n    volumes: dict[str, str] | None = None,\n):\n    \"\"\"Initialize Docker sandbox.\n\n    Args:\n        image: Docker image to use (ignored if runtime is provided).\n        sandbox_id: Unique identifier for this sandbox.\n        work_dir: Working directory inside container (ignored if runtime is provided).\n        auto_remove: Remove container when stopped.\n        runtime: RuntimeConfig or name of built-in runtime.\n        session_id: Alias for sandbox_id (for session management).\n        idle_timeout: Timeout in seconds for idle cleanup (default: 1 hour).\n        volumes: Host-to-container volume mappings for persistent storage.\n                 Format: {\"/host/path\": \"/container/path\"}\n    \"\"\"\n    # session_id is an alias for sandbox_id\n    effective_id = session_id or sandbox_id\n    super().__init__(effective_id)\n\n    self._auto_remove = auto_remove\n    self._container = None\n    self._idle_timeout = idle_timeout\n    self._last_activity = time.time()\n    self._volumes = volumes or {}\n\n    # Handle runtime configuration\n    if runtime is not None:\n        if isinstance(runtime, str):\n            from pydantic_ai_backends.backends.docker.runtimes import get_runtime\n\n            runtime = get_runtime(runtime)\n        self._runtime: RuntimeConfig | None = runtime\n        self._work_dir = runtime.work_dir\n        self._image = image  # Will be overridden by _ensure_runtime_image()\n    else:\n        self._runtime = None\n        self._work_dir = work_dir\n        self._image = image\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.execute","title":"<code>execute(command, timeout=None)</code>","text":"<p>Execute command in Docker container.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def execute(self, command: str, timeout: int | None = None) -&gt; ExecuteResponse:\n    \"\"\"Execute command in Docker container.\"\"\"\n    self._ensure_container()\n    self._last_activity = time.time()  # Update activity timestamp\n    assert self._container is not None  # Ensured by _ensure_container()\n\n    try:\n        # Note: Docker SDK exec_run doesn't support timeout parameter directly.\n        # For timeouts, we wrap the command with 'timeout' utility.\n        if timeout:\n            exec_cmd = [\"timeout\", str(timeout), \"sh\", \"-c\", command]\n        else:\n            exec_cmd = [\"sh\", \"-c\", command]\n\n        exit_code, output = self._container.exec_run(\n            exec_cmd,\n            workdir=self._work_dir,\n        )\n\n        output_str = output.decode(\"utf-8\", errors=\"replace\")\n\n        # Truncate if too long\n        max_output = 100000\n        truncated = len(output_str) &gt; max_output\n        if truncated:\n            output_str = output_str[:max_output]\n\n        return ExecuteResponse(\n            output=output_str,\n            exit_code=exit_code,\n            truncated=truncated,\n        )\n    except Exception as e:\n        return ExecuteResponse(\n            output=f\"Error: {e}\",\n            exit_code=1,\n            truncated=False,\n        )\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.read","title":"<code>read(path, offset=0, limit=2000)</code>","text":"<p>Read file from container using Docker get_archive API.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to the file in the container.</p> required <code>offset</code> <code>int</code> <p>Start line index (for pagination).</p> <code>0</code> <code>limit</code> <code>int</code> <p>Maximum number of lines to return.</p> <code>2000</code> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n    \"\"\"\n    Read file from container using Docker get_archive API.\n\n    Args:\n        path: Path to the file in the container.\n        offset: Start line index (for pagination).\n        limit: Maximum number of lines to return.\n    \"\"\"\n    try:\n        # Read raw bytes from file\n        file_bytes = self._read_bytes(path)\n\n        # Convert bytes to string\n        file_ext = Path(path).suffix.lower().lstrip(\".\")\n        try:\n            full_text = self._convert_bytes_to_text(file_ext, file_bytes)\n        except ValueError as e:\n            return f\"[Error: {e}]\"\n\n        # Split into lines\n        lines = full_text.splitlines()\n        total_lines = len(lines)\n\n        if offset &gt;= total_lines:\n            return \"[End of file]\"\n\n        end_index = offset + limit\n        chunk_lines = lines[offset:end_index]\n        chunk = \"\\n\".join(chunk_lines)\n\n        if end_index &lt; total_lines:\n            remaining = total_lines - end_index\n            footer = f\"\\n\\n[... {remaining} more lines. Use offset={end_index} to read more.]\"\n            return chunk + footer\n\n        return chunk\n\n    except Exception as e:\n        return f\"[Error reading file: {e}]\"\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.write","title":"<code>write(path, content)</code>","text":"<p>Write file to container using Docker put_archive API.</p> <p>This method uses Docker's put_archive() instead of heredoc to handle large files and special characters reliably.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Absolute path where the file should be written.</p> required <code>content</code> <code>str | bytes</code> <p>File content as string or bytes.</p> required <p>Returns:</p> Type Description <code>WriteResult</code> <p>WriteResult with path on success, or error message on failure.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n    \"\"\"Write file to container using Docker put_archive API.\n\n    This method uses Docker's put_archive() instead of heredoc to handle\n    large files and special characters reliably.\n\n    Args:\n        path: Absolute path where the file should be written.\n        content: File content as string or bytes.\n\n    Returns:\n        WriteResult with path on success, or error message on failure.\n    \"\"\"\n    self._ensure_container()\n    assert self._container is not None\n\n    try:\n        # Parse path into directory and filename\n        posix_path = PurePosixPath(path)\n        parent_dir = str(posix_path.parent)\n        filename = posix_path.name\n\n        # Ensure parent directory exists\n        safe_parent_dir = shlex.quote(parent_dir)\n        mkdir_result = self.execute(f\"mkdir -p {safe_parent_dir}\")\n        if mkdir_result.exit_code != 0:\n            return WriteResult(error=f\"Failed to create directory: {mkdir_result.output}\")\n\n        # Create tar archive in memory\n        content = content if isinstance(content, bytes) else content.encode()\n        tar_buffer = io.BytesIO()\n\n        with tarfile.open(fileobj=tar_buffer, mode=\"w\") as tar:\n            # Create TarInfo for the file\n            tarinfo = tarfile.TarInfo(name=filename)\n            tarinfo.size = len(content)\n            tarinfo.mtime = int(time.time())\n            tarinfo.mode = 0o644\n\n            # Add file to archive\n            tar.addfile(tarinfo, io.BytesIO(content))\n\n        # Reset buffer position\n        tar_buffer.seek(0)\n\n        # Upload to container\n        self._container.put_archive(parent_dir, tar_buffer)\n\n        return WriteResult(path=path)\n\n    except Exception as e:\n        return WriteResult(error=f\"Failed to write file: {e}\")\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.start","title":"<code>start()</code>","text":"<p>Explicitly start the container.</p> <p>This is useful for pre-warming containers before use. The container is normally started lazily on first operation.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def start(self) -&gt; None:\n    \"\"\"Explicitly start the container.\n\n    This is useful for pre-warming containers before use.\n    The container is normally started lazily on first operation.\n    \"\"\"\n    self._ensure_container()\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.stop","title":"<code>stop()</code>","text":"<p>Stop and remove the container.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def stop(self) -&gt; None:\n    \"\"\"Stop and remove the container.\"\"\"\n    import contextlib\n\n    container = getattr(self, \"_container\", None)\n    if container is not None:\n        with contextlib.suppress(Exception):\n            container.stop()\n        self._container = None\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.DockerSandbox.is_alive","title":"<code>is_alive()</code>","text":"<p>Check if container is running.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if container is running, False otherwise.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def is_alive(self) -&gt; bool:\n    \"\"\"Check if container is running.\n\n    Returns:\n        True if container is running, False otherwise.\n    \"\"\"\n    if self._container is None:\n        return False\n    try:\n        self._container.reload()\n        return self._container.status == \"running\"\n    except Exception:\n        return False\n</code></pre>"},{"location":"api/docker/#basesandbox","title":"BaseSandbox","text":""},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox","title":"<code>pydantic_ai_backends.backends.docker.sandbox.BaseSandbox</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for sandbox backends.</p> <p>Sandboxes provide isolated environments for executing commands and managing files. Subclasses must implement the execute() method.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>class BaseSandbox(ABC):\n    \"\"\"Abstract base class for sandbox backends.\n\n    Sandboxes provide isolated environments for executing commands and\n    managing files. Subclasses must implement the execute() method.\n    \"\"\"\n\n    def __init__(self, sandbox_id: str | None = None):\n        \"\"\"Initialize the sandbox.\n\n        Args:\n            sandbox_id: Unique identifier for this sandbox. Generated if not provided.\n        \"\"\"\n        self._id = sandbox_id or str(uuid.uuid4())  # pragma: no cover\n\n    @property\n    def id(self) -&gt; str:\n        \"\"\"Unique identifier for this sandbox.\"\"\"\n        return self._id  # pragma: no cover\n\n    @abstractmethod\n    def execute(\n        self, command: str, timeout: int | None = None\n    ) -&gt; ExecuteResponse:  # pragma: no cover\n        \"\"\"Execute a command in the sandbox.\n\n        Args:\n            command: Command to execute.\n            timeout: Maximum execution time in seconds.\n\n        Returns:\n            ExecuteResponse with output, exit code, and truncation status.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def edit(  # pragma: no cover\n        self, path: str, old_string: str, new_string: str, replace_all: bool = False\n    ) -&gt; EditResult:\n        \"\"\"Edit a file by replacing strings.\n\n        Args:\n            path: File path to edit.\n            old_string: String to find and replace.\n            new_string: Replacement string.\n            replace_all: If True, replace all occurrences. Otherwise, replace only first.\n\n        Returns:\n            EditResult with path, error, or occurrence count.\n        \"\"\"\n        ...\n\n    def ls_info(self, path: str) -&gt; list[FileInfo]:  # pragma: no cover\n        \"\"\"List files using ls command.\"\"\"\n        path = shlex.quote(path)\n        result = self.execute(f\"ls -la {path}\")\n        if result.exit_code != 0:\n            return []\n\n        entries: list[FileInfo] = []\n        for line in result.output.strip().split(\"\\n\")[1:]:  # Skip total line\n            if not line.strip():\n                continue\n\n            parts = line.split()\n            if len(parts) &lt; 9:\n                continue\n\n            perms = parts[0]\n            size = int(parts[4]) if parts[4].isdigit() else None\n            name = \" \".join(parts[8:])\n\n            if name in (\".\", \"..\"):\n                continue\n\n            full_path = f\"{path.rstrip('/')}/{name}\"\n            entries.append(\n                FileInfo(\n                    name=name,\n                    path=full_path,\n                    is_dir=perms.startswith(\"d\"),\n                    size=size,\n                )\n            )\n\n        return sorted(entries, key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n\n    def _read_bytes(self, path: str) -&gt; bytes:  # pragma: no cover\n        \"\"\"Read raw bytes from file using cat command.\"\"\"\n        path = shlex.quote(path)\n        result = self.execute(f\"cat {path}\")\n\n        if result.exit_code != 0:\n            return f\"[Error: {result.output}]\".encode()\n\n        return result.output.encode(\"utf-8\", errors=\"replace\")\n\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:  # pragma: no cover\n        \"\"\"Read file using cat command with line numbers.\"\"\"\n        # Use sed to handle offset and limit\n        start = offset + 1  # sed is 1-indexed\n        end = offset + limit\n\n        path = shlex.quote(path)\n        result = self.execute(f\"sed -n '{start},{end}p' {path} | cat -n\")\n\n        if result.exit_code != 0:\n            return f\"Error: {result.output}\"\n\n        if result.truncated:\n            return result.output + \"\\n\\n... (output truncated)\"\n\n        return result.output\n\n    def write(self, path: str, content: str) -&gt; WriteResult:  # pragma: no cover\n        \"\"\"Write file using cat with heredoc.\"\"\"\n        # Escape special characters for heredoc\n        escaped = content.replace(\"\\\\\", \"\\\\\\\\\").replace(\"$\", \"\\\\$\").replace(\"`\", \"\\\\`\")\n\n        # Use a unique delimiter\n        delimiter = f\"EOF_{uuid.uuid4().hex[:8]}\"\n\n        quoted_path = shlex.quote(path)\n        command = (\n            f\"mkdir -p $(dirname {quoted_path}) &amp;&amp; cat &gt; {quoted_path} &lt;&lt; '{delimiter}'\\n\"\n            f\"{escaped}\\n\"\n            f\"{delimiter}\"\n        )\n        result = self.execute(command)\n\n        if result.exit_code != 0:\n            return WriteResult(error=result.output)\n\n        return WriteResult(path=path)\n\n    def glob_info(self, pattern: str, path: str = \"/\") -&gt; list[FileInfo]:  # pragma: no cover\n        \"\"\"Find files using find command.\"\"\"\n        # Convert glob to find pattern\n        path = shlex.quote(path)\n        result = self.execute(f\"find {path} -name '{pattern}' -type f 2&gt;/dev/null\")\n\n        if result.exit_code != 0:\n            return []\n\n        entries: list[FileInfo] = []\n        for file_path in result.output.strip().split(\"\\n\"):\n            if not file_path:\n                continue\n\n            name = file_path.split(\"/\")[-1]\n            entries.append(\n                FileInfo(\n                    name=name,\n                    path=file_path,\n                    is_dir=False,\n                    size=None,\n                )\n            )\n\n        return sorted(entries, key=lambda x: x[\"path\"])\n\n    def grep_raw(  # pragma: no cover\n        self,\n        pattern: str,\n        path: str | None = None,\n        glob: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Search using grep command.\"\"\"\n        search_path = path or \"/\"\n\n        search_path = shlex.quote(search_path)\n\n        options = [\"-rn\"]\n        if ignore_hidden:\n            options.extend([\"--exclude='.*'\", \"--exclude-dir='.*'\"])\n        if glob:\n            options.append(f\"--include='{glob}'\")\n\n        options_str = \" \".join(options)\n        cmd = f\"grep {options_str} '{pattern}' {search_path}\"\n\n        result = self.execute(cmd)\n\n        if result.exit_code == 1:  # No matches\n            return []\n        if result.exit_code != 0:\n            return f\"Error: {result.output}\"\n\n        matches: list[GrepMatch] = []\n        for line in result.output.strip().split(\"\\n\"):\n            if not line:\n                continue\n\n            # Parse grep output: file:line:content\n            parts = line.split(\":\", 2)\n            if len(parts) &gt;= 3:\n                try:\n                    matches.append(\n                        GrepMatch(\n                            path=parts[0],\n                            line_number=int(parts[1]),\n                            line=parts[2],\n                        )\n                    )\n                except ValueError:\n                    continue\n\n        return matches\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.id","title":"<code>id</code>  <code>property</code>","text":"<p>Unique identifier for this sandbox.</p>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.__init__","title":"<code>__init__(sandbox_id=None)</code>","text":"<p>Initialize the sandbox.</p> <p>Parameters:</p> Name Type Description Default <code>sandbox_id</code> <code>str | None</code> <p>Unique identifier for this sandbox. Generated if not provided.</p> <code>None</code> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def __init__(self, sandbox_id: str | None = None):\n    \"\"\"Initialize the sandbox.\n\n    Args:\n        sandbox_id: Unique identifier for this sandbox. Generated if not provided.\n    \"\"\"\n    self._id = sandbox_id or str(uuid.uuid4())  # pragma: no cover\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.execute","title":"<code>execute(command, timeout=None)</code>  <code>abstractmethod</code>","text":"<p>Execute a command in the sandbox.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>Command to execute.</p> required <code>timeout</code> <code>int | None</code> <p>Maximum execution time in seconds.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExecuteResponse</code> <p>ExecuteResponse with output, exit code, and truncation status.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>@abstractmethod\ndef execute(\n    self, command: str, timeout: int | None = None\n) -&gt; ExecuteResponse:  # pragma: no cover\n    \"\"\"Execute a command in the sandbox.\n\n    Args:\n        command: Command to execute.\n        timeout: Maximum execution time in seconds.\n\n    Returns:\n        ExecuteResponse with output, exit code, and truncation status.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.ls_info","title":"<code>ls_info(path)</code>","text":"<p>List files using ls command.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def ls_info(self, path: str) -&gt; list[FileInfo]:  # pragma: no cover\n    \"\"\"List files using ls command.\"\"\"\n    path = shlex.quote(path)\n    result = self.execute(f\"ls -la {path}\")\n    if result.exit_code != 0:\n        return []\n\n    entries: list[FileInfo] = []\n    for line in result.output.strip().split(\"\\n\")[1:]:  # Skip total line\n        if not line.strip():\n            continue\n\n        parts = line.split()\n        if len(parts) &lt; 9:\n            continue\n\n        perms = parts[0]\n        size = int(parts[4]) if parts[4].isdigit() else None\n        name = \" \".join(parts[8:])\n\n        if name in (\".\", \"..\"):\n            continue\n\n        full_path = f\"{path.rstrip('/')}/{name}\"\n        entries.append(\n            FileInfo(\n                name=name,\n                path=full_path,\n                is_dir=perms.startswith(\"d\"),\n                size=size,\n            )\n        )\n\n    return sorted(entries, key=lambda x: (not x[\"is_dir\"], x[\"name\"]))\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.read","title":"<code>read(path, offset=0, limit=2000)</code>","text":"<p>Read file using cat command with line numbers.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:  # pragma: no cover\n    \"\"\"Read file using cat command with line numbers.\"\"\"\n    # Use sed to handle offset and limit\n    start = offset + 1  # sed is 1-indexed\n    end = offset + limit\n\n    path = shlex.quote(path)\n    result = self.execute(f\"sed -n '{start},{end}p' {path} | cat -n\")\n\n    if result.exit_code != 0:\n        return f\"Error: {result.output}\"\n\n    if result.truncated:\n        return result.output + \"\\n\\n... (output truncated)\"\n\n    return result.output\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.write","title":"<code>write(path, content)</code>","text":"<p>Write file using cat with heredoc.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def write(self, path: str, content: str) -&gt; WriteResult:  # pragma: no cover\n    \"\"\"Write file using cat with heredoc.\"\"\"\n    # Escape special characters for heredoc\n    escaped = content.replace(\"\\\\\", \"\\\\\\\\\").replace(\"$\", \"\\\\$\").replace(\"`\", \"\\\\`\")\n\n    # Use a unique delimiter\n    delimiter = f\"EOF_{uuid.uuid4().hex[:8]}\"\n\n    quoted_path = shlex.quote(path)\n    command = (\n        f\"mkdir -p $(dirname {quoted_path}) &amp;&amp; cat &gt; {quoted_path} &lt;&lt; '{delimiter}'\\n\"\n        f\"{escaped}\\n\"\n        f\"{delimiter}\"\n    )\n    result = self.execute(command)\n\n    if result.exit_code != 0:\n        return WriteResult(error=result.output)\n\n    return WriteResult(path=path)\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.edit","title":"<code>edit(path, old_string, new_string, replace_all=False)</code>  <code>abstractmethod</code>","text":"<p>Edit a file by replacing strings.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>File path to edit.</p> required <code>old_string</code> <code>str</code> <p>String to find and replace.</p> required <code>new_string</code> <code>str</code> <p>Replacement string.</p> required <code>replace_all</code> <code>bool</code> <p>If True, replace all occurrences. Otherwise, replace only first.</p> <code>False</code> <p>Returns:</p> Type Description <code>EditResult</code> <p>EditResult with path, error, or occurrence count.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>@abstractmethod\ndef edit(  # pragma: no cover\n    self, path: str, old_string: str, new_string: str, replace_all: bool = False\n) -&gt; EditResult:\n    \"\"\"Edit a file by replacing strings.\n\n    Args:\n        path: File path to edit.\n        old_string: String to find and replace.\n        new_string: Replacement string.\n        replace_all: If True, replace all occurrences. Otherwise, replace only first.\n\n    Returns:\n        EditResult with path, error, or occurrence count.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.glob_info","title":"<code>glob_info(pattern, path='/')</code>","text":"<p>Find files using find command.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def glob_info(self, pattern: str, path: str = \"/\") -&gt; list[FileInfo]:  # pragma: no cover\n    \"\"\"Find files using find command.\"\"\"\n    # Convert glob to find pattern\n    path = shlex.quote(path)\n    result = self.execute(f\"find {path} -name '{pattern}' -type f 2&gt;/dev/null\")\n\n    if result.exit_code != 0:\n        return []\n\n    entries: list[FileInfo] = []\n    for file_path in result.output.strip().split(\"\\n\"):\n        if not file_path:\n            continue\n\n        name = file_path.split(\"/\")[-1]\n        entries.append(\n            FileInfo(\n                name=name,\n                path=file_path,\n                is_dir=False,\n                size=None,\n            )\n        )\n\n    return sorted(entries, key=lambda x: x[\"path\"])\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.sandbox.BaseSandbox.grep_raw","title":"<code>grep_raw(pattern, path=None, glob=None, ignore_hidden=True)</code>","text":"<p>Search using grep command.</p> Source code in <code>src/pydantic_ai_backends/backends/docker/sandbox.py</code> Python<pre><code>def grep_raw(  # pragma: no cover\n    self,\n    pattern: str,\n    path: str | None = None,\n    glob: str | None = None,\n    ignore_hidden: bool = True,\n) -&gt; list[GrepMatch] | str:\n    \"\"\"Search using grep command.\"\"\"\n    search_path = path or \"/\"\n\n    search_path = shlex.quote(search_path)\n\n    options = [\"-rn\"]\n    if ignore_hidden:\n        options.extend([\"--exclude='.*'\", \"--exclude-dir='.*'\"])\n    if glob:\n        options.append(f\"--include='{glob}'\")\n\n    options_str = \" \".join(options)\n    cmd = f\"grep {options_str} '{pattern}' {search_path}\"\n\n    result = self.execute(cmd)\n\n    if result.exit_code == 1:  # No matches\n        return []\n    if result.exit_code != 0:\n        return f\"Error: {result.output}\"\n\n    matches: list[GrepMatch] = []\n    for line in result.output.strip().split(\"\\n\"):\n        if not line:\n            continue\n\n        # Parse grep output: file:line:content\n        parts = line.split(\":\", 2)\n        if len(parts) &gt;= 3:\n            try:\n                matches.append(\n                    GrepMatch(\n                        path=parts[0],\n                        line_number=int(parts[1]),\n                        line=parts[2],\n                    )\n                )\n            except ValueError:\n                continue\n\n    return matches\n</code></pre>"},{"location":"api/docker/#sessionmanager","title":"SessionManager","text":""},{"location":"api/docker/#pydantic_ai_backends.backends.docker.session.SessionManager","title":"<code>pydantic_ai_backends.backends.docker.session.SessionManager</code>","text":"<p>Manages user sessions and their Docker containers.</p> <p>This class provides a way to manage multiple Docker sandbox instances for different user sessions. It handles: - Creating new sandboxes for new sessions - Reusing existing sandboxes for returning sessions - Cleaning up idle sessions automatically</p> Example Python<pre><code>from pydantic_ai_backends import SessionManager\n\nmanager = SessionManager(default_runtime=\"python-datascience\")\n\n# Get sandbox for user\nsandbox = await manager.get_or_create(\"user-123\")\n\n# Later: cleanup idle sessions\ncleaned = await manager.cleanup_idle(max_idle=1800)  # 30 min\nprint(f\"Cleaned up {cleaned} idle sessions\")\n</code></pre> Source code in <code>src/pydantic_ai_backends/backends/docker/session.py</code> Python<pre><code>class SessionManager:\n    \"\"\"Manages user sessions and their Docker containers.\n\n    This class provides a way to manage multiple Docker sandbox instances\n    for different user sessions. It handles:\n    - Creating new sandboxes for new sessions\n    - Reusing existing sandboxes for returning sessions\n    - Cleaning up idle sessions automatically\n\n    Example:\n        ```python\n        from pydantic_ai_backends import SessionManager\n\n        manager = SessionManager(default_runtime=\"python-datascience\")\n\n        # Get sandbox for user\n        sandbox = await manager.get_or_create(\"user-123\")\n\n        # Later: cleanup idle sessions\n        cleaned = await manager.cleanup_idle(max_idle=1800)  # 30 min\n        print(f\"Cleaned up {cleaned} idle sessions\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        default_runtime: RuntimeConfig | str | None = None,\n        default_idle_timeout: int = 3600,\n        workspace_root: str | Path | None = None,\n    ):\n        \"\"\"Initialize the session manager.\n\n        Args:\n            default_runtime: Default RuntimeConfig or name for new sandboxes.\n            default_idle_timeout: Default idle timeout in seconds (default: 1 hour).\n            workspace_root: Root directory for persistent session storage.\n                           If set, creates {workspace_root}/{session_id}/workspace\n                           and mounts it as a volume. Files persist across container restarts.\n        \"\"\"\n        self._sessions: dict[str, DockerSandbox] = {}\n        self._default_runtime = default_runtime\n        self._default_idle_timeout = default_idle_timeout\n        self._cleanup_task: asyncio.Task[None] | None = None\n        self._workspace_root = Path(workspace_root) if workspace_root else None\n\n    @property\n    def sessions(self) -&gt; dict[str, DockerSandbox]:\n        \"\"\"Active sessions dictionary (read-only access).\"\"\"\n        return dict(self._sessions)\n\n    @property\n    def session_count(self) -&gt; int:\n        \"\"\"Number of active sessions.\"\"\"\n        return len(self._sessions)\n\n    async def get_or_create(\n        self,\n        session_id: str,\n        runtime: RuntimeConfig | str | None = None,\n    ) -&gt; DockerSandbox:\n        \"\"\"Get an existing sandbox or create a new one.\n\n        If a sandbox exists for the session_id and is still alive,\n        it will be returned. Otherwise, a new sandbox will be created.\n\n        Args:\n            session_id: Unique identifier for the session.\n            runtime: RuntimeConfig or name to use (defaults to manager's default).\n\n        Returns:\n            DockerSandbox instance for the session.\n\n        Raises:\n            ValueError: If no runtime specified and no default runtime set.\n        \"\"\"\n        from pydantic_ai_backends.backends.docker.sandbox import DockerSandbox\n\n        # Check for existing session\n        if session_id in self._sessions:\n            sandbox = self._sessions[session_id]\n            if sandbox.is_alive():\n                sandbox._last_activity = time.time()\n                return sandbox\n            # Container died, remove from cache\n            del self._sessions[session_id]\n\n        # Prepare volumes for persistent storage\n        volumes: dict[str, str] | None = None\n        if self._workspace_root:\n            session_workspace = self._workspace_root / session_id / \"workspace\"\n            session_workspace.mkdir(parents=True, exist_ok=True)\n            volumes = {str(session_workspace.resolve()): \"/workspace\"}\n\n        # Create new sandbox\n        effective_runtime = runtime or self._default_runtime\n        sandbox = DockerSandbox(\n            runtime=effective_runtime,\n            session_id=session_id,\n            idle_timeout=self._default_idle_timeout,\n            volumes=volumes,\n        )\n        sandbox.start()\n        self._sessions[session_id] = sandbox\n        return sandbox\n\n    async def release(self, session_id: str) -&gt; bool:\n        \"\"\"Release a session and stop its container.\n\n        Args:\n            session_id: Session identifier to release.\n\n        Returns:\n            True if session was found and released, False otherwise.\n        \"\"\"\n        if session_id not in self._sessions:\n            return False\n\n        sandbox = self._sessions.pop(session_id)\n        sandbox.stop()\n        return True\n\n    async def cleanup_idle(self, max_idle: int | None = None) -&gt; int:\n        \"\"\"Clean up idle sessions.\n\n        Removes and stops sandboxes that have been idle for longer than\n        the specified time.\n\n        Args:\n            max_idle: Maximum idle time in seconds. Uses default if not specified.\n\n        Returns:\n            Number of sessions cleaned up.\n        \"\"\"\n        max_idle = max_idle if max_idle is not None else self._default_idle_timeout\n        now = time.time()\n        to_remove: list[str] = []\n\n        for session_id, sandbox in self._sessions.items():\n            if now - sandbox._last_activity &gt; max_idle:\n                to_remove.append(session_id)\n\n        for session_id in to_remove:\n            await self.release(session_id)\n\n        return len(to_remove)\n\n    def start_cleanup_loop(self, interval: int = 300) -&gt; None:\n        \"\"\"Start background cleanup loop.\n\n        Periodically cleans up idle sessions.\n\n        Args:\n            interval: Cleanup interval in seconds (default: 5 minutes).\n        \"\"\"\n        if self._cleanup_task is not None:\n            return  # Already running\n\n        async def _loop() -&gt; None:  # pragma: no cover\n            while True:\n                await asyncio.sleep(interval)\n                await self.cleanup_idle()\n\n        self._cleanup_task = asyncio.create_task(_loop())\n\n    def stop_cleanup_loop(self) -&gt; None:\n        \"\"\"Stop the background cleanup loop.\"\"\"\n        if self._cleanup_task is not None:\n            self._cleanup_task.cancel()\n            self._cleanup_task = None\n\n    async def shutdown(self) -&gt; int:\n        \"\"\"Shutdown all sessions and stop cleanup loop.\n\n        Returns:\n            Number of sessions that were stopped.\n        \"\"\"\n        self.stop_cleanup_loop()\n\n        count = len(self._sessions)\n        session_ids = list(self._sessions.keys())\n\n        for session_id in session_ids:\n            await self.release(session_id)\n\n        return count\n\n    def __contains__(self, session_id: str) -&gt; bool:\n        \"\"\"Check if a session exists.\"\"\"\n        return session_id in self._sessions\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return number of active sessions.\"\"\"\n        return len(self._sessions)\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.backends.docker.session.SessionManager.__init__","title":"<code>__init__(default_runtime=None, default_idle_timeout=3600, workspace_root=None)</code>","text":"<p>Initialize the session manager.</p> <p>Parameters:</p> Name Type Description Default <code>default_runtime</code> <code>RuntimeConfig | str | None</code> <p>Default RuntimeConfig or name for new sandboxes.</p> <code>None</code> <code>default_idle_timeout</code> <code>int</code> <p>Default idle timeout in seconds (default: 1 hour).</p> <code>3600</code> <code>workspace_root</code> <code>str | Path | None</code> <p>Root directory for persistent session storage.            If set, creates {workspace_root}/{session_id}/workspace            and mounts it as a volume. Files persist across container restarts.</p> <code>None</code> Source code in <code>src/pydantic_ai_backends/backends/docker/session.py</code> Python<pre><code>def __init__(\n    self,\n    default_runtime: RuntimeConfig | str | None = None,\n    default_idle_timeout: int = 3600,\n    workspace_root: str | Path | None = None,\n):\n    \"\"\"Initialize the session manager.\n\n    Args:\n        default_runtime: Default RuntimeConfig or name for new sandboxes.\n        default_idle_timeout: Default idle timeout in seconds (default: 1 hour).\n        workspace_root: Root directory for persistent session storage.\n                       If set, creates {workspace_root}/{session_id}/workspace\n                       and mounts it as a volume. Files persist across container restarts.\n    \"\"\"\n    self._sessions: dict[str, DockerSandbox] = {}\n    self._default_runtime = default_runtime\n    self._default_idle_timeout = default_idle_timeout\n    self._cleanup_task: asyncio.Task[None] | None = None\n    self._workspace_root = Path(workspace_root) if workspace_root else None\n</code></pre>"},{"location":"api/docker/#runtimeconfig","title":"RuntimeConfig","text":""},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig","title":"<code>pydantic_ai_backends.types.RuntimeConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a Docker runtime environment.</p> <p>A runtime defines a pre-configured execution environment with specific packages and settings. Can be used with DockerSandbox to provide ready-to-use environments without manual package installation.</p> Example Python<pre><code>from pydantic_ai_backends import RuntimeConfig, DockerSandbox\n\n# Custom runtime with ML packages\nml_runtime = RuntimeConfig(\n    name=\"ml-env\",\n    description=\"Machine learning environment\",\n    base_image=\"python:3.12-slim\",\n    packages=[\"torch\", \"transformers\", \"datasets\"],\n)\n\nsandbox = DockerSandbox(runtime=ml_runtime)\n</code></pre> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>class RuntimeConfig(BaseModel):\n    \"\"\"Configuration for a Docker runtime environment.\n\n    A runtime defines a pre-configured execution environment with specific\n    packages and settings. Can be used with DockerSandbox to provide\n    ready-to-use environments without manual package installation.\n\n    Example:\n        ```python\n        from pydantic_ai_backends import RuntimeConfig, DockerSandbox\n\n        # Custom runtime with ML packages\n        ml_runtime = RuntimeConfig(\n            name=\"ml-env\",\n            description=\"Machine learning environment\",\n            base_image=\"python:3.12-slim\",\n            packages=[\"torch\", \"transformers\", \"datasets\"],\n        )\n\n        sandbox = DockerSandbox(runtime=ml_runtime)\n        ```\n    \"\"\"\n\n    name: str\n    \"\"\"Unique name for the runtime (e.g., \"python-datascience\").\"\"\"\n\n    description: str = \"\"\n    \"\"\"Human-readable description of the runtime.\"\"\"\n\n    # Image source (one of these)\n    image: str | None = None\n    \"\"\"Ready-to-use Docker image (e.g., \"myregistry/python-ds:v1\").\"\"\"\n\n    base_image: str | None = None\n    \"\"\"Base image to build upon (e.g., \"python:3.12-slim\").\"\"\"\n\n    # Packages to install (only if base_image)\n    packages: list[str] = []\n    \"\"\"Packages to install (e.g., [\"pandas\", \"numpy\", \"matplotlib\"]).\"\"\"\n\n    package_manager: Literal[\"pip\", \"npm\", \"apt\", \"cargo\"] = \"pip\"\n    \"\"\"Package manager to use for installation.\"\"\"\n\n    # Additional configuration\n    setup_commands: list[str] = []\n    \"\"\"Additional setup commands to run (e.g., [\"apt-get update\"]).\"\"\"\n\n    env_vars: dict[str, str] = {}\n    \"\"\"Environment variables to set in the container.\"\"\"\n\n    work_dir: str = \"/workspace\"\n    \"\"\"Working directory inside the container.\"\"\"\n\n    # Cache settings\n    cache_image: bool = True\n    \"\"\"Whether to cache the built image locally.\"\"\"\n</code></pre>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.name","title":"<code>name</code>  <code>instance-attribute</code>","text":"<p>Unique name for the runtime (e.g., \"python-datascience\").</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.description","title":"<code>description = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Human-readable description of the runtime.</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.image","title":"<code>image = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ready-to-use Docker image (e.g., \"myregistry/python-ds:v1\").</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.base_image","title":"<code>base_image = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Base image to build upon (e.g., \"python:3.12-slim\").</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.packages","title":"<code>packages = []</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Packages to install (e.g., [\"pandas\", \"numpy\", \"matplotlib\"]).</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.package_manager","title":"<code>package_manager = 'pip'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Package manager to use for installation.</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.setup_commands","title":"<code>setup_commands = []</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Additional setup commands to run (e.g., [\"apt-get update\"]).</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.env_vars","title":"<code>env_vars = {}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Environment variables to set in the container.</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.work_dir","title":"<code>work_dir = '/workspace'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Working directory inside the container.</p>"},{"location":"api/docker/#pydantic_ai_backends.types.RuntimeConfig.cache_image","title":"<code>cache_image = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to cache the built image locally.</p>"},{"location":"api/docker/#built-in-runtimes","title":"Built-in Runtimes","text":"Python<pre><code>from pydantic_ai_backends import BUILTIN_RUNTIMES\n\n# Available runtimes\nprint(BUILTIN_RUNTIMES.keys())\n# dict_keys(['python-minimal', 'python-datascience', 'python-web', 'node-minimal', 'node-react'])\n\n# Use a runtime\nfrom pydantic_ai_backends import DockerSandbox\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n</code></pre> Runtime Base Image Packages <code>python-minimal</code> python:3.12-slim (none) <code>python-datascience</code> python:3.12-slim pandas, numpy, matplotlib, scikit-learn, seaborn <code>python-web</code> python:3.12-slim fastapi, uvicorn, sqlalchemy, httpx <code>node-minimal</code> node:20-slim (none) <code>node-react</code> node:20-slim typescript, vite, react, react-dom, @types/react"},{"location":"api/permissions/","title":"Permissions API","text":""},{"location":"api/permissions/#types","title":"Types","text":""},{"location":"api/permissions/#permissionaction","title":"PermissionAction","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionAction","title":"<code>pydantic_ai_backends.permissions.types.PermissionAction = Literal['allow', 'deny', 'ask']</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#permissionoperation","title":"PermissionOperation","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionOperation","title":"<code>pydantic_ai_backends.permissions.types.PermissionOperation = Literal['read', 'write', 'edit', 'execute', 'glob', 'grep', 'ls']</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#permissionrule","title":"PermissionRule","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRule","title":"<code>pydantic_ai_backends.permissions.types.PermissionRule</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A rule that matches paths/commands and specifies an action.</p> <p>Rules are evaluated in order - first matching rule wins. Patterns use fnmatch-style matching with support for <code>**</code> (recursive).</p> Example Python<pre><code># Deny access to .env files\nPermissionRule(\n    pattern=\"**/.env*\",\n    action=\"deny\",\n    description=\"Protect environment files\",\n)\n\n# Ask before writing to config files\nPermissionRule(\n    pattern=\"**/config/**\",\n    action=\"ask\",\n    description=\"Confirm config changes\",\n)\n</code></pre> Source code in <code>src/pydantic_ai_backends/permissions/types.py</code> Python<pre><code>class PermissionRule(BaseModel):\n    \"\"\"A rule that matches paths/commands and specifies an action.\n\n    Rules are evaluated in order - first matching rule wins.\n    Patterns use fnmatch-style matching with support for `**` (recursive).\n\n    Example:\n        ```python\n        # Deny access to .env files\n        PermissionRule(\n            pattern=\"**/.env*\",\n            action=\"deny\",\n            description=\"Protect environment files\",\n        )\n\n        # Ask before writing to config files\n        PermissionRule(\n            pattern=\"**/config/**\",\n            action=\"ask\",\n            description=\"Confirm config changes\",\n        )\n        ```\n    \"\"\"\n\n    pattern: str\n    \"\"\"Glob pattern to match against paths or commands.\n\n    Supports fnmatch patterns:\n    - `*` matches any characters except `/`\n    - `**` matches any characters including `/` (recursive)\n    - `?` matches any single character\n    - `[seq]` matches any character in seq\n    \"\"\"\n\n    action: PermissionAction\n    \"\"\"Action to take when pattern matches: \"allow\", \"deny\", or \"ask\".\"\"\"\n\n    description: str = \"\"\n    \"\"\"Human-readable description of why this rule exists.\"\"\"\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRule.pattern","title":"<code>pattern</code>  <code>instance-attribute</code>","text":"<p>Glob pattern to match against paths or commands.</p> <p>Supports fnmatch patterns: - <code>*</code> matches any characters except <code>/</code> - <code>**</code> matches any characters including <code>/</code> (recursive) - <code>?</code> matches any single character - <code>[seq]</code> matches any character in seq</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRule.action","title":"<code>action</code>  <code>instance-attribute</code>","text":"<p>Action to take when pattern matches: \"allow\", \"deny\", or \"ask\".</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRule.description","title":"<code>description = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Human-readable description of why this rule exists.</p>"},{"location":"api/permissions/#operationpermissions","title":"OperationPermissions","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.OperationPermissions","title":"<code>pydantic_ai_backends.permissions.types.OperationPermissions</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Permissions configuration for a single operation type.</p> <p>Contains a default action and a list of rules that override the default for specific patterns.</p> Example Python<pre><code>OperationPermissions(\n    default=\"allow\",\n    rules=[\n        PermissionRule(pattern=\"**/.env*\", action=\"deny\"),\n        PermissionRule(pattern=\"**/secrets/**\", action=\"deny\"),\n    ],\n)\n</code></pre> Source code in <code>src/pydantic_ai_backends/permissions/types.py</code> Python<pre><code>class OperationPermissions(BaseModel):\n    \"\"\"Permissions configuration for a single operation type.\n\n    Contains a default action and a list of rules that override\n    the default for specific patterns.\n\n    Example:\n        ```python\n        OperationPermissions(\n            default=\"allow\",\n            rules=[\n                PermissionRule(pattern=\"**/.env*\", action=\"deny\"),\n                PermissionRule(pattern=\"**/secrets/**\", action=\"deny\"),\n            ],\n        )\n        ```\n    \"\"\"\n\n    default: PermissionAction = \"allow\"\n    \"\"\"Default action when no rule matches.\"\"\"\n\n    rules: list[PermissionRule] = Field(default_factory=list)\n    \"\"\"Rules evaluated in order - first match wins.\"\"\"\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.OperationPermissions.default","title":"<code>default = 'allow'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Default action when no rule matches.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.OperationPermissions.rules","title":"<code>rules = Field(default_factory=list)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Rules evaluated in order - first match wins.</p>"},{"location":"api/permissions/#permissionruleset","title":"PermissionRuleset","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset","title":"<code>pydantic_ai_backends.permissions.types.PermissionRuleset</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Complete permissions configuration for all operations.</p> <p>Defines default behavior and per-operation permissions. Each operation can have its own default and rules.</p> Example Python<pre><code>ruleset = PermissionRuleset(\n    default=\"deny\",  # Default deny everything\n    read=OperationPermissions(default=\"allow\"),  # But allow reads\n    write=OperationPermissions(\n        default=\"ask\",  # Ask before writing\n        rules=[\n            PermissionRule(pattern=\"**/temp/**\", action=\"allow\"),\n        ],\n    ),\n)\n</code></pre> Source code in <code>src/pydantic_ai_backends/permissions/types.py</code> Python<pre><code>class PermissionRuleset(BaseModel):\n    \"\"\"Complete permissions configuration for all operations.\n\n    Defines default behavior and per-operation permissions.\n    Each operation can have its own default and rules.\n\n    Example:\n        ```python\n        ruleset = PermissionRuleset(\n            default=\"deny\",  # Default deny everything\n            read=OperationPermissions(default=\"allow\"),  # But allow reads\n            write=OperationPermissions(\n                default=\"ask\",  # Ask before writing\n                rules=[\n                    PermissionRule(pattern=\"**/temp/**\", action=\"allow\"),\n                ],\n            ),\n        )\n        ```\n    \"\"\"\n\n    default: PermissionAction = \"ask\"\n    \"\"\"Global default action when operation has no specific config.\"\"\"\n\n    read: OperationPermissions | None = None\n    \"\"\"Permissions for read operations.\"\"\"\n\n    write: OperationPermissions | None = None\n    \"\"\"Permissions for write operations.\"\"\"\n\n    edit: OperationPermissions | None = None\n    \"\"\"Permissions for edit operations.\"\"\"\n\n    execute: OperationPermissions | None = None\n    \"\"\"Permissions for execute operations (shell commands).\"\"\"\n\n    glob: OperationPermissions | None = None\n    \"\"\"Permissions for glob operations.\"\"\"\n\n    grep: OperationPermissions | None = None\n    \"\"\"Permissions for grep operations.\"\"\"\n\n    ls: OperationPermissions | None = None\n    \"\"\"Permissions for ls operations.\"\"\"\n\n    def get_operation_permissions(self, operation: PermissionOperation) -&gt; OperationPermissions:\n        \"\"\"Get permissions for a specific operation.\n\n        Returns the operation-specific permissions if defined,\n        otherwise creates default permissions using the global default.\n\n        Args:\n            operation: The operation type to get permissions for.\n\n        Returns:\n            OperationPermissions for the specified operation.\n        \"\"\"\n        op_perms: OperationPermissions | None = getattr(self, operation, None)\n        if op_perms is not None:\n            return op_perms\n        return OperationPermissions(default=self.default)\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.default","title":"<code>default = 'ask'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Global default action when operation has no specific config.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.read","title":"<code>read = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for read operations.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.write","title":"<code>write = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for write operations.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.edit","title":"<code>edit = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for edit operations.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.execute","title":"<code>execute = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for execute operations (shell commands).</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.glob","title":"<code>glob = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for glob operations.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.grep","title":"<code>grep = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for grep operations.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.ls","title":"<code>ls = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Permissions for ls operations.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.types.PermissionRuleset.get_operation_permissions","title":"<code>get_operation_permissions(operation)</code>","text":"<p>Get permissions for a specific operation.</p> <p>Returns the operation-specific permissions if defined, otherwise creates default permissions using the global default.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>PermissionOperation</code> <p>The operation type to get permissions for.</p> required <p>Returns:</p> Type Description <code>OperationPermissions</code> <p>OperationPermissions for the specified operation.</p> Source code in <code>src/pydantic_ai_backends/permissions/types.py</code> Python<pre><code>def get_operation_permissions(self, operation: PermissionOperation) -&gt; OperationPermissions:\n    \"\"\"Get permissions for a specific operation.\n\n    Returns the operation-specific permissions if defined,\n    otherwise creates default permissions using the global default.\n\n    Args:\n        operation: The operation type to get permissions for.\n\n    Returns:\n        OperationPermissions for the specified operation.\n    \"\"\"\n    op_perms: OperationPermissions | None = getattr(self, operation, None)\n    if op_perms is not None:\n        return op_perms\n    return OperationPermissions(default=self.default)\n</code></pre>"},{"location":"api/permissions/#checker","title":"Checker","text":""},{"location":"api/permissions/#permissionchecker","title":"PermissionChecker","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker","title":"<code>pydantic_ai_backends.permissions.checker.PermissionChecker</code>","text":"<p>Checks operations against a permission ruleset.</p> <p>The checker evaluates rules in order and uses the first matching rule's action. If no rule matches, the operation's default action is used. If no operation-specific permissions exist, the global default is used.</p> Example Python<pre><code>from pydantic_ai_backends.permissions import (\n    PermissionChecker,\n    DEFAULT_RULESET,\n)\n\nasync def ask_user(op: str, target: str, reason: str) -&gt; bool:\n    return input(f\"Allow {op} on {target}? \").lower() == \"y\"\n\nchecker = PermissionChecker(\n    ruleset=DEFAULT_RULESET,\n    ask_callback=ask_user,\n)\n\n# Synchronous check (returns action without asking)\naction = checker.check_sync(\"read\", \"/path/to/file\")\n\n# Async check (handles \"ask\" via callback)\nallowed = await checker.check(\"write\", \"/path/to/file\", \"Save changes\")\n</code></pre> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>class PermissionChecker:\n    \"\"\"Checks operations against a permission ruleset.\n\n    The checker evaluates rules in order and uses the first matching rule's\n    action. If no rule matches, the operation's default action is used.\n    If no operation-specific permissions exist, the global default is used.\n\n    Example:\n        ```python\n        from pydantic_ai_backends.permissions import (\n            PermissionChecker,\n            DEFAULT_RULESET,\n        )\n\n        async def ask_user(op: str, target: str, reason: str) -&gt; bool:\n            return input(f\"Allow {op} on {target}? \").lower() == \"y\"\n\n        checker = PermissionChecker(\n            ruleset=DEFAULT_RULESET,\n            ask_callback=ask_user,\n        )\n\n        # Synchronous check (returns action without asking)\n        action = checker.check_sync(\"read\", \"/path/to/file\")\n\n        # Async check (handles \"ask\" via callback)\n        allowed = await checker.check(\"write\", \"/path/to/file\", \"Save changes\")\n        ```\n    \"\"\"\n\n    def __init__(\n        self,\n        ruleset: PermissionRuleset,\n        ask_callback: AskCallback | None = None,\n        ask_fallback: AskFallback = \"error\",\n    ):\n        \"\"\"Initialize the permission checker.\n\n        Args:\n            ruleset: The permission ruleset to check against.\n            ask_callback: Async callback for \"ask\" actions. Receives\n                (operation, target, reason) and returns True to allow.\n            ask_fallback: What to do when ask_callback is None or needed\n                but not available. \"deny\" returns False, \"error\" raises.\n        \"\"\"\n        self._ruleset = ruleset\n        self._ask_callback = ask_callback\n        self._ask_fallback = ask_fallback\n\n    @property\n    def ruleset(self) -&gt; PermissionRuleset:\n        \"\"\"The permission ruleset being used.\"\"\"\n        return self._ruleset\n\n    def check_sync(\n        self,\n        operation: PermissionOperation,\n        target: str,\n    ) -&gt; PermissionAction:\n        \"\"\"Check permission synchronously without invoking callbacks.\n\n        This method evaluates rules and returns the action without\n        executing any callbacks. Use this when you need to know what\n        action would be taken.\n\n        Args:\n            operation: The operation type (read, write, etc.).\n            target: The path or command being accessed.\n\n        Returns:\n            The permission action: \"allow\", \"deny\", or \"ask\".\n        \"\"\"\n        op_perms = self._ruleset.get_operation_permissions(operation)\n\n        # Check rules in order - first match wins\n        for rule in op_perms.rules:\n            if _matches_pattern(target, rule.pattern):\n                return rule.action\n\n        # No rule matched, use default\n        return op_perms.default\n\n    def _find_matching_rule(\n        self,\n        operation: PermissionOperation,\n        target: str,\n    ) -&gt; PermissionRule | None:\n        \"\"\"Find the first matching rule for an operation and target.\n\n        Args:\n            operation: The operation type.\n            target: The path or command.\n\n        Returns:\n            The matching rule, or None if no rule matches.\n        \"\"\"\n        op_perms = self._ruleset.get_operation_permissions(operation)\n\n        for rule in op_perms.rules:\n            if _matches_pattern(target, rule.pattern):\n                return rule\n\n        return None\n\n    async def check(\n        self,\n        operation: PermissionOperation,\n        target: str,\n        reason: str = \"\",\n    ) -&gt; bool:\n        \"\"\"Check permission asynchronously with callback support.\n\n        Evaluates rules and handles \"ask\" actions via the callback.\n        For \"allow\" returns True, for \"deny\" raises PermissionDeniedError.\n\n        Args:\n            operation: The operation type (read, write, etc.).\n            target: The path or command being accessed.\n            reason: Human-readable reason for the operation.\n\n        Returns:\n            True if the operation is allowed.\n\n        Raises:\n            PermissionDeniedError: If the operation is explicitly denied.\n            PermissionError: If ask_fallback=\"error\" and callback unavailable.\n        \"\"\"\n        action = self.check_sync(operation, target)\n\n        if action == \"allow\":\n            return True\n\n        if action == \"deny\":\n            rule = self._find_matching_rule(operation, target)\n            raise PermissionDeniedError(operation, target, rule)\n\n        # Action is \"ask\"\n        if self._ask_callback is not None:\n            allowed = await self._ask_callback(operation, target, reason)\n            if allowed:\n                return True\n            raise PermissionDeniedError(operation, target)\n\n        # No callback available\n        if self._ask_fallback == \"error\":\n            raise PermissionError(operation, target, reason)\n\n        # ask_fallback == \"deny\"\n        raise PermissionDeniedError(operation, target)\n\n    def is_allowed(\n        self,\n        operation: PermissionOperation,\n        target: str,\n    ) -&gt; bool:\n        \"\"\"Check if an operation would be immediately allowed.\n\n        This is a convenience method that returns True only if the\n        operation would be allowed without needing to ask.\n\n        Args:\n            operation: The operation type.\n            target: The path or command.\n\n        Returns:\n            True if action is \"allow\", False otherwise.\n        \"\"\"\n        return self.check_sync(operation, target) == \"allow\"\n\n    def is_denied(\n        self,\n        operation: PermissionOperation,\n        target: str,\n    ) -&gt; bool:\n        \"\"\"Check if an operation would be immediately denied.\n\n        Args:\n            operation: The operation type.\n            target: The path or command.\n\n        Returns:\n            True if action is \"deny\", False otherwise.\n        \"\"\"\n        return self.check_sync(operation, target) == \"deny\"\n\n    def requires_approval(\n        self,\n        operation: PermissionOperation,\n        target: str,\n    ) -&gt; bool:\n        \"\"\"Check if an operation would require user approval.\n\n        Args:\n            operation: The operation type.\n            target: The path or command.\n\n        Returns:\n            True if action is \"ask\", False otherwise.\n        \"\"\"\n        return self.check_sync(operation, target) == \"ask\"\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.ruleset","title":"<code>ruleset</code>  <code>property</code>","text":"<p>The permission ruleset being used.</p>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.__init__","title":"<code>__init__(ruleset, ask_callback=None, ask_fallback='error')</code>","text":"<p>Initialize the permission checker.</p> <p>Parameters:</p> Name Type Description Default <code>ruleset</code> <code>PermissionRuleset</code> <p>The permission ruleset to check against.</p> required <code>ask_callback</code> <code>AskCallback | None</code> <p>Async callback for \"ask\" actions. Receives (operation, target, reason) and returns True to allow.</p> <code>None</code> <code>ask_fallback</code> <code>AskFallback</code> <p>What to do when ask_callback is None or needed but not available. \"deny\" returns False, \"error\" raises.</p> <code>'error'</code> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>def __init__(\n    self,\n    ruleset: PermissionRuleset,\n    ask_callback: AskCallback | None = None,\n    ask_fallback: AskFallback = \"error\",\n):\n    \"\"\"Initialize the permission checker.\n\n    Args:\n        ruleset: The permission ruleset to check against.\n        ask_callback: Async callback for \"ask\" actions. Receives\n            (operation, target, reason) and returns True to allow.\n        ask_fallback: What to do when ask_callback is None or needed\n            but not available. \"deny\" returns False, \"error\" raises.\n    \"\"\"\n    self._ruleset = ruleset\n    self._ask_callback = ask_callback\n    self._ask_fallback = ask_fallback\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.check_sync","title":"<code>check_sync(operation, target)</code>","text":"<p>Check permission synchronously without invoking callbacks.</p> <p>This method evaluates rules and returns the action without executing any callbacks. Use this when you need to know what action would be taken.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>PermissionOperation</code> <p>The operation type (read, write, etc.).</p> required <code>target</code> <code>str</code> <p>The path or command being accessed.</p> required <p>Returns:</p> Type Description <code>PermissionAction</code> <p>The permission action: \"allow\", \"deny\", or \"ask\".</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>def check_sync(\n    self,\n    operation: PermissionOperation,\n    target: str,\n) -&gt; PermissionAction:\n    \"\"\"Check permission synchronously without invoking callbacks.\n\n    This method evaluates rules and returns the action without\n    executing any callbacks. Use this when you need to know what\n    action would be taken.\n\n    Args:\n        operation: The operation type (read, write, etc.).\n        target: The path or command being accessed.\n\n    Returns:\n        The permission action: \"allow\", \"deny\", or \"ask\".\n    \"\"\"\n    op_perms = self._ruleset.get_operation_permissions(operation)\n\n    # Check rules in order - first match wins\n    for rule in op_perms.rules:\n        if _matches_pattern(target, rule.pattern):\n            return rule.action\n\n    # No rule matched, use default\n    return op_perms.default\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.check","title":"<code>check(operation, target, reason='')</code>  <code>async</code>","text":"<p>Check permission asynchronously with callback support.</p> <p>Evaluates rules and handles \"ask\" actions via the callback. For \"allow\" returns True, for \"deny\" raises PermissionDeniedError.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>PermissionOperation</code> <p>The operation type (read, write, etc.).</p> required <code>target</code> <code>str</code> <p>The path or command being accessed.</p> required <code>reason</code> <code>str</code> <p>Human-readable reason for the operation.</p> <code>''</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the operation is allowed.</p> <p>Raises:</p> Type Description <code>PermissionDeniedError</code> <p>If the operation is explicitly denied.</p> <code>PermissionError</code> <p>If ask_fallback=\"error\" and callback unavailable.</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>async def check(\n    self,\n    operation: PermissionOperation,\n    target: str,\n    reason: str = \"\",\n) -&gt; bool:\n    \"\"\"Check permission asynchronously with callback support.\n\n    Evaluates rules and handles \"ask\" actions via the callback.\n    For \"allow\" returns True, for \"deny\" raises PermissionDeniedError.\n\n    Args:\n        operation: The operation type (read, write, etc.).\n        target: The path or command being accessed.\n        reason: Human-readable reason for the operation.\n\n    Returns:\n        True if the operation is allowed.\n\n    Raises:\n        PermissionDeniedError: If the operation is explicitly denied.\n        PermissionError: If ask_fallback=\"error\" and callback unavailable.\n    \"\"\"\n    action = self.check_sync(operation, target)\n\n    if action == \"allow\":\n        return True\n\n    if action == \"deny\":\n        rule = self._find_matching_rule(operation, target)\n        raise PermissionDeniedError(operation, target, rule)\n\n    # Action is \"ask\"\n    if self._ask_callback is not None:\n        allowed = await self._ask_callback(operation, target, reason)\n        if allowed:\n            return True\n        raise PermissionDeniedError(operation, target)\n\n    # No callback available\n    if self._ask_fallback == \"error\":\n        raise PermissionError(operation, target, reason)\n\n    # ask_fallback == \"deny\"\n    raise PermissionDeniedError(operation, target)\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.is_allowed","title":"<code>is_allowed(operation, target)</code>","text":"<p>Check if an operation would be immediately allowed.</p> <p>This is a convenience method that returns True only if the operation would be allowed without needing to ask.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>PermissionOperation</code> <p>The operation type.</p> required <code>target</code> <code>str</code> <p>The path or command.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if action is \"allow\", False otherwise.</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>def is_allowed(\n    self,\n    operation: PermissionOperation,\n    target: str,\n) -&gt; bool:\n    \"\"\"Check if an operation would be immediately allowed.\n\n    This is a convenience method that returns True only if the\n    operation would be allowed without needing to ask.\n\n    Args:\n        operation: The operation type.\n        target: The path or command.\n\n    Returns:\n        True if action is \"allow\", False otherwise.\n    \"\"\"\n    return self.check_sync(operation, target) == \"allow\"\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.is_denied","title":"<code>is_denied(operation, target)</code>","text":"<p>Check if an operation would be immediately denied.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>PermissionOperation</code> <p>The operation type.</p> required <code>target</code> <code>str</code> <p>The path or command.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if action is \"deny\", False otherwise.</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>def is_denied(\n    self,\n    operation: PermissionOperation,\n    target: str,\n) -&gt; bool:\n    \"\"\"Check if an operation would be immediately denied.\n\n    Args:\n        operation: The operation type.\n        target: The path or command.\n\n    Returns:\n        True if action is \"deny\", False otherwise.\n    \"\"\"\n    return self.check_sync(operation, target) == \"deny\"\n</code></pre>"},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionChecker.requires_approval","title":"<code>requires_approval(operation, target)</code>","text":"<p>Check if an operation would require user approval.</p> <p>Parameters:</p> Name Type Description Default <code>operation</code> <code>PermissionOperation</code> <p>The operation type.</p> required <code>target</code> <code>str</code> <p>The path or command.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if action is \"ask\", False otherwise.</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>def requires_approval(\n    self,\n    operation: PermissionOperation,\n    target: str,\n) -&gt; bool:\n    \"\"\"Check if an operation would require user approval.\n\n    Args:\n        operation: The operation type.\n        target: The path or command.\n\n    Returns:\n        True if action is \"ask\", False otherwise.\n    \"\"\"\n    return self.check_sync(operation, target) == \"ask\"\n</code></pre>"},{"location":"api/permissions/#permissionerror","title":"PermissionError","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionError","title":"<code>pydantic_ai_backends.permissions.checker.PermissionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a permission check fails with ask_fallback=\"error\".</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>class PermissionError(Exception):\n    \"\"\"Raised when a permission check fails with ask_fallback=\"error\".\"\"\"\n\n    def __init__(\n        self,\n        operation: PermissionOperation,\n        target: str,\n        reason: str = \"\",\n    ):\n        self.operation = operation\n        self.target = target\n        self.reason = reason\n        message = f\"Permission required for {operation} on '{target}'\"\n        if reason:\n            message += f\": {reason}\"\n        super().__init__(message)\n</code></pre>"},{"location":"api/permissions/#permissiondeniederror","title":"PermissionDeniedError","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.PermissionDeniedError","title":"<code>pydantic_ai_backends.permissions.checker.PermissionDeniedError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Raised when a permission is explicitly denied.</p> Source code in <code>src/pydantic_ai_backends/permissions/checker.py</code> Python<pre><code>class PermissionDeniedError(Exception):\n    \"\"\"Raised when a permission is explicitly denied.\"\"\"\n\n    def __init__(\n        self,\n        operation: PermissionOperation,\n        target: str,\n        rule: PermissionRule | None = None,\n    ):\n        self.operation = operation\n        self.target = target\n        self.rule = rule\n        message = f\"Permission denied for {operation} on '{target}'\"\n        if rule and rule.description:\n            message += f\": {rule.description}\"\n        super().__init__(message)\n</code></pre>"},{"location":"api/permissions/#presets","title":"Presets","text":""},{"location":"api/permissions/#default_ruleset","title":"DEFAULT_RULESET","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.DEFAULT_RULESET","title":"<code>pydantic_ai_backends.permissions.presets.DEFAULT_RULESET = PermissionRuleset(default='ask', read=(OperationPermissions(default='allow', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), write=(OperationPermissions(default='ask', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), edit=(OperationPermissions(default='ask', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), execute=(OperationPermissions(default='ask', rules=(_create_deny_rules(DANGEROUS_COMMANDS, 'Block dangerous commands')))), glob=(OperationPermissions(default='allow')), grep=(OperationPermissions(default='allow')), ls=(OperationPermissions(default='allow')))</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#permissive_ruleset","title":"PERMISSIVE_RULESET","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.PERMISSIVE_RULESET","title":"<code>pydantic_ai_backends.permissions.presets.PERMISSIVE_RULESET = PermissionRuleset(default='allow', read=(OperationPermissions(default='allow', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), write=(OperationPermissions(default='allow', rules=(_create_deny_rules(SECRETS_PATTERNS + SYSTEM_PATTERNS, 'Protect sensitive and system files')))), edit=(OperationPermissions(default='allow', rules=(_create_deny_rules(SECRETS_PATTERNS + SYSTEM_PATTERNS, 'Protect sensitive and system files')))), execute=(OperationPermissions(default='allow', rules=(_create_deny_rules(DANGEROUS_COMMANDS, 'Block dangerous commands')))), glob=(OperationPermissions(default='allow')), grep=(OperationPermissions(default='allow')), ls=(OperationPermissions(default='allow')))</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#readonly_ruleset","title":"READONLY_RULESET","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.READONLY_RULESET","title":"<code>pydantic_ai_backends.permissions.presets.READONLY_RULESET = PermissionRuleset(default='deny', read=(OperationPermissions(default='allow', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), write=(OperationPermissions(default='deny')), edit=(OperationPermissions(default='deny')), execute=(OperationPermissions(default='deny')), glob=(OperationPermissions(default='allow')), grep=(OperationPermissions(default='allow')), ls=(OperationPermissions(default='allow')))</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#strict_ruleset","title":"STRICT_RULESET","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.STRICT_RULESET","title":"<code>pydantic_ai_backends.permissions.presets.STRICT_RULESET = PermissionRuleset(default='ask', read=(OperationPermissions(default='ask', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), write=(OperationPermissions(default='ask', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), edit=(OperationPermissions(default='ask', rules=(_create_deny_rules(SECRETS_PATTERNS, 'Protect sensitive files')))), execute=(OperationPermissions(default='ask', rules=(_create_deny_rules(DANGEROUS_COMMANDS, 'Block dangerous commands')))), glob=(OperationPermissions(default='ask')), grep=(OperationPermissions(default='ask')), ls=(OperationPermissions(default='ask')))</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#create_ruleset","title":"create_ruleset","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.create_ruleset","title":"<code>pydantic_ai_backends.permissions.presets.create_ruleset(*, default='ask', allow_read=True, allow_write=False, allow_edit=False, allow_execute=False, allow_glob=True, allow_grep=True, allow_ls=True, deny_secrets=True)</code>","text":"<p>Create a custom permission ruleset.</p> <p>A convenience factory for creating rulesets with common configurations.</p> <p>Parameters:</p> Name Type Description Default <code>default</code> <code>str</code> <p>Global default action (\"allow\", \"deny\", or \"ask\").</p> <code>'ask'</code> <code>allow_read</code> <code>bool</code> <p>Whether to allow read operations by default.</p> <code>True</code> <code>allow_write</code> <code>bool</code> <p>Whether to allow write operations by default.</p> <code>False</code> <code>allow_edit</code> <code>bool</code> <p>Whether to allow edit operations by default.</p> <code>False</code> <code>allow_execute</code> <code>bool</code> <p>Whether to allow execute operations by default.</p> <code>False</code> <code>allow_glob</code> <code>bool</code> <p>Whether to allow glob operations by default.</p> <code>True</code> <code>allow_grep</code> <code>bool</code> <p>Whether to allow grep operations by default.</p> <code>True</code> <code>allow_ls</code> <code>bool</code> <p>Whether to allow ls operations by default.</p> <code>True</code> <code>deny_secrets</code> <code>bool</code> <p>Whether to deny access to sensitive file patterns.</p> <code>True</code> <p>Returns:</p> Type Description <code>PermissionRuleset</code> <p>A configured PermissionRuleset.</p> Example Python<pre><code># Create a ruleset that allows reads and writes but asks for execute\nruleset = create_ruleset(\n    allow_read=True,\n    allow_write=True,\n    allow_execute=False,\n)\n</code></pre> Source code in <code>src/pydantic_ai_backends/permissions/presets.py</code> Python<pre><code>def create_ruleset(\n    *,\n    default: str = \"ask\",\n    allow_read: bool = True,\n    allow_write: bool = False,\n    allow_edit: bool = False,\n    allow_execute: bool = False,\n    allow_glob: bool = True,\n    allow_grep: bool = True,\n    allow_ls: bool = True,\n    deny_secrets: bool = True,\n) -&gt; PermissionRuleset:\n    \"\"\"Create a custom permission ruleset.\n\n    A convenience factory for creating rulesets with common configurations.\n\n    Args:\n        default: Global default action (\"allow\", \"deny\", or \"ask\").\n        allow_read: Whether to allow read operations by default.\n        allow_write: Whether to allow write operations by default.\n        allow_edit: Whether to allow edit operations by default.\n        allow_execute: Whether to allow execute operations by default.\n        allow_glob: Whether to allow glob operations by default.\n        allow_grep: Whether to allow grep operations by default.\n        allow_ls: Whether to allow ls operations by default.\n        deny_secrets: Whether to deny access to sensitive file patterns.\n\n    Returns:\n        A configured PermissionRuleset.\n\n    Example:\n        ```python\n        # Create a ruleset that allows reads and writes but asks for execute\n        ruleset = create_ruleset(\n            allow_read=True,\n            allow_write=True,\n            allow_execute=False,\n        )\n        ```\n    \"\"\"\n\n    def _action(allowed: bool) -&gt; str:\n        return \"allow\" if allowed else \"ask\"\n\n    secret_rules = (\n        _create_deny_rules(SECRETS_PATTERNS, \"Protect sensitive files\") if deny_secrets else []\n    )\n\n    return PermissionRuleset(\n        default=default,  # type: ignore[arg-type]\n        read=OperationPermissions(default=_action(allow_read), rules=secret_rules),  # type: ignore[arg-type]\n        write=OperationPermissions(default=_action(allow_write), rules=secret_rules),  # type: ignore[arg-type]\n        edit=OperationPermissions(default=_action(allow_edit), rules=secret_rules),  # type: ignore[arg-type]\n        execute=OperationPermissions(default=_action(allow_execute)),  # type: ignore[arg-type]\n        glob=OperationPermissions(default=_action(allow_glob)),  # type: ignore[arg-type]\n        grep=OperationPermissions(default=_action(allow_grep)),  # type: ignore[arg-type]\n        ls=OperationPermissions(default=_action(allow_ls)),  # type: ignore[arg-type]\n    )\n</code></pre>"},{"location":"api/permissions/#patterns","title":"Patterns","text":""},{"location":"api/permissions/#secrets_patterns","title":"SECRETS_PATTERNS","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.SECRETS_PATTERNS","title":"<code>pydantic_ai_backends.permissions.presets.SECRETS_PATTERNS = ['**/.env', '**/.env.*', '**/*.pem', '**/*.key', '**/*.crt', '**/credentials*', '**/secrets*', '**/*secret*', '**/*password*', '**/.aws/**', '**/.ssh/**', '**/.gnupg/**']</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#system_patterns","title":"SYSTEM_PATTERNS","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.presets.SYSTEM_PATTERNS","title":"<code>pydantic_ai_backends.permissions.presets.SYSTEM_PATTERNS = ['/etc/**', '/var/**', '/usr/**', '/bin/**', '/sbin/**', '/boot/**', '/sys/**', '/proc/**']</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#callback-types","title":"Callback Types","text":""},{"location":"api/permissions/#askcallback","title":"AskCallback","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.AskCallback","title":"<code>pydantic_ai_backends.permissions.checker.AskCallback = Callable[[PermissionOperation, str, str], Awaitable[bool]]</code>  <code>module-attribute</code>","text":""},{"location":"api/permissions/#askfallback","title":"AskFallback","text":""},{"location":"api/permissions/#pydantic_ai_backends.permissions.checker.AskFallback","title":"<code>pydantic_ai_backends.permissions.checker.AskFallback = Literal['deny', 'error']</code>  <code>module-attribute</code>","text":""},{"location":"api/toolsets/","title":"Toolsets API","text":""},{"location":"api/toolsets/#create_console_toolset","title":"create_console_toolset","text":""},{"location":"api/toolsets/#pydantic_ai_backends.toolsets.console.create_console_toolset","title":"<code>pydantic_ai_backends.toolsets.console.create_console_toolset(id=None, include_execute=True, require_write_approval=False, require_execute_approval=True, default_ignore_hidden=True, permissions=None)</code>","text":"<p>Create a console toolset for file operations and shell execution.</p> <p>This toolset provides tools for interacting with the filesystem and executing shell commands. It works with any backend that implements BackendProtocol (LocalBackend, DockerSandbox, StateBackend, etc.)</p> <p>Parameters:</p> Name Type Description Default <code>id</code> <code>str | None</code> <p>Optional unique ID for the toolset.</p> <code>None</code> <code>include_execute</code> <code>bool</code> <p>Whether to include the execute tool. Requires backend to have execute() method.</p> <code>True</code> <code>require_write_approval</code> <code>bool</code> <p>Whether write_file and edit_file require approval. Ignored if permissions is provided.</p> <code>False</code> <code>require_execute_approval</code> <code>bool</code> <p>Whether execute requires approval. Ignored if permissions is provided.</p> <code>True</code> <code>default_ignore_hidden</code> <code>bool</code> <p>Default behavior for grep regarding hidden files.</p> <code>True</code> <code>permissions</code> <code>PermissionRuleset | None</code> <p>Optional permission ruleset to determine tool approval requirements. If provided, overrides require_write_approval and require_execute_approval based on whether the operation's default action is \"ask\".</p> <code>None</code> <p>Returns:</p> Type Description <code>FunctionToolset[ConsoleDeps]</code> <p>FunctionToolset with console tools.</p> Example Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass MyDeps:\n    backend: LocalBackend\n\ntoolset = create_console_toolset()\ndeps = MyDeps(backend=LocalBackend(\"/workspace\"))\n\n# Or with permissions\nfrom pydantic_ai_backends.permissions import DEFAULT_RULESET\n\ntoolset = create_console_toolset(permissions=DEFAULT_RULESET)\n</code></pre> Source code in <code>src/pydantic_ai_backends/toolsets/console.py</code> Python<pre><code>def create_console_toolset(  # noqa: C901\n    id: str | None = None,\n    include_execute: bool = True,\n    require_write_approval: bool = False,\n    require_execute_approval: bool = True,\n    default_ignore_hidden: bool = True,\n    permissions: PermissionRuleset | None = None,\n) -&gt; FunctionToolset[ConsoleDeps]:\n    \"\"\"Create a console toolset for file operations and shell execution.\n\n    This toolset provides tools for interacting with the filesystem and\n    executing shell commands. It works with any backend that implements\n    BackendProtocol (LocalBackend, DockerSandbox, StateBackend, etc.)\n\n    Args:\n        id: Optional unique ID for the toolset.\n        include_execute: Whether to include the execute tool.\n            Requires backend to have execute() method.\n        require_write_approval: Whether write_file and edit_file require approval.\n            Ignored if permissions is provided.\n        require_execute_approval: Whether execute requires approval.\n            Ignored if permissions is provided.\n        default_ignore_hidden: Default behavior for grep regarding hidden files.\n        permissions: Optional permission ruleset to determine tool approval requirements.\n            If provided, overrides require_write_approval and require_execute_approval\n            based on whether the operation's default action is \"ask\".\n\n    Returns:\n        FunctionToolset with console tools.\n\n    Example:\n        ```python\n        from dataclasses import dataclass\n        from pydantic_ai_backends import LocalBackend, create_console_toolset\n\n        @dataclass\n        class MyDeps:\n            backend: LocalBackend\n\n        toolset = create_console_toolset()\n        deps = MyDeps(backend=LocalBackend(\"/workspace\"))\n\n        # Or with permissions\n        from pydantic_ai_backends.permissions import DEFAULT_RULESET\n\n        toolset = create_console_toolset(permissions=DEFAULT_RULESET)\n        ```\n    \"\"\"\n    from pydantic_ai.toolsets import FunctionToolset\n\n    # Determine approval requirements\n    write_approval = _requires_approval_from_ruleset(permissions, \"write\", require_write_approval)\n    execute_approval = _requires_approval_from_ruleset(\n        permissions, \"execute\", require_execute_approval\n    )\n\n    toolset: FunctionToolset[ConsoleDeps] = FunctionToolset(id=id)\n\n    @toolset.tool\n    async def ls(  # pragma: no cover\n        ctx: RunContext[ConsoleDeps],\n        path: str = \".\",\n    ) -&gt; str:\n        \"\"\"List files and directories at the given path.\n\n        Args:\n            path: Directory path to list. Defaults to current directory.\n        \"\"\"\n        entries = ctx.deps.backend.ls_info(path)\n\n        if not entries:\n            return f\"Directory '{path}' is empty or does not exist\"\n\n        lines = [f\"Contents of {path}:\"]\n        for entry in entries:\n            if entry[\"is_dir\"]:\n                lines.append(f\"  {entry['name']}/\")\n            else:\n                size = entry.get(\"size\")\n                size_str = f\" ({size} bytes)\" if size is not None else \"\"\n                lines.append(f\"  {entry['name']}{size_str}\")\n\n        return \"\\n\".join(lines)\n\n    @toolset.tool\n    async def read_file(  # pragma: no cover\n        ctx: RunContext[ConsoleDeps],\n        path: str,\n        offset: int = 0,\n        limit: int = 2000,\n    ) -&gt; str:\n        \"\"\"Read file content with line numbers.\n\n        Args:\n            path: Path to the file to read.\n            offset: Line number to start reading from (0-indexed).\n            limit: Maximum number of lines to read.\n        \"\"\"\n        return ctx.deps.backend.read(path, offset, limit)\n\n    @toolset.tool(requires_approval=write_approval)\n    async def write_file(  # pragma: no cover\n        ctx: RunContext[ConsoleDeps],\n        path: str,\n        content: str,\n    ) -&gt; str:\n        \"\"\"Write content to a file (creates or overwrites).\n\n        This will create parent directories if needed.\n        Use edit_file for making small changes to existing files.\n\n        Args:\n            path: Path to the file to write.\n            content: Content to write to the file.\n        \"\"\"\n        result = ctx.deps.backend.write(path, content)\n\n        if result.error:\n            return f\"Error: {result.error}\"\n\n        lines = content.count(\"\\n\") + 1\n        return f\"Wrote {lines} lines to {result.path}\"\n\n    @toolset.tool(requires_approval=write_approval)\n    async def edit_file(  # pragma: no cover\n        ctx: RunContext[ConsoleDeps],\n        path: str,\n        old_string: str,\n        new_string: str,\n        replace_all: bool = False,\n    ) -&gt; str:\n        \"\"\"Edit a file by replacing strings.\n\n        The old_string must be unique in the file unless replace_all is True.\n        Always read the file first to understand its content before editing.\n\n        Args:\n            path: Path to the file to edit.\n            old_string: String to find and replace.\n            new_string: Replacement string.\n            replace_all: If True, replace all occurrences. Otherwise, fails if not unique.\n        \"\"\"\n        result = ctx.deps.backend.edit(path, old_string, new_string, replace_all)\n\n        if result.error:\n            return f\"Error: {result.error}\"\n\n        return f\"Edited {result.path}: replaced {result.occurrences} occurrence(s)\"\n\n    @toolset.tool\n    async def glob(  # pragma: no cover\n        ctx: RunContext[ConsoleDeps],\n        pattern: str,\n        path: str = \".\",\n    ) -&gt; str:\n        \"\"\"Find files matching a glob pattern.\n\n        Common patterns:\n        - \"*.py\" - Python files in current directory\n        - \"**/*.py\" - Python files recursively\n        - \"src/**/*.ts\" - TypeScript files under src/\n\n        Args:\n            pattern: Glob pattern to match (e.g., \"**/*.py\").\n            path: Base directory to search from.\n        \"\"\"\n        entries = ctx.deps.backend.glob_info(pattern, path)\n\n        if not entries:\n            return f\"No files matching '{pattern}' in {path}\"\n\n        lines = [f\"Found {len(entries)} file(s) matching '{pattern}':\"]\n        for entry in entries[:100]:\n            lines.append(f\"  {entry['path']}\")\n\n        if len(entries) &gt; 100:\n            lines.append(f\"  ... and {len(entries) - 100} more\")\n\n        return \"\\n\".join(lines)\n\n    @toolset.tool\n    async def grep(  # pragma: no cover\n        ctx: RunContext[ConsoleDeps],\n        pattern: str,\n        path: str | None = None,\n        glob_pattern: str | None = None,\n        output_mode: Literal[\"content\", \"files_with_matches\", \"count\"] = \"files_with_matches\",\n        ignore_hidden: bool = default_ignore_hidden,\n    ) -&gt; str:\n        \"\"\"Search for a regex pattern in files.\n\n        Args:\n            pattern: Regex pattern to search for.\n            path: Specific file or directory to search.\n            glob_pattern: Glob pattern to filter files (e.g., \"*.py\").\n            output_mode: Output format - \"content\", \"files_with_matches\", or \"count\".\n            ignore_hidden: Whether to skip hidden files (defaults to toolset setting).\n        \"\"\"\n        result = ctx.deps.backend.grep_raw(pattern, path, glob_pattern, ignore_hidden)\n\n        if isinstance(result, str):\n            return result  # Error message\n\n        if not result:\n            return f\"No matches for '{pattern}'\"\n\n        matches: list[GrepMatch] = result\n\n        if output_mode == \"count\":\n            return f\"Found {len(matches)} match(es) for '{pattern}'\"\n\n        if output_mode == \"files_with_matches\":\n            files = sorted(set(m[\"path\"] for m in matches))\n            lines = [f\"Files containing '{pattern}':\"]\n            for f in files[:50]:\n                lines.append(f\"  {f}\")\n            if len(files) &gt; 50:\n                lines.append(f\"  ... and {len(files) - 50} more files\")\n            return \"\\n\".join(lines)\n\n        # content mode\n        lines = [f\"Matches for '{pattern}':\"]\n        for m in matches[:50]:\n            lines.append(f\"  {m['path']}:{m['line_number']}: {m['line'][:100]}\")\n        if len(matches) &gt; 50:\n            lines.append(f\"  ... and {len(matches) - 50} more matches\")\n        return \"\\n\".join(lines)\n\n    # Expose references for testing\n    cast(_ConsoleToolsetTestAttrs, toolset)._console_default_ignore_hidden = default_ignore_hidden\n    cast(_ConsoleToolsetTestAttrs, toolset)._console_grep_impl = grep\n\n    if include_execute:\n\n        @toolset.tool(requires_approval=execute_approval)\n        async def execute(  # pragma: no cover\n            ctx: RunContext[ConsoleDeps],\n            command: str,\n            timeout: int | None = 120,\n        ) -&gt; str:\n            \"\"\"Execute a shell command.\n\n            Use this for running tests, builds, scripts, etc.\n            Be careful with destructive commands.\n\n            Args:\n                command: The shell command to execute.\n                timeout: Maximum execution time in seconds (default 120).\n            \"\"\"\n            backend = ctx.deps.backend\n\n            # Check if backend supports execute\n            if not hasattr(backend, \"execute\"):\n                return \"Error: Backend does not support command execution\"\n\n            # Check if execute is enabled (for LocalBackend)\n            if hasattr(backend, \"execute_enabled\") and not backend.execute_enabled:  # pyright: ignore[reportAttributeAccessIssue]\n                return \"Error: Shell execution is disabled for this backend\"\n\n            try:\n                result = backend.execute(command, timeout)  # pyright: ignore[reportAttributeAccessIssue]\n            except RuntimeError as e:\n                return f\"Error: {e}\"\n\n            output = result.output\n            if result.truncated:\n                output += \"\\n\\n... (output truncated)\"\n\n            if result.exit_code is not None and result.exit_code != 0:\n                return f\"Command failed (exit code {result.exit_code}):\\n{output}\"\n\n            return str(output)\n\n    return toolset\n</code></pre>"},{"location":"api/toolsets/#get_console_system_prompt","title":"get_console_system_prompt","text":""},{"location":"api/toolsets/#pydantic_ai_backends.toolsets.console.get_console_system_prompt","title":"<code>pydantic_ai_backends.toolsets.console.get_console_system_prompt()</code>","text":"<p>Get the system prompt for console tools.</p> <p>Returns:</p> Type Description <code>str</code> <p>System prompt describing available console tools.</p> Source code in <code>src/pydantic_ai_backends/toolsets/console.py</code> Python<pre><code>def get_console_system_prompt() -&gt; str:\n    \"\"\"Get the system prompt for console tools.\n\n    Returns:\n        System prompt describing available console tools.\n    \"\"\"\n    return CONSOLE_SYSTEM_PROMPT\n</code></pre>"},{"location":"api/toolsets/#consoledeps","title":"ConsoleDeps","text":""},{"location":"api/toolsets/#pydantic_ai_backends.toolsets.console.ConsoleDeps","title":"<code>pydantic_ai_backends.toolsets.console.ConsoleDeps</code>","text":"<p>               Bases: <code>Protocol</code></p> <p>Protocol for dependencies that provide a backend.</p> Source code in <code>src/pydantic_ai_backends/toolsets/console.py</code> Python<pre><code>@runtime_checkable\nclass ConsoleDeps(Protocol):\n    \"\"\"Protocol for dependencies that provide a backend.\"\"\"\n\n    @property\n    def backend(self) -&gt; BackendProtocol:\n        \"\"\"The backend for file operations.\"\"\"\n        ...\n</code></pre>"},{"location":"api/toolsets/#pydantic_ai_backends.toolsets.console.ConsoleDeps.backend","title":"<code>backend</code>  <code>property</code>","text":"<p>The backend for file operations.</p>"},{"location":"api/toolsets/#console-tools","title":"Console Tools","text":"<p>The toolset provides these tools:</p>"},{"location":"api/toolsets/#ls","title":"ls","text":"Python<pre><code>async def ls(ctx: RunContext[ConsoleDeps], path: str = \".\") -&gt; str:\n    \"\"\"List files and directories at the given path.\n\n    Args:\n        path: Directory path to list. Defaults to current directory.\n    \"\"\"\n</code></pre>"},{"location":"api/toolsets/#read_file","title":"read_file","text":"Python<pre><code>async def read_file(\n    ctx: RunContext[ConsoleDeps],\n    path: str,\n    offset: int = 0,\n    limit: int = 2000,\n) -&gt; str:\n    \"\"\"Read file content with line numbers.\n\n    Args:\n        path: Path to the file to read.\n        offset: Line number to start reading from (0-indexed).\n        limit: Maximum number of lines to read.\n    \"\"\"\n</code></pre>"},{"location":"api/toolsets/#write_file","title":"write_file","text":"Python<pre><code>async def write_file(\n    ctx: RunContext[ConsoleDeps],\n    path: str,\n    content: str,\n) -&gt; str:\n    \"\"\"Write content to a file (creates or overwrites).\n\n    Args:\n        path: Path to the file to write.\n        content: Content to write to the file.\n    \"\"\"\n</code></pre>"},{"location":"api/toolsets/#edit_file","title":"edit_file","text":"Python<pre><code>async def edit_file(\n    ctx: RunContext[ConsoleDeps],\n    path: str,\n    old_string: str,\n    new_string: str,\n    replace_all: bool = False,\n) -&gt; str:\n    \"\"\"Edit a file by replacing strings.\n\n    Args:\n        path: Path to the file to edit.\n        old_string: String to find and replace.\n        new_string: Replacement string.\n        replace_all: If True, replace all occurrences.\n    \"\"\"\n</code></pre>"},{"location":"api/toolsets/#glob","title":"glob","text":"Python<pre><code>async def glob(\n    ctx: RunContext[ConsoleDeps],\n    pattern: str,\n    path: str = \".\",\n) -&gt; str:\n    \"\"\"Find files matching a glob pattern.\n\n    Args:\n        pattern: Glob pattern to match (e.g., \"**/*.py\").\n        path: Base directory to search from.\n    \"\"\"\n</code></pre>"},{"location":"api/toolsets/#grep","title":"grep","text":"Python<pre><code>async def grep(\n    ctx: RunContext[ConsoleDeps],\n    pattern: str,\n    path: str | None = None,\n    glob_pattern: str | None = None,\n    output_mode: Literal[\"content\", \"files_with_matches\", \"count\"] = \"files_with_matches\",\n    ignore_hidden: bool = True,\n) -&gt; str:\n    \"\"\"Search for a regex pattern in files.\n\n    Args:\n        pattern: Regex pattern to search for.\n        path: Specific file or directory to search.\n        glob_pattern: Glob pattern to filter files.\n        output_mode: Output format.\n        ignore_hidden: Whether to skip hidden files (defaults to the toolset setting).\n    \"\"\"\n</code></pre>"},{"location":"api/toolsets/#execute","title":"execute","text":"Python<pre><code>async def execute(\n    ctx: RunContext[ConsoleDeps],\n    command: str,\n    timeout: int | None = 120,\n) -&gt; str:\n    \"\"\"Execute a shell command.\n\n    Args:\n        command: The shell command to execute.\n        timeout: Maximum execution time in seconds.\n    \"\"\"\n</code></pre>"},{"location":"api/types/","title":"Types API","text":""},{"location":"api/types/#fileinfo","title":"FileInfo","text":"Python<pre><code>from pydantic_ai_backends import FileInfo\n\n# Example\nfile_info: FileInfo = {\n    \"name\": \"app.py\",\n    \"path\": \"/workspace/app.py\",\n    \"is_dir\": False,\n    \"size\": 1234,\n}\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.FileInfo","title":"<code>pydantic_ai_backends.types.FileInfo</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Information about a file or directory.</p> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>class FileInfo(TypedDict):\n    \"\"\"Information about a file or directory.\"\"\"\n\n    name: str\n    path: str\n    is_dir: bool\n    size: int | None\n</code></pre>"},{"location":"api/types/#filedata","title":"FileData","text":"Python<pre><code>from pydantic_ai_backends import FileData\n\n# Example (used internally by StateBackend)\nfile_data: FileData = {\n    \"content\": [\"line 1\", \"line 2\", \"line 3\"],\n    \"created_at\": \"2024-01-15T10:30:00Z\",\n    \"modified_at\": \"2024-01-15T11:00:00Z\",\n}\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.FileData","title":"<code>pydantic_ai_backends.types.FileData</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>Data structure for storing file content in StateBackend.</p> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>class FileData(TypedDict):\n    \"\"\"Data structure for storing file content in StateBackend.\"\"\"\n\n    content: list[str]  # Lines of the file\n    created_at: str  # ISO 8601 timestamp\n    modified_at: str  # ISO 8601 timestamp\n</code></pre>"},{"location":"api/types/#writeresult","title":"WriteResult","text":"Python<pre><code>from pydantic_ai_backends import WriteResult\n\n# Success\nresult = WriteResult(path=\"/workspace/app.py\")\n\n# Error\nresult = WriteResult(error=\"Permission denied\")\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.WriteResult","title":"<code>pydantic_ai_backends.types.WriteResult</code>  <code>dataclass</code>","text":"<p>Result of a write operation.</p> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>@dataclass\nclass WriteResult:\n    \"\"\"Result of a write operation.\"\"\"\n\n    path: str | None = None\n    error: str | None = None\n</code></pre>"},{"location":"api/types/#editresult","title":"EditResult","text":"Python<pre><code>from pydantic_ai_backends import EditResult\n\n# Success\nresult = EditResult(path=\"/workspace/app.py\", occurrences=3)\n\n# Error\nresult = EditResult(error=\"String not found\")\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.EditResult","title":"<code>pydantic_ai_backends.types.EditResult</code>  <code>dataclass</code>","text":"<p>Result of an edit operation.</p> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>@dataclass\nclass EditResult:\n    \"\"\"Result of an edit operation.\"\"\"\n\n    path: str | None = None\n    error: str | None = None\n    occurrences: int | None = None\n</code></pre>"},{"location":"api/types/#executeresponse","title":"ExecuteResponse","text":"Python<pre><code>from pydantic_ai_backends import ExecuteResponse\n\n# Example\nresponse = ExecuteResponse(\n    output=\"Hello, World!\\n\",\n    exit_code=0,\n    truncated=False,\n)\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.ExecuteResponse","title":"<code>pydantic_ai_backends.types.ExecuteResponse</code>  <code>dataclass</code>","text":"<p>Response from command execution in a sandbox.</p> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>@dataclass\nclass ExecuteResponse:\n    \"\"\"Response from command execution in a sandbox.\"\"\"\n\n    output: str\n    exit_code: int | None = None\n    truncated: bool = False\n</code></pre>"},{"location":"api/types/#grepmatch","title":"GrepMatch","text":"Python<pre><code>from pydantic_ai_backends import GrepMatch\n\n# Example\nmatch: GrepMatch = {\n    \"path\": \"/workspace/app.py\",\n    \"line_number\": 42,\n    \"line\": \"def hello_world():\",\n}\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.GrepMatch","title":"<code>pydantic_ai_backends.types.GrepMatch</code>","text":"<p>               Bases: <code>TypedDict</code></p> <p>A single grep match result.</p> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>class GrepMatch(TypedDict):\n    \"\"\"A single grep match result.\"\"\"\n\n    path: str\n    line_number: int\n    line: str\n</code></pre>"},{"location":"api/types/#runtimeconfig","title":"RuntimeConfig","text":"Python<pre><code>from pydantic_ai_backends import RuntimeConfig\n\n# Custom runtime\nruntime = RuntimeConfig(\n    name=\"ml-env\",\n    base_image=\"python:3.12-slim\",\n    packages=[\"torch\", \"transformers\"],\n    env_vars={\"PYTHONUNBUFFERED\": \"1\"},\n    work_dir=\"/workspace\",\n)\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig","title":"<code>pydantic_ai_backends.types.RuntimeConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for a Docker runtime environment.</p> <p>A runtime defines a pre-configured execution environment with specific packages and settings. Can be used with DockerSandbox to provide ready-to-use environments without manual package installation.</p> Example Python<pre><code>from pydantic_ai_backends import RuntimeConfig, DockerSandbox\n\n# Custom runtime with ML packages\nml_runtime = RuntimeConfig(\n    name=\"ml-env\",\n    description=\"Machine learning environment\",\n    base_image=\"python:3.12-slim\",\n    packages=[\"torch\", \"transformers\", \"datasets\"],\n)\n\nsandbox = DockerSandbox(runtime=ml_runtime)\n</code></pre> Source code in <code>src/pydantic_ai_backends/types.py</code> Python<pre><code>class RuntimeConfig(BaseModel):\n    \"\"\"Configuration for a Docker runtime environment.\n\n    A runtime defines a pre-configured execution environment with specific\n    packages and settings. Can be used with DockerSandbox to provide\n    ready-to-use environments without manual package installation.\n\n    Example:\n        ```python\n        from pydantic_ai_backends import RuntimeConfig, DockerSandbox\n\n        # Custom runtime with ML packages\n        ml_runtime = RuntimeConfig(\n            name=\"ml-env\",\n            description=\"Machine learning environment\",\n            base_image=\"python:3.12-slim\",\n            packages=[\"torch\", \"transformers\", \"datasets\"],\n        )\n\n        sandbox = DockerSandbox(runtime=ml_runtime)\n        ```\n    \"\"\"\n\n    name: str\n    \"\"\"Unique name for the runtime (e.g., \"python-datascience\").\"\"\"\n\n    description: str = \"\"\n    \"\"\"Human-readable description of the runtime.\"\"\"\n\n    # Image source (one of these)\n    image: str | None = None\n    \"\"\"Ready-to-use Docker image (e.g., \"myregistry/python-ds:v1\").\"\"\"\n\n    base_image: str | None = None\n    \"\"\"Base image to build upon (e.g., \"python:3.12-slim\").\"\"\"\n\n    # Packages to install (only if base_image)\n    packages: list[str] = []\n    \"\"\"Packages to install (e.g., [\"pandas\", \"numpy\", \"matplotlib\"]).\"\"\"\n\n    package_manager: Literal[\"pip\", \"npm\", \"apt\", \"cargo\"] = \"pip\"\n    \"\"\"Package manager to use for installation.\"\"\"\n\n    # Additional configuration\n    setup_commands: list[str] = []\n    \"\"\"Additional setup commands to run (e.g., [\"apt-get update\"]).\"\"\"\n\n    env_vars: dict[str, str] = {}\n    \"\"\"Environment variables to set in the container.\"\"\"\n\n    work_dir: str = \"/workspace\"\n    \"\"\"Working directory inside the container.\"\"\"\n\n    # Cache settings\n    cache_image: bool = True\n    \"\"\"Whether to cache the built image locally.\"\"\"\n</code></pre>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.name","title":"<code>name</code>  <code>instance-attribute</code>","text":"<p>Unique name for the runtime (e.g., \"python-datascience\").</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.description","title":"<code>description = ''</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Human-readable description of the runtime.</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.image","title":"<code>image = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Ready-to-use Docker image (e.g., \"myregistry/python-ds:v1\").</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.base_image","title":"<code>base_image = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Base image to build upon (e.g., \"python:3.12-slim\").</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.packages","title":"<code>packages = []</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Packages to install (e.g., [\"pandas\", \"numpy\", \"matplotlib\"]).</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.package_manager","title":"<code>package_manager = 'pip'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Package manager to use for installation.</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.setup_commands","title":"<code>setup_commands = []</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Additional setup commands to run (e.g., [\"apt-get update\"]).</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.env_vars","title":"<code>env_vars = {}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Environment variables to set in the container.</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.work_dir","title":"<code>work_dir = '/workspace'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Working directory inside the container.</p>"},{"location":"api/types/#pydantic_ai_backends.types.RuntimeConfig.cache_image","title":"<code>cache_image = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether to cache the built image locally.</p>"},{"location":"concepts/","title":"Core Concepts","text":"<p>pydantic-ai-backend adds file operations and code execution to your pydantic-ai agents. Three main components work together:</p>"},{"location":"concepts/#1-console-toolset","title":"1. Console Toolset","text":"<p>The console toolset gives your pydantic-ai agent file and execution capabilities:</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Create toolset with file + execution tools\ntoolset = create_console_toolset()\n\n# Add to your pydantic-ai agent\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps)\nagent = agent.with_toolset(toolset)\n\n# Run - agent can now read, write, search, and execute!\nresult = agent.run_sync(\n    \"Create a Python script that calculates pi and run it\",\n    deps=Deps(backend=LocalBackend(root_dir=\".\")),\n)\n</code></pre> <p>Tools provided: <code>ls</code>, <code>read_file</code>, <code>write_file</code>, <code>edit_file</code>, <code>glob</code>, <code>grep</code>, <code>execute</code></p> <p>Learn more about Console Toolset \u2192</p>"},{"location":"concepts/#2-backends","title":"2. Backends","text":"<p>Backends provide file storage. The same toolset works with any backend:</p> Python<pre><code>from pydantic_ai_backends import LocalBackend, StateBackend, DockerSandbox\n\n# Local filesystem (for CLI tools)\nbackend = LocalBackend(root_dir=\"/workspace\")\n\n# In-memory (for testing)\nbackend = StateBackend()\n\n# Docker (for safe execution)\nbackend = DockerSandbox(runtime=\"python-datascience\")\n</code></pre> <p>Learn more about Backends \u2192</p>"},{"location":"concepts/#3-docker-sandbox","title":"3. Docker Sandbox","text":"<p>For production and multi-user scenarios, <code>DockerSandbox</code> provides isolated execution:</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import DockerSandbox, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: DockerSandbox\n\n# Safe sandbox with data science packages\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n\ntry:\n    toolset = create_console_toolset()\n    agent = Agent(\"openai:gpt-4o\", deps_type=Deps)\n    agent = agent.with_toolset(toolset)\n\n    # Agent can run arbitrary code safely in Docker\n    result = agent.run_sync(\n        \"Analyze the iris dataset with pandas and show statistics\",\n        deps=Deps(backend=sandbox),\n    )\n    print(result.output)\nfinally:\n    sandbox.stop()\n</code></pre> <p>Learn more about Docker \u2192</p>"},{"location":"concepts/#4-permissions","title":"4. Permissions","text":"<p>Fine-grained access control for file operations and shell commands:</p> Python<pre><code>from pydantic_ai_backends import LocalBackend\nfrom pydantic_ai_backends.permissions import DEFAULT_RULESET, READONLY_RULESET\n\n# Safe defaults - allow reads, ask for writes/executes\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=DEFAULT_RULESET)\n\n# Read-only mode - deny all writes and executes\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=READONLY_RULESET)\n</code></pre> <p>Available presets: <code>DEFAULT_RULESET</code>, <code>PERMISSIVE_RULESET</code>, <code>READONLY_RULESET</code>, <code>STRICT_RULESET</code></p> <p>Learn more about Permissions \u2192</p>"},{"location":"concepts/#architecture","title":"Architecture","text":""},{"location":"concepts/#choosing-a-backend","title":"Choosing a Backend","text":"Use Case Backend Example CLI tools, local dev <code>LocalBackend</code> Personal coding assistant Unit tests <code>StateBackend</code> Testing agent behavior Safe code execution <code>DockerSandbox</code> Code interpreter Multi-user web apps <code>SessionManager</code> SaaS product Mixed (project + temp) <code>CompositeBackend</code> Complex workflows"},{"location":"concepts/backends/","title":"Backends","text":"<p>Backends provide file storage for your pydantic-ai agents. All backends implement <code>BackendProtocol</code>, so you can swap them without changing your agent code.</p>"},{"location":"concepts/backends/#quick-comparison","title":"Quick Comparison","text":"Backend Persistence Execution Best For <code>LocalBackend</code> Persistent Yes CLI tools, local development <code>StateBackend</code> Ephemeral No Unit testing, mocking <code>DockerSandbox</code> Ephemeral* Yes Safe execution, multi-user <code>CompositeBackend</code> Mixed Depends Route by path prefix"},{"location":"concepts/backends/#localbackend","title":"LocalBackend","text":"<p>Local filesystem with optional shell execution. Use for CLI tools and local development.</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Backend for local development\nbackend = LocalBackend(root_dir=\"./workspace\")\n\n# Create agent with file tools\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps).with_toolset(toolset)\n\n# Agent can now work with local files\nresult = agent.run_sync(\n    \"Create a todo.py CLI app and test it\",\n    deps=Deps(backend=backend),\n)\n</code></pre>"},{"location":"concepts/backends/#security-options","title":"Security Options","text":"Python<pre><code># Restrict to specific directories\nbackend = LocalBackend(\n    allowed_directories=[\"/home/user/project\", \"/home/user/data\"],\n    enable_execute=True,\n)\n\n# Read-only mode (no shell execution)\nbackend = LocalBackend(\n    root_dir=\"/workspace\",\n    enable_execute=False,\n)\n\n# Corresponding toolset without execute\ntoolset = create_console_toolset(include_execute=False)\n</code></pre>"},{"location":"concepts/backends/#permission-system","title":"Permission System","text":"<p>For fine-grained access control, use the permission system:</p> Python<pre><code>from pydantic_ai_backends import LocalBackend\nfrom pydantic_ai_backends.permissions import (\n    DEFAULT_RULESET,\n    READONLY_RULESET,\n    PermissionRuleset,\n    OperationPermissions,\n    PermissionRule,\n)\n\n# Use pre-configured presets\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=DEFAULT_RULESET)\n\n# Read-only permissions\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=READONLY_RULESET)\n\n# Custom permissions\ncustom = PermissionRuleset(\n    read=OperationPermissions(\n        default=\"allow\",\n        rules=[\n            PermissionRule(pattern=\"**/.env*\", action=\"deny\"),\n        ],\n    ),\n    write=OperationPermissions(default=\"ask\"),\n    execute=OperationPermissions(\n        default=\"deny\",\n        rules=[\n            PermissionRule(pattern=\"git *\", action=\"allow\"),\n            PermissionRule(pattern=\"python *\", action=\"allow\"),\n        ],\n    ),\n)\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=custom)\n</code></pre> <p>See Permissions for full documentation.</p>"},{"location":"concepts/backends/#features","title":"Features","text":"<ul> <li>\u2705 Python-native file operations (cross-platform)</li> <li>\u2705 Optional shell execution via subprocess</li> <li>\u2705 Directory restrictions with <code>allowed_directories</code></li> <li>\u2705 Fast grep using ripgrep (with Python fallback)</li> <li>\u274c No isolation - runs with your permissions</li> </ul>"},{"location":"concepts/backends/#statebackend","title":"StateBackend","text":"<p>In-memory storage - perfect for testing your pydantic-ai agents.</p> Python<pre><code>import pytest\nfrom dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.test import TestModel\nfrom pydantic_ai_backends import StateBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: StateBackend\n\ndef test_agent_creates_file():\n    \"\"\"Test that agent can create files.\"\"\"\n    backend = StateBackend()\n    toolset = create_console_toolset(include_execute=False)\n\n    # Use TestModel for deterministic testing\n    agent = Agent(TestModel(), deps_type=Deps).with_toolset(toolset)\n\n    # Pre-populate files if needed\n    backend.write(\"/data/input.txt\", \"test data\")\n\n    # Run agent\n    result = agent.run_sync(\"Read input.txt\", deps=Deps(backend=backend))\n\n    # Verify files\n    assert \"/data/input.txt\" in backend.files\n</code></pre>"},{"location":"concepts/backends/#features_1","title":"Features","text":"<ul> <li>\u2705 Fast - no disk I/O</li> <li>\u2705 Isolated - no side effects</li> <li>\u2705 Perfect for unit testing</li> <li>\u2705 Access files via <code>backend.files</code></li> <li>\u274c Data lost when process ends</li> <li>\u274c No command execution</li> </ul>"},{"location":"concepts/backends/#compositebackend","title":"CompositeBackend","text":"<p>Route operations to different backends based on path prefix.</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import (\n    CompositeBackend, StateBackend, LocalBackend, create_console_toolset\n)\n\n@dataclass\nclass Deps:\n    backend: CompositeBackend\n\n# Combine backends with routing\nbackend = CompositeBackend(\n    default=StateBackend(),  # Default for unmatched paths\n    routes={\n        \"/project/\": LocalBackend(\"/my/project\"),\n        \"/data/\": LocalBackend(\"/shared/data\", enable_execute=False),\n    },\n)\n\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps).with_toolset(toolset)\n\n# Agent writes to /project/ go to LocalBackend\n# Agent writes to /temp/ go to StateBackend (ephemeral)\nresult = agent.run_sync(\n    \"Read /data/config.json and write results to /temp/output.json\",\n    deps=Deps(backend=backend),\n)\n</code></pre>"},{"location":"concepts/backends/#use-cases","title":"Use Cases","text":"<ul> <li>Persistent project files + ephemeral scratch space</li> <li>Multiple project directories</li> <li>Read-only data sources + writable outputs</li> </ul>"},{"location":"concepts/backends/#backend-protocol","title":"Backend Protocol","text":"<p>All backends implement this interface:</p> Python<pre><code>class BackendProtocol(Protocol):\n    def ls_info(self, path: str) -&gt; list[FileInfo]:\n        \"\"\"List directory contents.\"\"\"\n        ...\n\n    def read(self, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n        \"\"\"Read file with line numbers.\"\"\"\n        ...\n\n    def write(self, path: str, content: str | bytes) -&gt; WriteResult:\n        \"\"\"Write file contents.\"\"\"\n        ...\n\n    def edit(\n        self, path: str, old_string: str, new_string: str, replace_all: bool = False\n    ) -&gt; EditResult:\n        \"\"\"Edit file by replacing strings.\"\"\"\n        ...\n\n    def glob_info(self, pattern: str, path: str = \".\") -&gt; list[FileInfo]:\n        \"\"\"Find files matching glob pattern.\"\"\"\n        ...\n\n    def grep_raw(\n        self,\n        pattern: str,\n        path: str | None = None,\n        glob: str | None = None,\n        ignore_hidden: bool = True,\n    ) -&gt; list[GrepMatch] | str:\n        \"\"\"Search file contents with regex.\"\"\"\n        ...\n</code></pre>"},{"location":"concepts/backends/#execute-localbackend-dockersandbox","title":"Execute (LocalBackend, DockerSandbox)","text":"Python<pre><code>def execute(self, command: str, timeout: int | None = None) -&gt; ExecuteResponse:\n    \"\"\"Execute a shell command.\"\"\"\n    ...\n</code></pre>"},{"location":"concepts/backends/#path-security","title":"Path Security","text":"<p>All backends validate paths to prevent directory traversal:</p> Python<pre><code># These will fail:\nbackend.read(\"../etc/passwd\")      # Parent directory\nbackend.read(\"~/secrets\")          # Home expansion\nbackend.read(\"C:\\\\Windows\\\\...\")   # Windows paths\n</code></pre>"},{"location":"concepts/backends/#next-steps","title":"Next Steps","text":"<ul> <li>Permissions - Fine-grained access control</li> <li>Docker Sandbox - Isolated execution</li> <li>Console Toolset - Ready-to-use tools</li> <li>API Reference - Complete API</li> </ul>"},{"location":"concepts/console-toolset/","title":"Console Toolset","text":"<p>The console toolset provides ready-to-use pydantic-ai tools for file operations and shell execution.</p> <p>Requires pydantic-ai</p> Bash<pre><code>pip install pydantic-ai-backend[console]\n</code></pre>"},{"location":"concepts/console-toolset/#quick-start","title":"Quick Start","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Create toolset\ntoolset = create_console_toolset()\n\n# Create agent with tools\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps)\nagent = agent.with_toolset(toolset)\n\n# Run\nbackend = LocalBackend(root_dir=\"/workspace\")\nresult = agent.run_sync(\"List all Python files\", deps=Deps(backend=backend))\n</code></pre>"},{"location":"concepts/console-toolset/#available-tools","title":"Available Tools","text":"Tool Description <code>ls</code> List files in a directory <code>read_file</code> Read file content with line numbers <code>write_file</code> Create or overwrite a file <code>edit_file</code> Replace strings in a file <code>glob</code> Find files matching a pattern <code>grep</code> Search for patterns in files <code>execute</code> Run shell commands (optional)"},{"location":"concepts/console-toolset/#configuration","title":"Configuration","text":"Python<pre><code># Default: execute enabled, requires approval\ntoolset = create_console_toolset()\n\n# Without shell execution\ntoolset = create_console_toolset(include_execute=False)\n\n# Auto-approve writes\ntoolset = create_console_toolset(\n    require_write_approval=False,\n    require_execute_approval=False,\n)\n\n# Custom toolset ID\ntoolset = create_console_toolset(id=\"my-console\")\n\n# Include hidden files by default for grep\ntoolset = create_console_toolset(default_ignore_hidden=False)\n</code></pre>"},{"location":"concepts/console-toolset/#permission-based-configuration","title":"Permission-based Configuration","text":"<p>For fine-grained control, use the permission system:</p> Python<pre><code>from pydantic_ai_backends import create_console_toolset\nfrom pydantic_ai_backends.permissions import (\n    DEFAULT_RULESET,\n    READONLY_RULESET,\n    PermissionRuleset,\n    OperationPermissions,\n)\n\n# Use pre-configured presets\ntoolset = create_console_toolset(permissions=DEFAULT_RULESET)\n\n# Read-only toolset\ntoolset = create_console_toolset(permissions=READONLY_RULESET)\n\n# Custom permissions\ncustom = PermissionRuleset(\n    write=OperationPermissions(default=\"allow\"),  # No approval needed\n    execute=OperationPermissions(default=\"ask\"),   # Requires approval\n)\ntoolset = create_console_toolset(permissions=custom)\n</code></pre> <p>When <code>permissions</code> is provided, it overrides the legacy <code>require_write_approval</code> and <code>require_execute_approval</code> flags.</p> <p>See Permissions for full documentation.</p>"},{"location":"concepts/console-toolset/#consoledeps-protocol","title":"ConsoleDeps Protocol","text":"<p>Your dependencies class must have a <code>backend</code> property:</p> Python<pre><code>from pydantic_ai_backends import BackendProtocol\n\nclass ConsoleDeps(Protocol):\n    @property\n    def backend(self) -&gt; BackendProtocol:\n        ...\n</code></pre> <p>Any class with a <code>backend</code> attribute works:</p> Python<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass MyDeps:\n    backend: LocalBackend\n    user_id: str  # Additional fields are fine\n</code></pre>"},{"location":"concepts/console-toolset/#system-prompt","title":"System Prompt","text":"<p>Include the console system prompt for better tool usage:</p> Python<pre><code>from pydantic_ai_backends import get_console_system_prompt\n\nsystem_prompt = f\"\"\"You are a helpful coding assistant.\n\n{get_console_system_prompt()}\n\"\"\"\n\nagent = Agent(\n    \"openai:gpt-4o\",\n    system_prompt=system_prompt,\n    deps_type=Deps,\n)\n</code></pre>"},{"location":"concepts/console-toolset/#tool-details","title":"Tool Details","text":""},{"location":"concepts/console-toolset/#ls","title":"ls","text":"Python<pre><code>async def ls(ctx, path: str = \".\") -&gt; str:\n    \"\"\"List files and directories at the given path.\"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#read_file","title":"read_file","text":"Python<pre><code>async def read_file(ctx, path: str, offset: int = 0, limit: int = 2000) -&gt; str:\n    \"\"\"Read file content with line numbers.\"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#write_file","title":"write_file","text":"Python<pre><code>async def write_file(ctx, path: str, content: str) -&gt; str:\n    \"\"\"Write content to a file (creates or overwrites).\"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#edit_file","title":"edit_file","text":"Python<pre><code>async def edit_file(\n    ctx, path: str, old_string: str, new_string: str, replace_all: bool = False\n) -&gt; str:\n    \"\"\"Edit a file by replacing strings.\"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#glob","title":"glob","text":"Python<pre><code>async def glob(ctx, pattern: str, path: str = \".\") -&gt; str:\n    \"\"\"Find files matching a glob pattern.\"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#grep","title":"grep","text":"Python<pre><code>async def grep(\n    ctx,\n    pattern: str,\n    path: str | None = None,\n    glob_pattern: str | None = None,\n    output_mode: str = \"files_with_matches\",\n    ignore_hidden: bool = True,\n) -&gt; str:\n    \"\"\"Search for a regex pattern in files.\n\n    Args:\n        pattern: Regex pattern to search for.\n        path: Optional file/directory scope.\n        glob_pattern: Glob filter applied before searching.\n        output_mode: \"content\", \"files_with_matches\", or \"count\".\n        ignore_hidden: Whether to skip hidden files (defaults to the toolset setting).\n    \"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#execute","title":"execute","text":"Python<pre><code>async def execute(ctx, command: str, timeout: int | None = 120) -&gt; str:\n    \"\"\"Execute a shell command.\"\"\"\n</code></pre>"},{"location":"concepts/console-toolset/#with-different-backends","title":"With Different Backends","text":"<p>The toolset works with any backend:</p> LocalBackendStateBackendDockerSandbox Python<pre><code>backend = LocalBackend(root_dir=\"/workspace\")\n</code></pre> Python<pre><code>backend = StateBackend()\n</code></pre> Python<pre><code>backend = DockerSandbox(image=\"python:3.12-slim\")\n</code></pre>"},{"location":"concepts/console-toolset/#next-steps","title":"Next Steps","text":"<ul> <li>Permissions - Fine-grained access control</li> <li>CLI Agent Example - Build a CLI coding assistant</li> <li>API Reference - Complete API</li> </ul>"},{"location":"concepts/docker/","title":"Docker Sandbox","text":"<p><code>DockerSandbox</code> provides isolated code execution for your pydantic-ai agents. Run untrusted code safely in Docker containers.</p> <p>Requires Docker</p> <p>Bash<pre><code>pip install pydantic-ai-backend[docker]\n</code></pre> Ensure Docker is installed and the daemon is running.</p>"},{"location":"concepts/docker/#basic-usage-with-pydantic-ai","title":"Basic Usage with pydantic-ai","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import DockerSandbox, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: DockerSandbox\n\n# Create sandbox with pre-configured runtime\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n\ntry:\n    # Add console tools to your agent\n    toolset = create_console_toolset()\n    agent = Agent(\"openai:gpt-4o\", deps_type=Deps)\n    agent = agent.with_toolset(toolset)\n\n    # Agent can safely execute arbitrary code in Docker\n    result = agent.run_sync(\n        \"Load the iris dataset with sklearn, analyze it with pandas, \"\n        \"and create a visualization with matplotlib\",\n        deps=Deps(backend=sandbox),\n    )\n    print(result.output)\nfinally:\n    sandbox.stop()  # Clean up container\n</code></pre>"},{"location":"concepts/docker/#runtime-configurations","title":"Runtime Configurations","text":"<p>Pre-configured environments with packages pre-installed:</p> Python<pre><code>from pydantic_ai_backends import DockerSandbox, RuntimeConfig\n\n# Use built-in runtime\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n\n# Or define custom runtime for your use case\nruntime = RuntimeConfig(\n    name=\"ml-env\",\n    base_image=\"python:3.12-slim\",\n    packages=[\"torch\", \"transformers\", \"pandas\"],\n)\nsandbox = DockerSandbox(runtime=runtime)\n</code></pre>"},{"location":"concepts/docker/#built-in-runtimes","title":"Built-in Runtimes","text":"Runtime Description Use Case <code>python-minimal</code> Clean Python 3.12 General scripting <code>python-datascience</code> pandas, numpy, matplotlib, scikit-learn, seaborn Data analysis <code>python-web</code> FastAPI, SQLAlchemy, httpx Web development <code>node-minimal</code> Clean Node.js 20 JavaScript/TypeScript <code>node-react</code> TypeScript, Vite, React Frontend development"},{"location":"concepts/docker/#sessionmanager-for-multi-user","title":"SessionManager for Multi-User","text":"<p>For web apps where each user needs isolated execution:</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import SessionManager, DockerSandbox, create_console_toolset\n\n@dataclass\nclass UserDeps:\n    backend: DockerSandbox\n    user_id: str\n\n# Create session manager\nmanager = SessionManager(\n    default_runtime=\"python-datascience\",\n    workspace_root=\"/app/workspaces\",  # Persistent storage per user\n)\n\nasync def handle_user_request(user_id: str, message: str):\n    # Get or create sandbox for this user\n    sandbox = await manager.get_or_create(user_id)\n\n    # Create agent with user's isolated sandbox\n    toolset = create_console_toolset()\n    agent = Agent(\"openai:gpt-4o\", deps_type=UserDeps)\n    agent = agent.with_toolset(toolset)\n\n    result = await agent.run(\n        message,\n        deps=UserDeps(backend=sandbox, user_id=user_id),\n    )\n    return result.output\n\n# Each user's code runs in isolated container\n# User A cannot see User B's files\n</code></pre>"},{"location":"concepts/docker/#architecture","title":"Architecture","text":"Text Only<pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502 SessionManager  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                             \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                    \u2502                    \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 DockerSandbox \u2502   \u2502 DockerSandbox \u2502   \u2502 DockerSandbox \u2502\n\u2502   (User A)    \u2502   \u2502   (User B)    \u2502   \u2502   (User C)    \u2502\n\u2502  pydantic-ai  \u2502   \u2502  pydantic-ai  \u2502   \u2502  pydantic-ai  \u2502\n\u2502    Agent      \u2502   \u2502    Agent      \u2502   \u2502    Agent      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/docker/#persistent-storage","title":"Persistent Storage","text":"<p>By default, files are lost when container stops. Use volumes for persistence:</p> Python<pre><code>sandbox = DockerSandbox(\n    runtime=\"python-datascience\",\n    volumes={\"/host/data\": \"/workspace/data\"},  # Mount host directory\n)\n</code></pre> <p>With SessionManager, each user gets their own persistent directory:</p> Python<pre><code>manager = SessionManager(\n    workspace_root=\"/app/workspaces\",  # Creates /app/workspaces/{user_id}/\n)\n</code></pre>"},{"location":"concepts/docker/#security","title":"Security","text":"<ul> <li>Each user gets a separate Docker container</li> <li>Users cannot access each other's files</li> <li>Containers can have resource limits (CPU, memory)</li> <li>Network isolation available via Docker networking</li> <li>No host filesystem access (unless explicitly mounted)</li> </ul>"},{"location":"concepts/docker/#next-steps","title":"Next Steps","text":"<ul> <li>Multi-User Example - Web app with SessionManager</li> <li>Docker Sandbox Example - Full example</li> <li>API Reference - Complete API</li> </ul>"},{"location":"concepts/permissions/","title":"Permissions","text":"<p>The permission system provides fine-grained access control for file operations and shell commands. It uses pattern-based rules to allow, deny, or require approval for specific operations.</p>"},{"location":"concepts/permissions/#quick-start","title":"Quick Start","text":"Python<pre><code>from pydantic_ai_backends import LocalBackend\nfrom pydantic_ai_backends.permissions import DEFAULT_RULESET\n\n# Use the default safe ruleset\nbackend = LocalBackend(\n    root_dir=\"/workspace\",\n    permissions=DEFAULT_RULESET,\n)\n\n# Reads are allowed (except secrets)\ncontent = backend.read(\"app.py\")  # Works\n\n# Writes require approval (in sync context, denied by default)\nresult = backend.write(\"output.txt\", \"data\")  # Denied without callback\n</code></pre>"},{"location":"concepts/permissions/#permission-actions","title":"Permission Actions","text":"<p>Each operation can result in one of three actions:</p> Action Behavior <code>allow</code> Operation proceeds immediately <code>deny</code> Operation is blocked with an error <code>ask</code> Requires user approval via callback"},{"location":"concepts/permissions/#pre-configured-presets","title":"Pre-configured Presets","text":""},{"location":"concepts/permissions/#default_ruleset","title":"DEFAULT_RULESET","text":"<p>Safe defaults for development environments:</p> <ul> <li>Read: Allowed, except for secrets (<code>.env</code>, <code>.pem</code>, <code>credentials</code>, etc.)</li> <li>Write/Edit: Requires approval</li> <li>Execute: Requires approval, dangerous commands blocked</li> <li>Glob/Grep/Ls: Allowed</li> </ul> Python<pre><code>from pydantic_ai_backends.permissions import DEFAULT_RULESET\n\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=DEFAULT_RULESET)\n</code></pre>"},{"location":"concepts/permissions/#permissive_ruleset","title":"PERMISSIVE_RULESET","text":"<p>For trusted environments where most operations should succeed:</p> <ul> <li>Read: Allowed, except secrets</li> <li>Write/Edit: Allowed, except secrets and system files</li> <li>Execute: Allowed, dangerous commands blocked</li> <li>Glob/Grep/Ls: Allowed</li> </ul> Python<pre><code>from pydantic_ai_backends.permissions import PERMISSIVE_RULESET\n\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=PERMISSIVE_RULESET)\n</code></pre>"},{"location":"concepts/permissions/#readonly_ruleset","title":"READONLY_RULESET","text":"<p>For read-only access:</p> <ul> <li>Read: Allowed, except secrets</li> <li>Write/Edit/Execute: Denied</li> <li>Glob/Grep/Ls: Allowed</li> </ul> Python<pre><code>from pydantic_ai_backends.permissions import READONLY_RULESET\n\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=READONLY_RULESET)\n</code></pre>"},{"location":"concepts/permissions/#strict_ruleset","title":"STRICT_RULESET","text":"<p>Everything requires explicit approval:</p> <ul> <li>All operations: Require approval</li> <li>Secrets: Denied</li> </ul> Python<pre><code>from pydantic_ai_backends.permissions import STRICT_RULESET\n\nbackend = LocalBackend(root_dir=\"/workspace\", permissions=STRICT_RULESET)\n</code></pre>"},{"location":"concepts/permissions/#custom-rulesets","title":"Custom Rulesets","text":""},{"location":"concepts/permissions/#using-create_ruleset","title":"Using create_ruleset()","text":"<p>Quick factory for common configurations:</p> Python<pre><code>from pydantic_ai_backends.permissions import create_ruleset\n\n# Allow reads and writes, but ask for execute\nruleset = create_ruleset(\n    allow_read=True,\n    allow_write=True,\n    allow_execute=False,  # Will require approval\n    deny_secrets=True,     # Block access to sensitive files\n)\n</code></pre>"},{"location":"concepts/permissions/#full-custom-configuration","title":"Full Custom Configuration","text":"<p>For complete control, build a <code>PermissionRuleset</code>:</p> Python<pre><code>from pydantic_ai_backends.permissions import (\n    PermissionRuleset,\n    OperationPermissions,\n    PermissionRule,\n)\n\ncustom_permissions = PermissionRuleset(\n    default=\"deny\",  # Global default for unconfigured operations\n\n    read=OperationPermissions(\n        default=\"allow\",\n        rules=[\n            # Deny access to secrets\n            PermissionRule(\n                pattern=\"**/.env*\",\n                action=\"deny\",\n                description=\"Protect environment files\",\n            ),\n            PermissionRule(\n                pattern=\"**/secrets/**\",\n                action=\"deny\",\n                description=\"Protect secrets directory\",\n            ),\n        ],\n    ),\n\n    write=OperationPermissions(\n        default=\"ask\",\n        rules=[\n            # Auto-allow Python files\n            PermissionRule(pattern=\"**/*.py\", action=\"allow\"),\n            # Auto-allow markdown\n            PermissionRule(pattern=\"**/*.md\", action=\"allow\"),\n        ],\n    ),\n\n    execute=OperationPermissions(\n        default=\"deny\",\n        rules=[\n            # Allow safe git commands\n            PermissionRule(pattern=\"git status\", action=\"allow\"),\n            PermissionRule(pattern=\"git diff*\", action=\"allow\"),\n            PermissionRule(pattern=\"git log*\", action=\"allow\"),\n            # Allow Python execution\n            PermissionRule(pattern=\"python *\", action=\"allow\"),\n            PermissionRule(pattern=\"pytest *\", action=\"allow\"),\n        ],\n    ),\n\n    # Allow all search operations\n    glob=OperationPermissions(default=\"allow\"),\n    grep=OperationPermissions(default=\"allow\"),\n    ls=OperationPermissions(default=\"allow\"),\n)\n</code></pre>"},{"location":"concepts/permissions/#pattern-syntax","title":"Pattern Syntax","text":"<p>Patterns use glob-style matching:</p> Pattern Matches <code>*</code> Any characters except <code>/</code> <code>**</code> Any characters including <code>/</code> (recursive) <code>?</code> Any single character <code>[abc]</code> Any character in the set <code>[!abc]</code> Any character not in the set"},{"location":"concepts/permissions/#examples","title":"Examples","text":"Python<pre><code># Match .env files anywhere\nPermissionRule(pattern=\"**/.env\", action=\"deny\")\n\n# Match all .env* files (including .env.local, .env.production)\nPermissionRule(pattern=\"**/.env*\", action=\"deny\")\n\n# Match files in secrets directory\nPermissionRule(pattern=\"**/secrets/**\", action=\"deny\")\n\n# Match specific command\nPermissionRule(pattern=\"rm -rf *\", action=\"deny\")\n\n# Match command prefix\nPermissionRule(pattern=\"git *\", action=\"allow\")\n</code></pre>"},{"location":"concepts/permissions/#ask-callback","title":"Ask Callback","text":"<p>For interactive approval, provide an <code>ask_callback</code>:</p> Python<pre><code>async def my_approval_callback(\n    operation: str,  # \"read\", \"write\", \"edit\", \"execute\", etc.\n    target: str,     # Path or command\n    reason: str,     # Why approval is needed\n) -&gt; bool:\n    # Your approval logic here\n    response = input(f\"Allow {operation} on {target}? [y/N] \")\n    return response.lower() == \"y\"\n\nbackend = LocalBackend(\n    root_dir=\"/workspace\",\n    permissions=DEFAULT_RULESET,\n    ask_callback=my_approval_callback,\n)\n</code></pre>"},{"location":"concepts/permissions/#ask-fallback","title":"Ask Fallback","text":"<p>When no callback is provided, <code>ask_fallback</code> controls behavior:</p> Python<pre><code># Deny operations that need approval (default behavior)\nbackend = LocalBackend(\n    permissions=DEFAULT_RULESET,\n    ask_fallback=\"deny\",\n)\n\n# Raise PermissionError for operations that need approval\nbackend = LocalBackend(\n    permissions=DEFAULT_RULESET,\n    ask_fallback=\"error\",\n)\n</code></pre>"},{"location":"concepts/permissions/#integration-with-localbackend","title":"Integration with LocalBackend","text":"<p>Permissions are checked after <code>allowed_directories</code>:</p> Python<pre><code>backend = LocalBackend(\n    root_dir=\"/workspace\",\n    allowed_directories=[\"/workspace\", \"/data\"],  # Checked first\n    permissions=DEFAULT_RULESET,                   # Checked second\n)\n\n# Path must pass BOTH checks:\n# 1. Is the path within allowed_directories?\n# 2. Does the permission ruleset allow this operation?\n</code></pre>"},{"location":"concepts/permissions/#integration-with-console-toolset","title":"Integration with Console Toolset","text":"<p>Pass permissions to the toolset:</p> Python<pre><code>from pydantic_ai_backends import create_console_toolset\nfrom pydantic_ai_backends.permissions import DEFAULT_RULESET\n\n# Toolset uses permissions to determine approval requirements\ntoolset = create_console_toolset(permissions=DEFAULT_RULESET)\n</code></pre> <p>When <code>permissions</code> is provided, the legacy <code>require_write_approval</code> and <code>require_execute_approval</code> flags are ignored.</p>"},{"location":"concepts/permissions/#permissionchecker","title":"PermissionChecker","text":"<p>For programmatic permission checking:</p> Python<pre><code>from pydantic_ai_backends.permissions import PermissionChecker, DEFAULT_RULESET\n\nchecker = PermissionChecker(ruleset=DEFAULT_RULESET)\n\n# Synchronous check (returns action without asking)\naction = checker.check_sync(\"read\", \"/path/to/file.txt\")\n# Returns: \"allow\", \"deny\", or \"ask\"\n\n# Convenience methods\nif checker.is_allowed(\"read\", \"/path/to/file.txt\"):\n    print(\"Read is allowed\")\n\nif checker.is_denied(\"write\", \"/etc/passwd\"):\n    print(\"Write is denied\")\n\nif checker.requires_approval(\"execute\", \"rm -rf /tmp/*\"):\n    print(\"Execute requires approval\")\n</code></pre>"},{"location":"concepts/permissions/#built-in-patterns","title":"Built-in Patterns","text":"<p>The presets use these common patterns:</p>"},{"location":"concepts/permissions/#secrets_patterns","title":"SECRETS_PATTERNS","text":"Python<pre><code>SECRETS_PATTERNS = [\n    \"**/.env\",\n    \"**/.env.*\",\n    \"**/*.pem\",\n    \"**/*.key\",\n    \"**/*.crt\",\n    \"**/credentials*\",\n    \"**/secrets*\",\n    \"**/*secret*\",\n    \"**/*password*\",\n    \"**/.aws/**\",\n    \"**/.ssh/**\",\n    \"**/.gnupg/**\",\n]\n</code></pre>"},{"location":"concepts/permissions/#system_patterns","title":"SYSTEM_PATTERNS","text":"Python<pre><code>SYSTEM_PATTERNS = [\n    \"/etc/**\",\n    \"/var/**\",\n    \"/usr/**\",\n    \"/bin/**\",\n    \"/sbin/**\",\n    \"/boot/**\",\n    \"/sys/**\",\n    \"/proc/**\",\n]\n</code></pre>"},{"location":"concepts/permissions/#next-steps","title":"Next Steps","text":"<ul> <li>Backends - Backend configuration</li> <li>Console Toolset - Tool configuration</li> <li>API Reference - Complete API</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>Complete examples showing how to use pydantic-ai-backend with pydantic-ai agents.</p>"},{"location":"examples/#getting-started","title":"Getting Started","text":"Example Description CLI Agent Interactive CLI coding assistant Local Backend File operations with LocalBackend"},{"location":"examples/#production","title":"Production","text":"Example Description Docker Sandbox Safe code execution in Docker Multi-User Web App FastAPI server with user isolation"},{"location":"examples/#full-examples","title":"Full Examples","text":"<p>Complete working examples in the <code>examples/</code> directory:</p> Directory Description <code>local_cli/</code> CLI coding assistant with pydantic-ai <code>web_production/</code> Multi-user web app with Docker"},{"location":"examples/#quick-reference","title":"Quick Reference","text":""},{"location":"examples/#cli-agent-localbackend","title":"CLI Agent (LocalBackend)","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\nbackend = LocalBackend(root_dir=\".\")\ntoolset = create_console_toolset()\n\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps)\nagent = agent.with_toolset(toolset)\n\nresult = agent.run_sync(\n    \"Create a hello.py script and run it\",\n    deps=Deps(backend=backend),\n)\n</code></pre>"},{"location":"examples/#safe-code-execution-dockersandbox","title":"Safe Code Execution (DockerSandbox)","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import DockerSandbox, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: DockerSandbox\n\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n\ntry:\n    toolset = create_console_toolset()\n    agent = Agent(\"openai:gpt-4o\", deps_type=Deps)\n    agent = agent.with_toolset(toolset)\n\n    result = agent.run_sync(\n        \"Analyze data with pandas and create a chart\",\n        deps=Deps(backend=sandbox),\n    )\nfinally:\n    sandbox.stop()\n</code></pre>"},{"location":"examples/#multi-user-web-app-sessionmanager","title":"Multi-User Web App (SessionManager)","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import SessionManager, DockerSandbox, create_console_toolset\n\n@dataclass\nclass UserDeps:\n    backend: DockerSandbox\n    user_id: str\n\nmanager = SessionManager(workspace_root=\"/app/workspaces\")\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=UserDeps).with_toolset(toolset)\n\nasync def handle_request(user_id: str, message: str):\n    sandbox = await manager.get_or_create(user_id)\n    result = await agent.run(message, deps=UserDeps(backend=sandbox, user_id=user_id))\n    return result.output\n</code></pre>"},{"location":"examples/#unit-testing-statebackend","title":"Unit Testing (StateBackend)","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models.test import TestModel\nfrom pydantic_ai_backends import StateBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: StateBackend\n\ndef test_agent_file_operations():\n    backend = StateBackend()\n    toolset = create_console_toolset(include_execute=False)\n\n    agent = Agent(TestModel(), deps_type=Deps)\n    agent = agent.with_toolset(toolset)\n\n    # Pre-populate test files\n    backend.write(\"/input.txt\", \"test data\")\n\n    result = agent.run_sync(\"Read input.txt\", deps=Deps(backend=backend))\n\n    # Verify agent behavior\n    assert \"/input.txt\" in backend.files\n</code></pre>"},{"location":"examples/cli-agent/","title":"CLI Agent Example","text":"<p>Build an interactive CLI coding assistant using <code>LocalBackend</code> and the console toolset.</p>"},{"location":"examples/cli-agent/#quick-start","title":"Quick Start","text":"Bash<pre><code>cd examples/local_cli\npip install pydantic-ai-backend[console]\nexport OPENAI_API_KEY=your-key\npython cli_agent.py\n\n# Include hidden files (e.g., .env) when searching\npython cli_agent.py --include-hidden\n</code></pre>"},{"location":"examples/cli-agent/#basic-implementation","title":"Basic Implementation","text":"Python<pre><code>import asyncio\nfrom dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset, get_console_system_prompt\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Create backend and toolset\nbackend = LocalBackend(root_dir=\".\", enable_execute=True)\ntoolset = create_console_toolset()\n\n# Create agent\nagent = Agent(\n    \"openai:gpt-4o-mini\",\n    system_prompt=f\"\"\"You are a helpful coding assistant.\n{get_console_system_prompt()}\n\"\"\",\n    deps_type=Deps,\n)\nagent = agent.with_toolset(toolset)\n\nasync def main():\n    deps = Deps(backend=backend)\n\n    print(\"CLI Agent ready! Type 'quit' to exit.\")\n\n    while True:\n        user_input = input(\"You: \").strip()\n\n        if user_input.lower() in (\"quit\", \"exit\"):\n            break\n\n        result = await agent.run(user_input, deps=deps)\n        print(f\"\\nAgent: {result.output}\\n\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/cli-agent/#features","title":"Features","text":"<p>The agent can:</p> <ul> <li>List files: \"Show me what's in this directory\"</li> <li>Read files: \"Read the main.py file\"</li> <li>Write files: \"Create a hello.py that prints Hello World\"</li> <li>Edit files: \"Change the function name from foo to bar\"</li> <li>Search: \"Find all files containing 'TODO'\" (use <code>--include-hidden</code> to search dotfiles)</li> <li>Execute: \"Run the tests\"</li> </ul>"},{"location":"examples/cli-agent/#example-session","title":"Example Session","text":"Text Only<pre><code>CLI Agent ready! Type 'quit' to exit.\n\nYou: Show me the project structure\n\nAgent: Let me list the files in the current directory.\n\nContents of .:\n  src/\n  tests/\n  README.md\n  pyproject.toml\n\nThe project has:\n- `src/` - Source code\n- `tests/` - Test files\n- `README.md` - Documentation\n- `pyproject.toml` - Project config\n\nYou: Create a fibonacci function\n\nAgent: I'll create a fibonacci.py file with the function.\n\nCreated fibonacci.py with a fibonacci function that calculates\nthe nth Fibonacci number using recursion with memoization.\n\nYou: Run it with n=10\n\nAgent: Running the script...\n\nOutput: 55\n\nThe 10th Fibonacci number is 55.\n</code></pre>"},{"location":"examples/cli-agent/#command-line-options","title":"Command Line Options","text":"<p>The full example supports these options:</p> Bash<pre><code># Specify working directory\npython cli_agent.py --dir /path/to/project\n\n# Use different model\npython cli_agent.py --model anthropic:claude-3-haiku\n\n# Disable shell execution\npython cli_agent.py --no-execute\n\n# Restrict file access\npython cli_agent.py --restrict\n\n# Include hidden files in searches\npython cli_agent.py --include-hidden\n\n# Single task mode\npython cli_agent.py --task \"Create a hello world script\"\n</code></pre>"},{"location":"examples/cli-agent/#full-example","title":"Full Example","text":"<p>See <code>examples/local_cli/cli_agent.py</code> for the complete implementation with:</p> <ul> <li>Command line argument parsing</li> <li>Interactive and single-task modes</li> <li>Security options (--restrict, --no-execute)</li> <li>Help command</li> </ul>"},{"location":"examples/docker-sandbox/","title":"Docker Sandbox Example","text":"<p>Build a pydantic-ai agent that safely executes code in Docker containers.</p> <p>Requires Docker</p> Bash<pre><code>pip install pydantic-ai-backend[docker]\ndocker pull python:3.12-slim\n</code></pre>"},{"location":"examples/docker-sandbox/#quick-start","title":"Quick Start","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import DockerSandbox, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: DockerSandbox\n\n# Create sandbox with data science packages\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n\ntry:\n    # Add file tools to your agent\n    toolset = create_console_toolset()\n    agent = Agent(\"openai:gpt-4o\", deps_type=Deps)\n    agent = agent.with_toolset(toolset)\n\n    # Agent can safely execute arbitrary code\n    result = agent.run_sync(\n        \"Create a script that generates random data with numpy, \"\n        \"analyzes it with pandas, and shows statistics\",\n        deps=Deps(backend=sandbox),\n    )\n    print(result.output)\nfinally:\n    sandbox.stop()\n</code></pre>"},{"location":"examples/docker-sandbox/#data-science-agent","title":"Data Science Agent","text":"<p>Build a code interpreter for data analysis:</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import (\n    DockerSandbox, create_console_toolset, get_console_system_prompt\n)\n\n@dataclass\nclass Deps:\n    backend: DockerSandbox\n\nsandbox = DockerSandbox(runtime=\"python-datascience\")\n\ntry:\n    toolset = create_console_toolset()\n    agent = Agent(\n        \"openai:gpt-4o\",\n        system_prompt=f\"\"\"You are a data science assistant.\nYou can write and execute Python code to analyze data.\nAvailable packages: pandas, numpy, matplotlib, scikit-learn, seaborn.\n\n{get_console_system_prompt()}\n\"\"\",\n        deps_type=Deps,\n    )\n    agent = agent.with_toolset(toolset)\n\n    # Complex data analysis task\n    result = agent.run_sync(\n        \"Load the iris dataset from sklearn, \"\n        \"create a classification model, \"\n        \"and visualize the results\",\n        deps=Deps(backend=sandbox),\n    )\n    print(result.output)\nfinally:\n    sandbox.stop()\n</code></pre>"},{"location":"examples/docker-sandbox/#pre-configured-runtimes","title":"Pre-configured Runtimes","text":"Runtime Packages Use Case <code>python-minimal</code> Clean Python 3.12 General scripting <code>python-datascience</code> pandas, numpy, matplotlib, scikit-learn, seaborn Data analysis <code>python-web</code> FastAPI, SQLAlchemy, httpx Web development <code>node-minimal</code> Clean Node.js 20 JavaScript <code>node-react</code> TypeScript, Vite, React Frontend"},{"location":"examples/docker-sandbox/#custom-runtime","title":"Custom Runtime","text":"Python<pre><code>from pydantic_ai_backends import DockerSandbox, RuntimeConfig\n\nruntime = RuntimeConfig(\n    name=\"ml-env\",\n    base_image=\"python:3.12-slim\",\n    packages=[\"torch\", \"transformers\", \"datasets\"],\n    env_vars={\"PYTHONUNBUFFERED\": \"1\"},\n)\n\nsandbox = DockerSandbox(runtime=runtime)\n</code></pre>"},{"location":"examples/docker-sandbox/#persistent-storage","title":"Persistent Storage","text":"<p>Save results between sessions:</p> Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import DockerSandbox, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: DockerSandbox\n\n# Mount host directory for persistence\nsandbox = DockerSandbox(\n    runtime=\"python-datascience\",\n    volumes={\n        \"/host/results\": \"/workspace/results\",\n    },\n)\n\ntry:\n    toolset = create_console_toolset()\n    agent = Agent(\"openai:gpt-4o\", deps_type=Deps).with_toolset(toolset)\n\n    result = agent.run_sync(\n        \"Analyze data and save results to /workspace/results/analysis.csv\",\n        deps=Deps(backend=sandbox),\n    )\n    # Results persist in /host/results/ after container stops\nfinally:\n    sandbox.stop()\n</code></pre>"},{"location":"examples/docker-sandbox/#error-handling","title":"Error Handling","text":"<p>The agent receives execution errors and can fix them:</p> Python<pre><code>result = agent.run_sync(\n    \"Try to import a non-existent package, then fix the error\",\n    deps=Deps(backend=sandbox),\n)\n# Agent will see the ImportError and adapt\n</code></pre>"},{"location":"examples/docker-sandbox/#container-lifecycle","title":"Container Lifecycle","text":"Python<pre><code>sandbox = DockerSandbox(runtime=\"python-datascience\")\n\n# Container starts lazily on first operation\nsandbox.write(\"/workspace/test.py\", \"print('hello')\")\n\n# Check if running\nprint(sandbox.is_alive())  # True\n\n# Pre-warm container (useful before user requests)\nsandbox.start()\n\n# Clean up when done\nsandbox.stop()\nprint(sandbox.is_alive())  # False\n</code></pre>"},{"location":"examples/local-backend/","title":"Local Backend Example","text":"<p>Build a pydantic-ai agent that works with local files using <code>LocalBackend</code>.</p>"},{"location":"examples/local-backend/#quick-start","title":"Quick Start","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Create backend for local filesystem\nbackend = LocalBackend(root_dir=\"./workspace\")\n\n# Add file tools to your agent\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps)\nagent = agent.with_toolset(toolset)\n\n# Your agent can now work with files!\nresult = agent.run_sync(\n    \"Create a fibonacci.py script that calculates fib(10) and run it\",\n    deps=Deps(backend=backend),\n)\nprint(result.output)\n</code></pre>"},{"location":"examples/local-backend/#complete-cli-agent","title":"Complete CLI Agent","text":"<p>Interactive coding assistant that works with your local project:</p> Python<pre><code>import asyncio\nfrom dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import (\n    LocalBackend, create_console_toolset, get_console_system_prompt\n)\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Create backend with security restrictions\nbackend = LocalBackend(\n    root_dir=\".\",\n    allowed_directories=[\"./\"],  # Restrict to current dir\n    enable_execute=True,\n)\n\n# Create agent with file tools\ntoolset = create_console_toolset()\nagent = Agent(\n    \"openai:gpt-4o\",\n    system_prompt=f\"\"\"You are a helpful coding assistant.\n{get_console_system_prompt()}\n\"\"\",\n    deps_type=Deps,\n)\nagent = agent.with_toolset(toolset)\n\nasync def main():\n    deps = Deps(backend=backend)\n    print(\"CLI Agent ready! Type 'quit' to exit.\\n\")\n\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() in (\"quit\", \"exit\"):\n            break\n\n        result = await agent.run(user_input, deps=deps)\n        print(f\"\\nAgent: {result.output}\\n\")\n\nasyncio.run(main())\n</code></pre>"},{"location":"examples/local-backend/#security-options","title":"Security Options","text":""},{"location":"examples/local-backend/#restricted-directories","title":"Restricted Directories","text":"Python<pre><code>from dataclasses import dataclass\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import LocalBackend, create_console_toolset\n\n@dataclass\nclass Deps:\n    backend: LocalBackend\n\n# Only allow access to specific directories\nbackend = LocalBackend(\n    allowed_directories=[\n        \"/home/user/project\",\n        \"/home/user/data\",\n    ],\n)\n\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=Deps).with_toolset(toolset)\n\n# Agent can access /home/user/project but NOT /etc/passwd\n</code></pre>"},{"location":"examples/local-backend/#disable-execution","title":"Disable Execution","text":"Python<pre><code># Read-only mode - no shell access\nbackend = LocalBackend(\n    root_dir=\"/workspace\",\n    enable_execute=False,\n)\n\n# Toolset without execute command\ntoolset = create_console_toolset(include_execute=False)\n</code></pre>"},{"location":"examples/local-backend/#example-session","title":"Example Session","text":"Text Only<pre><code>CLI Agent ready! Type 'quit' to exit.\n\nYou: Show me the project structure\n\nAgent: Let me list the files in the current directory.\n\nContents of .:\n  src/\n  tests/\n  README.md\n  pyproject.toml\n\nThe project has:\n- `src/` - Source code\n- `tests/` - Test files\n- `README.md` - Documentation\n- `pyproject.toml` - Project config\n\nYou: Create a fibonacci function\n\nAgent: I'll create a fibonacci.py file with the function.\n\nCreated fibonacci.py with a fibonacci function that calculates\nthe nth Fibonacci number using recursion with memoization.\n\nYou: Run it with n=10\n\nAgent: Running the script...\n\nOutput: 55\n\nThe 10th Fibonacci number is 55.\n</code></pre>"},{"location":"examples/local-backend/#full-example","title":"Full Example","text":"<p>See <code>examples/local_cli/</code> for a complete implementation:</p> Bash<pre><code>cd examples/local_cli\npip install pydantic-ai-backend[console]\npython cli_agent.py --dir ~/myproject\n</code></pre>"},{"location":"examples/multi-user/","title":"Multi-User Web App Example","text":"<p>Build a multi-user web application where each user gets isolated storage and execution.</p>"},{"location":"examples/multi-user/#architecture","title":"Architecture","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Web UI (templates/)                      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                      FastAPI Server                         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                    SessionManager                           \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 DockerSandbox \u2502 DockerSandbox \u2502 DockerSandbox \u2502    ...     \u2502\n\u2502   (User A)    \u2502   (User B)    \u2502   (User C)    \u2502            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"examples/multi-user/#sessionmanager","title":"SessionManager","text":"Python<pre><code>from pydantic_ai_backends import SessionManager\n\n# Create manager\nmanager = SessionManager(\n    image=\"python:3.12-slim\",\n    workspace_root=\"/app/workspaces\",  # Persistent storage\n    auto_remove=True,\n)\n\n# Create session for user\nsession_id = manager.create_session(user_id=\"alice\")\n\n# Get sandbox for session\nsandbox = manager.get_session(session_id)\n\n# User operations are isolated\nsandbox.write(\"/workspace/secret.txt\", \"Alice's private data\")\nsandbox.execute(\"python script.py\")\n\n# End session (removes container)\nmanager.end_session(session_id)\n</code></pre>"},{"location":"examples/multi-user/#fastapi-server","title":"FastAPI Server","text":"Python<pre><code>from contextlib import asynccontextmanager\nfrom dataclasses import dataclass\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom pydantic_ai import Agent\nfrom pydantic_ai_backends import SessionManager, DockerSandbox, create_console_toolset\n\n# Session manager\nsession_manager: SessionManager | None = None\n\n@asynccontextmanager\nasync def lifespan(app):\n    global session_manager\n    session_manager = SessionManager(\n        image=\"python:3.12-slim\",\n        workspace_root=\"/tmp/workspaces\",\n    )\n    yield\n    # Cleanup on shutdown\n    for sid in list(session_manager._sandboxes.keys()):\n        session_manager.end_session(sid)\n\napp = FastAPI(lifespan=lifespan)\n\n# Agent setup\n@dataclass\nclass UserDeps:\n    backend: DockerSandbox\n    user_id: str\n\ntoolset = create_console_toolset()\nagent = Agent(\"openai:gpt-4o\", deps_type=UserDeps).with_toolset(toolset)\n\n# Request models\nclass ChatRequest(BaseModel):\n    message: str\n\nclass ChatResponse(BaseModel):\n    response: str\n    session_id: str\n\n# Endpoints\n@app.post(\"/sessions\")\nasync def create_session(user_id: str | None = None):\n    session_id = session_manager.create_session(user_id=user_id)\n    return {\"session_id\": session_id}\n\n@app.post(\"/sessions/{session_id}/chat\")\nasync def chat(session_id: str, request: ChatRequest):\n    try:\n        sandbox = session_manager.get_session(session_id)\n    except ValueError:\n        raise HTTPException(404, \"Session not found\")\n\n    deps = UserDeps(backend=sandbox, user_id=session_id)\n    result = await agent.run(request.message, deps=deps)\n\n    return ChatResponse(response=result.output, session_id=session_id)\n\n@app.delete(\"/sessions/{session_id}\")\nasync def end_session(session_id: str):\n    session_manager.end_session(session_id)\n    return {\"message\": \"Session ended\"}\n\n@app.get(\"/sessions/{session_id}/files\")\nasync def list_files(session_id: str, path: str = \".\"):\n    sandbox = session_manager.get_session(session_id)\n    return {\"files\": sandbox.ls_info(path)}\n</code></pre>"},{"location":"examples/multi-user/#client-usage","title":"Client Usage","text":"Python<pre><code>import httpx\n\nasync def main():\n    async with httpx.AsyncClient(base_url=\"http://localhost:8000\") as client:\n        # Create session\n        r = await client.post(\"/sessions\", params={\"user_id\": \"alice\"})\n        session_id = r.json()[\"session_id\"]\n\n        # Chat with AI\n        r = await client.post(\n            f\"/sessions/{session_id}/chat\",\n            json={\"message\": \"Create a hello world script and run it\"}\n        )\n        print(r.json()[\"response\"])\n\n        # List files\n        r = await client.get(f\"/sessions/{session_id}/files\")\n        print(r.json()[\"files\"])\n\n        # Cleanup\n        await client.delete(f\"/sessions/{session_id}\")\n</code></pre>"},{"location":"examples/multi-user/#security-features","title":"Security Features","text":"<ul> <li>User Isolation: Each user's container is separate</li> <li>No Cross-Access: Users cannot see other users' files</li> <li>Persistent Storage: Files stored on host, mounted into containers</li> <li>Automatic Cleanup: Containers removed when sessions end</li> </ul>"},{"location":"examples/multi-user/#full-example","title":"Full Example","text":"<p>See <code>examples/web_production/</code> for a complete implementation with:</p> <ul> <li>FastAPI server</li> <li>HTML/JS frontend</li> <li>Session management</li> <li>AI chat integration</li> </ul> Bash<pre><code>cd examples/web_production\npip install pydantic-ai-backend[docker] fastapi uvicorn pydantic-ai jinja2\npython server.py\n# Open http://localhost:8000\n</code></pre>"}]}